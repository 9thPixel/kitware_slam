//=========================================================================
//
// Copyright 2018 Kitware, Inc.
// Author: Guilbert Pierre (spguilbert@gmail.com)
// Data: 03-27-2018
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//=========================================================================

// This slam algorithm is largely inspired by the LOAM algorithm:
// J. Zhang and S. Singh. LOAM: Lidar Odometry and Mapping in Real-time.
// Robotics: Science and Systems Conference (RSS). Berkeley, CA, July 2014.

// The algorithm is composed of three sequential steps:
//
// - Keypoints extraction: this step consists of extracting keypoints over
// the points clouds. To do that, the laser lines / scans are trated indepently.
// The laser lines are projected onto the XY plane and are rescale depending on
// their vertical angle. Then we compute their curvature and create two class of
// keypoints. The edges keypoints which correspond to points with a hight curvature
// and planar points which correspond to points with a low curvature.
//
// - Ego-Motion: this step consists of recovering the motion of the lidar
// sensor between two frames (two sweeps). The motion is modelized by a constant
// velocity and angular velocity between two frames (i.e null acceleration). 
// Hence, we can parameterize the motion by a rotation and translation per sweep / frame
// and interpolate the transformation inside a frame using the timestamp of the points.
// Since the points clouds generated by a lidar are sparses we can't design a
// pairwise match between keypoints of two successive frames. Hence, we decided to use
// a closest-point matching between the keypoints of the current frame
// and the geometrics features derived from the keypoints of the previous frame.
// The geometrics features are lines or planes and are computed using the edges keypoints
// and planar keypoints of the previous frame. Once the matching is done, a keypoint
// of the current frame is matched with a plane / line (depending of the
// nature of the keypoint) from the previous frame. Then, we recover R and T by
// minimizing the function f(R, T) = sum(d(point, line)^2) + sum(d(point, plane)^2).
// Which can be writen f(R, T) = sum((R*X+T-P).t*A*(R*X+T-P)) where:
// - X is a keypoint of the current frame
// - P is a point of the corresponding line / plane
// - A = (n*n.t) with n being the normal of the plane
// - A = (I - n*n.t).t * (I - n*n.t) with n being a director vector of the line
// Since the function f(R, T) is a non-linear mean square error function
// we decided to use the Levenberg-Marquardt algorithm to recover its argmin.
//
// - Mapping: This step consists of refining the motion recovered in the Ego-Motion
// step and to add the new frame in the environment map. Thanks to the ego-motion
// recovered at the previous step it is now possible to estimate the new position of
// the sensor in the map. We use this estimation as an initial point (R0, T0) and we
// perform an optimization again using the keypoints of the current frame and the matched
// keypoints of the map (and not only the previous frame this time!). Once the position in the
// map has been refined from the first estimation it is then possible to update the map by
// adding the keypoints of the current frame into the map.
//
// In the following programs : "vtkSlam.h" and "vtkSlam.cxx" the lidar
// coordinate system {L} is a 3D coordinate system with its origin at the
// geometric center of the lidar. The world coordinate system {W} is a 3D
// coordinate system which coinciding with {L] at the initial position. The
// points will be denoted by the ending letter L or W if they belong to
// the corresponding coordinate system

// LOCAL
#include "vtkSlam.h"
#include "vtkVelodyneHDLReader.h"
#include "vtkVelodyneTransformInterpolator.h"
#include "vtkPCLConversions.h"
// STD
#include <sstream>
#include <algorithm>
#include <cmath>
#include <cfloat>
#include <ctime>
// VTK
#include <vtkCellArray.h>
#include <vtkCellData.h>
#include <vtkDataArray.h>
#include <vtkDoubleArray.h>
#include <vtkFloatArray.h>
#include <vtkInformation.h>
#include <vtkInformationVector.h>
#include <vtkMath.h>
#include <vtkNew.h>
#include <vtkObjectFactory.h>
#include <vtkPointData.h>
#include <vtkPoints.h>
#include <vtkPolyData.h>
#include <vtkPolyLine.h>
#include <vtkSmartPointer.h>
#include <vtkStreamingDemandDrivenPipeline.h>
#include <vtkQuaternion.h>
#include <vtkUnsignedCharArray.h>
#include <vtkUnsignedShortArray.h>
#include <vtkTransform.h>
#include <vtkPoints.h>
#include <vtkTransform.h>
#include <vtkTransformPolyDataFilter.h>
// EIGEN
#include <Eigen/Dense>
// PCL
#include <pcl/point_types.h>
#include <pcl/filters/voxel_grid.h>

vtkStandardNewMacro(vtkSlam);


namespace {
class LineFitting
{
public:
  LineFitting();

  // Fitting using PCA
  void FitPCA(std::vector<Eigen::Matrix<double, 3, 1> >& points);

  // Poor but fast fitting using
  // extremities of the distribution
  void FitFast(std::vector<Eigen::Matrix<double, 3, 1> >& points);

  // Direction and position
  Eigen::Matrix<double, 3, 1> Direction;
  Eigen::Matrix<double, 3, 1> Position;
  Eigen::Matrix<double, 3, 3> SemiDist;
  double MaxDistance;

  Eigen::Matrix<double, 3, 3> I3;
};

//-----------------------------------------------------------------------------
LineFitting::LineFitting()
{
  this->I3 << 1, 0, 0,
              0, 1, 0,
              0, 0, 1;
}

//-----------------------------------------------------------------------------
void LineFitting::FitPCA(std::vector<Eigen::Matrix<double, 3, 1> >& points)
{
  Eigen::Matrix<double, 3, 3> I3;
  I3 << 1, 0, 0,
        0, 1, 0,
        0, 0, 1;

  // Compute PCA to determine best line approximation
  // of the points distribution
  Eigen::MatrixXd data(points.size(), 3);

  for (unsigned int k = 0; k < points.size(); k++)
  {
    data.row(k) = points[k];
  }

  Eigen::Matrix<double, 3, 1> mean = data.colwise().mean();
  Eigen::MatrixXd centered = data.rowwise() - mean.transpose();
  Eigen::MatrixXd cov = centered.transpose() * centered;
  Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> eig(cov);

  // Eigen values
  Eigen::MatrixXd D(1,3);
  // Eigen vectors
  Eigen::MatrixXd V(3,3);

  D = eig.eigenvalues();
  V = eig.eigenvectors();

  // Direction
  this->Direction = V.col(2).normalized();

  // Position
  this->Position = mean;

  // Semi distance matrix
  // (polar form associated to
  // a bilineare symmetric positive
  // semi-definite matrix)
  this->SemiDist = (this->I3 - this->Direction * this->Direction.transpose());
  this->SemiDist = this->SemiDist.transpose() * this->SemiDist;
}

//-----------------------------------------------------------------------------
void LineFitting::FitFast(std::vector<Eigen::Matrix<double, 3, 1> >& points)
{
  // Take the two extrems points of the neighborhood
  // i.e the farest and the closest to the current point
  Eigen::Matrix<double, 3, 1> U = points[0];
  Eigen::Matrix<double, 3, 1> V = points[points.size() - 1];

  // direction
  this->Direction = (V - U).normalized();

  // position
  this->Position = U;

  // Semi distance matrix
  // (polar form associated to
  // a bilineare symmetric positive
  // semi-definite matrix)
  this->SemiDist = (this->I3 - this->Direction * this->Direction.transpose());
  this->SemiDist = this->SemiDist.transpose() * this->SemiDist;
}

//-----------------------------------------------------------------------------
Eigen::Matrix3d GetRotationMatrix(Eigen::Matrix<double, 6, 1> T)
{
  // T(0) = rx, T(1) = ry, T(2) = rz
  // R = Rz(rz) * Ry(ry) * Rx(rx)
  return Eigen::Matrix3d(
        Eigen::AngleAxisd(T(2), Eigen::Vector3d::UnitZ())       /* rotation around Z-axis */
        * Eigen::AngleAxisd(T(1), Eigen::Vector3d::UnitY())     /* rotation around Y-axis */
        * Eigen::AngleAxisd(T(0), Eigen::Vector3d::UnitX()));   /* rotation around X-axis */
}

//-----------------------------------------------------------------------------
template <typename T>
vtkSmartPointer<T> CreateDataArray(const char* name, vtkIdType np, vtkPolyData* pd)
{
  vtkSmartPointer<T> array = vtkSmartPointer<T>::New();
  array->Allocate(np);
  array->SetName(name);

  if (pd)
    {
    pd->GetPointData()->AddArray(array);
    }

  return array;
}

//-----------------------------------------------------------------------------
template <typename T>
std::vector<size_t> sortIdx(const std::vector<T> &v)
{
  // initialize original index locations
  std::vector<size_t> idx(v.size());
  std::iota(idx.begin(), idx.end(), 0);

  // sort indexes based on comparing values in v
  std::sort(idx.begin(), idx.end(),
       [&v](size_t i1, size_t i2) {return v[i1] > v[i2];});

  return idx;
}

//-----------------------------------------------------------------------------
std::clock_t startTime;

//-----------------------------------------------------------------------------
void InitTime()
{
  startTime = std::clock();
}

//-----------------------------------------------------------------------------
void StopTimeAndDisplay(std::string functionName)
{
  std::clock_t endTime = std::clock();
  double dt = static_cast<double>(endTime - startTime) / CLOCKS_PER_SEC;
  std::cout << "  -time elapsed in function <" << functionName << "> : " << dt << " sec" << std::endl;
}

//-----------------------------------------------------------------------------
double Rad2Deg(double val)
{
  return val / vtkMath::Pi() * 180;
}

//-----------------------------------------------------------------------------
double Deg2Rad(double val)
{
  return val / 180 * vtkMath::Pi();
}
}

// The map reconstructed from the slam algorithm is stored in a voxel grid
// which split the space in differents region. From this voxel grid it is possible
// to only load the parts of the map which are pertinents when we run the mapping
// optimization algorithm. Morevover, when a a region of the space is too far from
// the current sensor position it is possible to remove the points stored in this region
// and to move the voxel grid in a closest region of the sensor position. This is used
// to decrease the memory used by the algorithm
class RollingGrid {
public:
  RollingGrid()
  {
    // should initialize using Tworld + size / 2
    this->VoxelGridPosition[0] = 0;
    this->VoxelGridPosition[1] = 0;
    this->VoxelGridPosition[2] = 0;

    this->LeafVoxelFilterSize = 0.2;
  }

  RollingGrid(double posX, double posY, double posZ)
  {
    // should initialize using Tworld + size / 2
    this->VoxelGridPosition[0] = static_cast<int>(posX);
    this->VoxelGridPosition[1] = static_cast<int>(posY);
    this->VoxelGridPosition[2] = static_cast<int>(posZ);;

    this->LeafVoxelFilterSize = 0.2;
  }

  // roll the grid to enable adding new point cloud
  void Roll(Eigen::Matrix<double, 6, 1> &T)
  {
    // Very basic implementation where the grid is not circular

    // compute the position of the new frame center in the grid
    int frameCenterX = std::floor(T[3] / this->VoxelSize) - this->VoxelGridPosition[0];
    int frameCenterY = std::floor(T[4] / this->VoxelSize) - this->VoxelGridPosition[1];
    int frameCenterZ = std::floor(T[5] / this->VoxelSize) - this->VoxelGridPosition[2];

    // shift the voxel grid to the left
    while (frameCenterX - std::ceil(this->PointCloud_NbVoxelX / 2) <= 0)
    {
      for (int j = 0; j < this->Grid_NbVoxelY; j++)
      {
        for (int k = 0; k < this->Grid_NbVoxelZ; k++)
        {
          for (int i = this->Grid_NbVoxelX - 1; i > 0; i--)
          {
            this->grid[i][j][k] = this->grid[i-1][j][k];
          }
          this->grid[0][j][k].reset(new pcl::PointCloud<Point>());
        }
      }
      frameCenterX++;
      this->VoxelGridPosition[0]--;
    }

    // shift the voxel grid to the right
    while (frameCenterX + std::ceil(this->PointCloud_NbVoxelX / 2) >= this->Grid_NbVoxelX - 1)
    {
      for (int j = 0; j < this->Grid_NbVoxelY; j++)
      {
        for (int k = 0; k < this->Grid_NbVoxelZ; k++)
        {
          for (int i = 0; i < this->Grid_NbVoxelX - 1; i++)
          {
            this->grid[i][j][k] = this->grid[i+1][j][k];
          }
          this->grid[Grid_NbVoxelX-1][j][k].reset(new pcl::PointCloud<Point>());
        }
      }
      frameCenterX--;
      this->VoxelGridPosition[0]++;
    }

    // shift the voxel grid to the bottom
    while (frameCenterY - std::ceil(this->PointCloud_NbVoxelY / 2) <= 0)
    {
      for (int i = 0; i < this->Grid_NbVoxelX; i++)
      {
        for (int k = 0; k < this->Grid_NbVoxelZ; k++)
        {
          for (int j = this->Grid_NbVoxelY - 1; j > 0; j--)
          {
            this->grid[i][j][k] = this->grid[i][j-1][k];
          }
          this->grid[i][0][k].reset(new pcl::PointCloud<Point>());
        }
      }
      frameCenterY++;
      this->VoxelGridPosition[1]--;
//      cout << "bottom";
    }

    // shift the voxel grid to the top
    while (frameCenterY + std::ceil(this->PointCloud_NbVoxelY / 2) >= this->Grid_NbVoxelY - 1)
    {
      for (int i = 0; i < this->Grid_NbVoxelX; i++)
      {
        for (int k = 0; k < this->Grid_NbVoxelZ; k++)
        {
          for (int j = 0; j < this->Grid_NbVoxelY - 1; j++)
          {
            this->grid[i][j][k] = this->grid[i][j+1][k];
          }
          this->grid[i][Grid_NbVoxelY-1][k].reset(new pcl::PointCloud<Point>());
        }
      }
      frameCenterY--;
      this->VoxelGridPosition[1]++;
    }

    // shift the voxel grid to the "camera"
    while (frameCenterZ - std::ceil(this->PointCloud_NbVoxelZ / 2) <= 0)
    {
      for (int i = 0; i < this->Grid_NbVoxelX; i++)
      {
        for (int j = 0; j < this->Grid_NbVoxelY; j++)
        {
          for (int k = this->Grid_NbVoxelZ - 1; k > 0; k--)
          {
            this->grid[i][j][k] = this->grid[i][j][k-1];
          }
          this->grid[i][j][0].reset(new pcl::PointCloud<Point>());
        }
      }
      frameCenterZ++;
      this->VoxelGridPosition[2]--;
    }

    // shift the voxel grid to the "horizon"
    while (frameCenterZ + std::ceil(this->PointCloud_NbVoxelZ  / 2) >= this->Grid_NbVoxelZ - 1)
    {
      for (int i = 0; i < this->Grid_NbVoxelX; i++)
      {
        for (int j = 0; j < this->Grid_NbVoxelY; j++)
        {
          for (int k = 0; k < this->Grid_NbVoxelZ - 1; k++)
          {
            this->grid[i][j][k] = this->grid[i][j][k+1];
          }
          this->grid[i][j][Grid_NbVoxelZ-1].reset(new pcl::PointCloud<Point>());
        }
      }
      frameCenterZ--;
      this->VoxelGridPosition[2]++;
    }
  }

  // get points arround T
  pcl::PointCloud<Point>::Ptr Get(Eigen::Matrix<double, 6, 1> &T)
  {
    // compute the position of the new frame center in the grid
    int frameCenterX = std::floor(T[3] / this->VoxelSize) - this->VoxelGridPosition[0];
    int frameCenterY = std::floor(T[4] / this->VoxelSize) - this->VoxelGridPosition[1];
    int frameCenterZ = std::floor(T[5] / this->VoxelSize) - this->VoxelGridPosition[2];

    pcl::PointCloud<Point>::Ptr intersection(new pcl::PointCloud<Point>);

    // Get all voxel in intersection should use ceil here
    for (int i = frameCenterX - std::ceil(this->PointCloud_NbVoxelX / 2); i <= frameCenterX + std::ceil(this->PointCloud_NbVoxelX / 2); i++)
    {
      for (int j = frameCenterY - std::ceil(this->PointCloud_NbVoxelY / 2); j <= frameCenterY + std::ceil(this->PointCloud_NbVoxelY / 2); j++)
      {
        for (int k = frameCenterZ - std::ceil(this->PointCloud_NbVoxelZ / 2); k <= frameCenterZ + std::ceil(this->PointCloud_NbVoxelZ / 2); k++)
        {
          pcl::PointCloud<Point>:: Ptr voxel = this->grid[i][j][k];
          for (int l = 0; l < voxel->size(); l++)
          {
            intersection->push_back(voxel->at(l));
          }
        }
      }
    }
    return intersection;
  }

  // get all points
  pcl::PointCloud<Point>::Ptr Get()
  {
    pcl::PointCloud<Point>::Ptr intersection(new pcl::PointCloud<Point>);

    // Get all voxel in intersection should use ceil here
    for (unsigned int i = 0; i < Grid_NbVoxelX; i++)
    {
      for (unsigned int j = 0; j < Grid_NbVoxelY; j++)
      {
        for (unsigned int k = 0; k < Grid_NbVoxelZ; k++)
        {
          pcl::PointCloud<Point>:: Ptr voxel = this->grid[i][j][k];
          for (int l = 0; l < voxel->size(); l++)
          {
            intersection->push_back(voxel->at(l));
          }
        }
      }
    }
    return intersection;
  }

  // add some points to the grid
  void Add(pcl::PointCloud<Point>::Ptr pointcloud)
  {
    this->vizualisation.clear();

    // Voxel to filte because new points were add
    std::vector<std::vector<std::vector<int> > > voxelToFilter(Grid_NbVoxelX, std::vector<std::vector<int> >(Grid_NbVoxelY, std::vector<int>(Grid_NbVoxelZ, 0)));

    // Add points in the rolling grid
    int outlier = 0; // point who are not in the rolling grid
    for (int i = 0; i < pointcloud->size(); i++)
    {
      Point pts = pointcloud->points[i];
      // find the closest coordinate
      int cubeIdxX = std::floor(pts.x / this->VoxelSize) - this->VoxelGridPosition[0];
      int cubeIdxY = std::floor(pts.y / this->VoxelSize) - this->VoxelGridPosition[1];
      int cubeIdxZ = std::floor(pts.z / this->VoxelSize) - this->VoxelGridPosition[2];


      if (cubeIdxX >= 0 && cubeIdxX < this->Grid_NbVoxelX &&
        cubeIdxY >= 0 && cubeIdxY < this->Grid_NbVoxelY &&
        cubeIdxZ >= 0 && cubeIdxZ < this->Grid_NbVoxelZ)
      {
        voxelToFilter[cubeIdxX][cubeIdxY][cubeIdxZ] = 1;
        grid[cubeIdxX][cubeIdxY][cubeIdxZ]->push_back(pts);
        // for vizualization purpose only
        this->vizualisation.push_back(cubeIdxX);
      }
      else
      {
        this->vizualisation.push_back(-1);
        outlier++;
      }
    }

    // Filter the modified pointCloud
    pcl::VoxelGrid<Point> downSizeFilter;
    downSizeFilter.setLeafSize(LeafVoxelFilterSize, LeafVoxelFilterSize, LeafVoxelFilterSize); // one point per 20x20x20 cm
    for (int i = 0; i < this->Grid_NbVoxelX; i++)
    {
      for (int j = 0; j < this->Grid_NbVoxelY; j++)
      {
        for (int k = 0; k < this->Grid_NbVoxelZ; k++)
        {
          if (voxelToFilter[i][j][k] == 1)
          {
            pcl::PointCloud<Point>::Ptr tmp(new pcl::PointCloud<Point>());
            downSizeFilter.setInputCloud(grid[i][j][k]);
            downSizeFilter.filter(*tmp);
            grid[i][j][k] = tmp;
          }
        }
      }
    }
  }

  // return size
  int NumberOfPoints()
  {
    int size = 0;
    for (int i = 0; i < this->Grid_NbVoxelX; i++)
    {
      for (int j = 0; j < this->Grid_NbVoxelY; j++)
      {
        for (int k = 0; k < this->Grid_NbVoxelZ; k++)
        {
          size += this->grid[i][j][k]->size();
        }
      }
    }
    return size;
  }

  const unsigned int Get_VoxelSize() const
  {
    return this->VoxelSize;
  }

  void Set_VoxelSize(const unsigned int size)
  {
    this->VoxelSize = size;
  }

  void Get_Grid_NbVoxel(double nbVoxel[3]) const
  {
    nbVoxel[0] = this->Grid_NbVoxelX;
    nbVoxel[1] = this->Grid_NbVoxelY;
    nbVoxel[2] = this->Grid_NbVoxelZ;
  }

  void Set_Grid_NbVoxel(const double nbVoxel[3])
  {
    this->Grid_NbVoxelX = nbVoxel[0];
    this->Grid_NbVoxelY = nbVoxel[1];
    this->Grid_NbVoxelZ = nbVoxel[2];
    grid.resize(Grid_NbVoxelX);
    for (int i = 0; i < Grid_NbVoxelX; i++)
    {
      grid[i].resize(Grid_NbVoxelY);
      for (int j = 0; j < Grid_NbVoxelY; j++)
      {
        grid[i][j].resize(Grid_NbVoxelZ);
        for (int k = 0; k < Grid_NbVoxelZ; k++)
        {
          grid[i][j][k].reset(new pcl::PointCloud<Point>());
        }
      }
    }
  }

  void Get_PointCloud_NbVoxel(double nbVoxel[3]) const
  {
    nbVoxel[0] = this->PointCloud_NbVoxelX;
    nbVoxel[1] = this->PointCloud_NbVoxelY;
    nbVoxel[2] = this->PointCloud_NbVoxelZ;
  }
  void Set_PointCloud_NbVoxel(const double nbVoxel[3])
  {
    this->PointCloud_NbVoxelX = nbVoxel[0];
    this->PointCloud_NbVoxelY = nbVoxel[1];
    this->PointCloud_NbVoxelZ = nbVoxel[2];
  }

  const double Get_LeafVoxelFilterSize() const
  {
    return this->LeafVoxelFilterSize;
  }

  void Set_LeafVoxelFilterSize(const double size)
  {
    this->LeafVoxelFilterSize = size;
  }

private:
  // width of a voxel in m
  // since the voxels are cubic
  // their volume is VoxelSize^3
  unsigned int VoxelSize;

  // number of voxel / axis
  unsigned int Grid_NbVoxelX;
  unsigned int Grid_NbVoxelY;
  unsigned int Grid_NbVoxelZ;

  // Size of a pointcloud in voxel
  unsigned int PointCloud_NbVoxelX;
  unsigned int PointCloud_NbVoxelY;
  unsigned int PointCloud_NbVoxelZ;

  double LeafVoxelFilterSize;

  // grid of pointcloud
  std::vector<std::vector<std::vector<pcl::PointCloud<Point>::Ptr> > > grid;

  // Position of the VoxelGrid
  int VoxelGridPosition[3];

  // vizualisation
  std::vector<int> vizualisation;
};

//-----------------------------------------------------------------------------
int vtkSlam::RequestData(vtkInformation *vtkNotUsed(request),
vtkInformationVector **inputVector, vtkInformationVector *outputVector)
{
  // get info
  vtkInformation *outInfo0 = outputVector->GetInformationObject(0);
  vtkInformation *outInfo1 = outputVector->GetInformationObject(1);
  vtkInformation *outInfo2 = outputVector->GetInformationObject(2);
  vtkInformation *outInfo3 = outputVector->GetInformationObject(3);
  vtkInformation *outInfo4 = outputVector->GetInformationObject(4);
  vtkInformation *outInfo5 = outputVector->GetInformationObject(5);

  // get output
  vtkPolyData *output0 = vtkPolyData::SafeDownCast(
    outInfo0->Get(vtkDataObject::DATA_OBJECT()));
  vtkPolyData *output1 = vtkPolyData::SafeDownCast(
    outInfo1->Get(vtkDataObject::DATA_OBJECT()));
  vtkPolyData *output2 = vtkPolyData::SafeDownCast(
    outInfo2->Get(vtkDataObject::DATA_OBJECT()));
  vtkPolyData *output3 = vtkPolyData::SafeDownCast(
    outInfo3->Get(vtkDataObject::DATA_OBJECT()));
  vtkPolyData *output4 = vtkPolyData::SafeDownCast(
    outInfo4->Get(vtkDataObject::DATA_OBJECT()));
  vtkPolyData *output5 = vtkPolyData::SafeDownCast(
    outInfo5->Get(vtkDataObject::DATA_OBJECT()));

  // output 0 - Current Frame
  // add all debug information if displayMode == True
  if (DisplayMode = true)
  {
    this->DisplayLaserIdMapping(this->vtkCurrentFrame);
    this->DisplayRelAdv(this->vtkCurrentFrame);
    AddVectorToPolydataPoints<double, vtkDoubleArray>(this->Angles, "angles_line", this->vtkCurrentFrame);
    AddVectorToPolydataPoints<double, vtkDoubleArray>(this->DepthGap, "depth_gap", this->vtkCurrentFrame);
    AddVectorToPolydataPoints<double, vtkDoubleArray>(this->BlobScore, "blob_score", this->vtkCurrentFrame);
    AddVectorToPolydataPoints<int, vtkIntArray>(this->IsPointValid, "is_point_valid", this->vtkCurrentFrame);
    AddVectorToPolydataPoints<int, vtkIntArray>(this->Label, "keypoint_label", this->vtkCurrentFrame);
  }
  // get transform
  vtkSmartPointer<vtkTransform> transform = vtkSmartPointer<vtkTransform>::New();
  transform->Translate(Tworld[3], Tworld[4], Tworld[5]);
  transform->RotateX(Rad2Deg(Tworld[0]));
  transform->RotateY(Rad2Deg(Tworld[1]));
  transform->RotateZ(Rad2Deg(Tworld[2]));
  // create transform filter and transformt the current frame
  vtkSmartPointer<vtkTransformPolyDataFilter> transformFilter = vtkSmartPointer<vtkTransformPolyDataFilter>::New();
  transformFilter->SetInputData(this->vtkCurrentFrame);
  transformFilter->SetTransform(transform);
  transformFilter->Update();
  output0->ShallowCopy(transformFilter->GetOutput());

  // output 1 - Trajectory
  // create polyLine
  vtkSmartPointer<vtkPolyLine> polyLine = vtkSmartPointer<vtkPolyLine>::New();
  int NbPosition = Trajectory->GetNumberOfPoints();
  polyLine->GetPointIds()->SetNumberOfIds(NbPosition);
  for(unsigned int i = 0; i < NbPosition; i++)
  {
    polyLine->GetPointIds()->SetId(i,i);
  }
  // create cells for Trajectory
  vtkSmartPointer<vtkCellArray> cells = vtkSmartPointer<vtkCellArray>::New();
  cells->InsertNextCell(polyLine);
  Trajectory->SetLines(cells);
  output1->ShallowCopy(this->Trajectory);

  // output 2 - Edges Map
  vtkSmartPointer<vtkPolyData> EdgeMap = vtkPCLConversions::PolyDataFromPointCloud(this->EdgesPointsLocalMap->Get());
  output2->ShallowCopy(EdgeMap);

  // output 3 - Planar Points Map
  vtkSmartPointer<vtkPolyData> PlanarMap = vtkPCLConversions::PolyDataFromPointCloud(this->PlanarPointsLocalMap->Get());
  output3->ShallowCopy(PlanarMap);

  // output 4 - Planar Points Map
  vtkSmartPointer<vtkPolyData> BlobMap = vtkPCLConversions::PolyDataFromPointCloud(this->BlobsPointsLocalMap->Get());
  output4->ShallowCopy(BlobMap);

  // output 5 - Orientation
  // create polyLine
  vtkSmartPointer<vtkPolyLine> polyLine2 = vtkSmartPointer<vtkPolyLine>::New();
  int NbPosition2 = Orientation->GetNumberOfPoints();
  polyLine2->GetPointIds()->SetNumberOfIds(NbPosition2);
  for(unsigned int i = 0; i < NbPosition2; i++)
  {
    polyLine2->GetPointIds()->SetId(i,i);
  }
  // create cells for Trajectory
  vtkSmartPointer<vtkCellArray> cells2 = vtkSmartPointer<vtkCellArray>::New();
  cells2->InsertNextCell(polyLine2);
  Orientation->SetLines(cells2);
  output5->ShallowCopy(this->Orientation);

  return 1;
}

int vtkSlam::RequestDataObject(vtkInformation*,
  vtkInformationVector** inputVector ,
  vtkInformationVector* outputVector)
{

  // output 0 - Current Frame
  vtkInformation* outInfo0 = outputVector->GetInformationObject(0);
  vtkPolyData* output0 = vtkPolyData::SafeDownCast(
                                          outInfo0->Get( vtkDataObject::DATA_OBJECT() ) );
  if ( ! output0 )
  {
    output0 = vtkPolyData::New();
    outInfo0->Set( vtkDataObject::DATA_OBJECT(), output0 );
    output0->FastDelete();
    this->GetOutputPortInformation(0)->Set(
                                    vtkDataObject::DATA_EXTENT_TYPE(), output0->GetExtentType() );
  }

  // output 1 - Trajectory
  vtkInformation* outInfo1 = outputVector->GetInformationObject(1);
  vtkPolyData* output1 = vtkPolyData::SafeDownCast(
                                              outInfo1->Get( vtkDataObject::DATA_OBJECT() ) );
  if ( ! output1 )
  {
    output1 = vtkPolyData::New();
    outInfo1->Set( vtkDataObject::DATA_OBJECT(), output1 );
    output1->FastDelete();
    this->GetOutputPortInformation(1)->Set(
                                    vtkDataObject::DATA_EXTENT_TYPE(), output1->GetExtentType() );
  }

  // output 2 - Edges Map
  vtkInformation* outInfo2 = outputVector->GetInformationObject(2);
  vtkPolyData* output2 = vtkPolyData::SafeDownCast(
                                              outInfo2->Get( vtkDataObject::DATA_OBJECT() ) );
  if ( ! output2 )
  {
    output2 = vtkPolyData::New();
    outInfo2->Set( vtkDataObject::DATA_OBJECT(), output2 );
    output2->FastDelete();
    this->GetOutputPortInformation(1)->Set(
                                    vtkDataObject::DATA_EXTENT_TYPE(), output2->GetExtentType() );
  }

  // output 3 - Planar Points Map
  vtkInformation* outInfo3 = outputVector->GetInformationObject(3);
  vtkPolyData* output3 = vtkPolyData::SafeDownCast(
                                              outInfo3->Get( vtkDataObject::DATA_OBJECT() ) );
  if ( ! output3 )
  {
    output3 = vtkPolyData::New();
    outInfo3->Set( vtkDataObject::DATA_OBJECT(), output3 );
    output3->FastDelete();
    this->GetOutputPortInformation(1)->Set(
                                    vtkDataObject::DATA_EXTENT_TYPE(), output3->GetExtentType() );
  }
  return 1;
}

//----------------------------------------------------------------------------
int vtkSlam::RequestUpdateExtent(
    vtkInformation* vtkNotUsed(request),
    vtkInformationVector** inputVector,
    vtkInformationVector* vtkNotUsed(outputVector))
{
  int numInputPorts = this->GetNumberOfInputPorts();
  for (int i=0; i<numInputPorts; i++)
  {
    int numInputConnections = this->GetNumberOfInputConnections(i);
    for (int j=0; j<numInputConnections; j++)
    {
      vtkInformation* inputInfo = inputVector[i]->GetInformationObject(j);
      inputInfo->Set(vtkStreamingDemandDrivenPipeline::EXACT_EXTENT(), 1);
    }
  }
  return 1;
}

//-----------------------------------------------------------------------------
int vtkSlam::RequestInformation(vtkInformation *request,
                                     vtkInformationVector **inputVector,
                                     vtkInformationVector *outputVector)
{
  return this->Superclass::RequestInformation(request, inputVector, outputVector);
}

//-----------------------------------------------------------------------------
void vtkSlam::PrintSelf(ostream& os, vtkIndent indent)
{
  this->Superclass::PrintSelf(os, indent);
}

//-----------------------------------------------------------------------------
vtkSlam::vtkSlam()
{
  this->SetNumberOfInputPorts(0);
  this->SetNumberOfOutputPorts(6);
  this->ResetAlgorithm();
}

//-----------------------------------------------------------------------------
vtkSlam::~vtkSlam()
{
  delete this->EdgesPointsLocalMap;
  delete this->PlanarPointsLocalMap;
  delete this->BlobsPointsLocalMap;
}

//-----------------------------------------------------------------------------
void vtkSlam::GetWorldTransform(double* Tworld)
{
  // Rotation and translation relative
  Eigen::Matrix<double, 3, 3> Rw;

  // full rotation
  Rw = GetRotationMatrix(this->Tworld);

  double rx = std::atan2(Rw(2, 1), Rw(2, 2));
  double ry = -std::asin(Rw(2, 0));
  double rz = std::atan2(Rw(1, 0), Rw(0, 0));
//  std::vector<double> res(6, 0);
  
  Tworld[0] = rx;
  Tworld[1] = ry;
  Tworld[2] = rz;
  Tworld[3] = this->Tworld(3);
  Tworld[4] = this->Tworld(4);
  Tworld[5] = this->Tworld(5);

//  return res;
}

//-----------------------------------------------------------------------------
void vtkSlam::PrintParameters()
{
  std::cout << "Launching slam with parameters: " << std::endl;
  std::cout << "EgoMotionMaxIter: " << this->EgoMotionMaxIter << std::endl;
  std::cout << "MappingMaxIter: " << this->MappingMaxIter << std::endl;
  std::cout << "MappingIcpFrequence: " << this->MappingIcpFrequence << std::endl;
  std::cout << "EgoMotionIcpFrequence: " << this->EgoMotionIcpFrequence << std::endl;
  std::cout << "MaxEdgePerScanLine: " << this->MaxEdgePerScanLine << std::endl;
  std::cout << "MaxPlanarsPerScanLine: " << this->MaxPlanarsPerScanLine << std::endl;
  std::cout << "EdgeSinAngleThreshold: " << this->EdgeSinAngleThreshold << std::endl;
  std::cout << "PlaneSinAngleThreshold: " << this->PlaneSinAngleThreshold << std::endl;
  std::cout << "EdgeDepthGapThreshold: " << this->EdgeDepthGapThreshold << std::endl;
  std::cout << "Lambda0: " << this->Lambda0 << std::endl;
  std::cout << "LambdaRatio: " << this->LambdaRatio << std::endl;
  std::cout << "EgoMotionLineDistanceNbrNeighbors: " << this->EgoMotionLineDistanceNbrNeighbors << std::endl;
  std::cout << "EgoMotionLineDistancefactor: " << this->EgoMotionLineDistancefactor << std::endl;
  std::cout << "MappingMaxLineDistance: " << this->MappingMaxLineDistance << std::endl;
  std::cout << "MappingPlaneDistanceNbrNeighbors: " << this->MappingPlaneDistanceNbrNeighbors << std::endl;
  std::cout << "MappingPlaneDistancefactor1: " << this->MappingPlaneDistancefactor1 << std::endl;
  std::cout << "MappingPlaneDistancefactor2: " << this->MappingPlaneDistancefactor2 << std::endl;
  std::cout << "MappingMaxPlaneDistance: " << this->MappingMaxPlaneDistance << std::endl;
  std::cout << "MaxDistanceForICPMatching: " << this->MaxDistanceForICPMatching << std::endl;
  std::cout << "AngleResolution: " << this->AngleResolution << std::endl;
  std::cout << "EgoMotionMinimumLineNeighborRejection: " << this->EgoMotionMinimumLineNeighborRejection << std::endl;
  std::cout << "MappingMinimumLineNeighborRejection: " << this->MappingMinimumLineNeighborRejection << std::endl;
  std::cout << "MappingLineMaxDistInlier: " << this->MappingLineMaxDistInlier << std::endl;
}

//-----------------------------------------------------------------------------
void vtkSlam::ResetAlgorithm()
{
  this->DisplayMode = true; // switch to false to improve speed
  this->NeighborWidth = 3; // size indicated in Zhang paper
  this->EgoMotionIcpFrequence = 5;
  this->MappingIcpFrequence = 5;
  this->EgoMotionMaxIter = 3 * EgoMotionIcpFrequence; // So that 3 icp will be made
  this->MappingMaxIter = 3 * MappingIcpFrequence; // So that 3 icp will be made
  this->MinDistanceToSensor = 3.0;
  this->MaxEdgePerScanLine = 200;
  this->MaxPlanarsPerScanLine = 200;
  this->EdgeSinAngleThreshold = 0.85; // 85 degrees
  this->PlaneSinAngleThreshold = 0.5; // 50 degrees
  this->EdgeDepthGapThreshold = 0.02; // meters

  // Use dense planars point cloud for mapping
  this->FastSlam = true;
  this->MotionModel = true;
  this->Lambda0 = 0.1;
  this->LambdaRatio = 1.5;
  this->KalmanEstimator.ResetKalmanFilter();

  // EgoMotion
  // edges
  this->EgoMotionLineDistanceNbrNeighbors = 5;
  this->EgoMotionMinimumLineNeighborRejection = 2;
  this->EgoMotionLineDistancefactor = 5.0;
  this->EgoMotionMaxLineDistance = 0.10; // 10 cm

  // planes
  this->EgoMotionPlaneDistanceNbrNeighbors = 5;
  this->EgoMotionPlaneDistancefactor1 = 50.0;
  this->EgoMotionPlaneDistancefactor2 = 5.0;
  this->EgoMotionMaxPlaneDistance = 0.04; // 4 cm

  // Mapping
  // edges
  this->MappingLineDistanceNbrNeighbors = 15;
  this->MappingMinimumLineNeighborRejection = 5;
  this->MappingLineMaxDistInlier = 0.3; // 30 cm
  this->MappingLineDistancefactor = 5.0;
  this->MappingMaxLineDistance = 0.2; // 20 cm

  // planes
  this->MappingPlaneDistanceNbrNeighbors = 5;
  this->MappingPlaneDistancefactor1 = 50.0;
  this->MappingPlaneDistancefactor2 = 5.0;
  this->MappingMaxPlaneDistance = 0.04; // 4 cm

  // Blobs
  this->SphericityThreshold = 0.35;
  this->IncertitudeCoef = 3.0;
  this->UseBlob = false;

  this->MaxDistanceForICPMatching = 20.0; // 20 meters

  this->NbrFrameProcessed = 0;
  this->EgoMotionIterMade = 0;
  this->MappingIterMade = 0;
  this->MappingIterMade = 0;
  this->NLasers = 0;
  this->AngleResolution = Deg2Rad(0.4);  // azimutal resolution of the VLP-16. We add an extra 20 %
  this->LaserIdMapping.clear();
  this->LaserIdMapping.resize(0);
  this->FromVTKtoPCLMapping.clear();
  this->FromVTKtoPCLMapping.resize(0);
  this->FromPCLtoVTKMapping.clear();
  this->FromPCLtoVTKMapping.resize(this->NLasers);
  this->Angles.clear();
  this->Angles.resize(this->NLasers);
  this->DepthGap.clear();
  this->DepthGap.resize(this->NLasers);
  this->BlobScore.clear();
  this->BlobScore.resize(this->NLasers);
  this->IsPointValid.clear();
  this->IsPointValid.resize(this->NLasers);
  this->Label.clear();
  this->Label.resize(this->NLasers);
  this->Tworld << 0, 0, 0, 0, 0, 0;
  this->TworldList.clear();
  this->TworldList.resize(0);

  this->I3 = Eigen::Matrix3d::Identity();
  this->I6 = Eigen::Matrix<double, 6, 6>::Identity();

  EdgesPointsLocalMap = new RollingGrid();
  PlanarPointsLocalMap = new RollingGrid();
  BlobsPointsLocalMap = new RollingGrid();

  EdgesPointsLocalMap->Set_VoxelSize(10);
  PlanarPointsLocalMap->Set_VoxelSize(10);
  BlobsPointsLocalMap->Set_VoxelSize(10);

  double nbVoxel[3] = {50, 50, 50};
  EdgesPointsLocalMap->Set_Grid_NbVoxel(nbVoxel);
  PlanarPointsLocalMap->Set_Grid_NbVoxel(nbVoxel);
  BlobsPointsLocalMap->Set_Grid_NbVoxel(nbVoxel);

  nbVoxel[0] = nbVoxel[1] = nbVoxel[2] = 16;
  EdgesPointsLocalMap->Set_PointCloud_NbVoxel(nbVoxel);
  PlanarPointsLocalMap->Set_PointCloud_NbVoxel(nbVoxel);
  BlobsPointsLocalMap->Set_PointCloud_NbVoxel(nbVoxel);

  this->Set_RollingGrid_LeafVoxelFilterSize(0.4);

  // Represent the distance that the lidar has made during one sweep
  // if it is moving at a speed of 90 km/h and spinning at a rpm
  // of 600 rotation per minute
  this->MaxDistBetweenTwoFrames = (90.0 / 3.6) * (60.0 / 600.0);

  // output of the vtk filter
  this->Trajectory = vtkSmartPointer<vtkPolyData>::New();
  this->Orientation = vtkSmartPointer<vtkPolyData>::New();

  // add the required array in the trajectory
  vtkNew<vtkPoints> points;
  CreateDataArray<vtkDoubleArray>("time", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("roll", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("pitch", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("yaw", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("Mapping: intiale cost function", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("Mapping: final cost function", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("Variance Error", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("Mapping: edges used", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("Mapping: planes used", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("Mapping: blobs used", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("Mapping: total keypoints used", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("EgoMotion: intiale cost function", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("EgoMotion: final cost function", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("EgoMotion: edges used", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("EgoMotion: planes used", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("EgoMotion: blobs used", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("EgoMotion: total keypoints used", 0, this->Trajectory);
  this->Trajectory->SetPoints(points.GetPointer());

  // add the required array in the orientation
  vtkNew<vtkPoints> points2;
  CreateDataArray<vtkDoubleArray>("time", 0, this->Orientation);
  CreateDataArray<vtkDoubleArray>("X", 0, this->Orientation);
  CreateDataArray<vtkDoubleArray>("Y", 0, this->Orientation);
  CreateDataArray<vtkDoubleArray>("Z", 0, this->Orientation);
  this->Orientation->SetPoints(points2.GetPointer());
}

//-----------------------------------------------------------------------------
void vtkSlam::PrepareDataForNextFrame()
{
  // Reset the pcl format pointcloud to store the new frame
  this->pclCurrentFrame.reset(new pcl::PointCloud<Point>());
  for (unsigned int k = 0; k < this->NLasers; ++k)
  {
    this->pclCurrentFrameByScan[k].reset(new pcl::PointCloud<Point>());
  }

  this->CurrentEdgesPoints.reset(new pcl::PointCloud<Point>());
  this->CurrentPlanarsPoints.reset(new pcl::PointCloud<Point>());
  this->CurrentBlobsPoints.reset(new pcl::PointCloud<Point>());
  this->DensePlanarsPoints.reset(new pcl::PointCloud<Point>());
  this->MappingPlanarsPoints.reset(new pcl::PointCloud<Point>());

  // reset vtk <-> pcl id mapping
  this->FromVTKtoPCLMapping.clear();
  this->FromVTKtoPCLMapping.resize(0);
  this->FromPCLtoVTKMapping.clear();
  this->FromPCLtoVTKMapping.resize(this->NLasers);
  this->Angles.clear();
  this->Angles.resize(this->NLasers);
  this->DepthGap.clear();
  this->DepthGap.resize(this->NLasers);
  this->BlobScore.clear();
  this->BlobScore.resize(this->NLasers);
  this->IsPointValid.clear();
  this->IsPointValid.resize(this->NLasers);
  this->Label.clear();
  this->Label.resize(this->NLasers);

  this->EgoMotionIterMade = 0;
  this->MappingIterMade = 0;
}

//-----------------------------------------------------------------------------
void vtkSlam::SetSensorCalibration(int* mapping, int nbLaser)
{
  this->NLasers = nbLaser;
  this->LaserIdMapping.resize(this->NLasers);
  for (int i = 0; i < this->NLasers; ++i)
  {
    int indice = static_cast<int>(mapping[2 * i + 1]);
    this->LaserIdMapping[indice] = i;
  }
  this->pclCurrentFrameByScan.resize(this->NLasers);

  std::cout << "mapping is : " << std::endl;
  for (unsigned int k = 0; k < this->NLasers; ++k)
  {
    std::cout << k << " <--> " << this->LaserIdMapping[k] << std::endl;
  }
}

//-----------------------------------------------------------------------------
bool vtkSlam::GetIsSensorCalibrationProvided()
{
  return (this->NLasers > 0) && (this->LaserIdMapping.size() == this->NLasers);
}

//-----------------------------------------------------------------------------
template <typename T, typename Tvtk>
void vtkSlam::AddVectorToPolydataPoints(const std::vector<std::vector<T>>& vec, const char* name, vtkPolyData* pd)
{
  vtkSmartPointer<Tvtk> array = vtkSmartPointer<Tvtk>::New();
  array->Allocate(pd->GetNumberOfPoints());
  array->SetName(name);
  for (unsigned int k = 0; k < pd->GetNumberOfPoints(); ++k)
  {
    unsigned int scan = this->FromVTKtoPCLMapping[k].first;
    unsigned int index = this->FromVTKtoPCLMapping[k].second;
    array->InsertNextTuple1(vec[scan][index]);
  }
  pd->GetPointData()->AddArray(array);
}

//-----------------------------------------------------------------------------
void vtkSlam::DisplayLaserIdMapping(vtkSmartPointer<vtkPolyData> input)
{
  vtkDataArray* idsArray = input->GetPointData()->GetArray("laser_id");
  vtkSmartPointer<vtkIntArray> laserMappingArray = vtkSmartPointer<vtkIntArray>::New();
  laserMappingArray->Allocate(input->GetNumberOfPoints());
  laserMappingArray->SetName("laser_mapping");
  for (unsigned int k = 0; k < input->GetNumberOfPoints(); ++k)
  {
    int id = static_cast<int>(idsArray->GetTuple1(k));
    id = this->LaserIdMapping[id];
    laserMappingArray->InsertNextTuple1(id);
  }
  input->GetPointData()->AddArray(laserMappingArray);
}

//-----------------------------------------------------------------------------
void vtkSlam::DisplayRelAdv(vtkSmartPointer<vtkPolyData> input)
{
  vtkSmartPointer<vtkDoubleArray> relAdvArray = vtkSmartPointer<vtkDoubleArray>::New();
  relAdvArray->Allocate(input->GetNumberOfPoints());
  relAdvArray->SetName("relative_adv");
  for (unsigned int k = 0; k < input->GetNumberOfPoints(); ++k)
  {
    unsigned int scan = this->FromVTKtoPCLMapping[k].first;
    unsigned int index = this->FromVTKtoPCLMapping[k].second;
    relAdvArray->InsertNextTuple1(this->pclCurrentFrameByScan[scan]->points[index].intensity);
  }
  input->GetPointData()->AddArray(relAdvArray);
}

//-----------------------------------------------------------------------------
void vtkSlam::OnlyComputeKeypoints(vtkSmartPointer<vtkPolyData> newFrame)
{
  this->PrepareDataForNextFrame();
  this->ConvertAndSortScanLines(newFrame);
  this->ComputeKeyPoints(newFrame);
}

//-----------------------------------------------------------------------------
void vtkSlam::InitTworldUsingExternalData(double adjustedTime0, double rawTime0)
{

}

//-----------------------------------------------------------------------------
void vtkSlam::AddFrame(vtkPolyData* newFrame)
{
  if (!newFrame)
  {
    vtkGenericWarningMacro("Slam entry is a null pointer data");
    return;
  }
  this->vtkCurrentFrame = newFrame;

  // Check if the number of lasers has been set
  if (this->NLasers == 0)
  {
    vtkGenericWarningMacro("Frame added without specifying the number of lasers");
  }

  std::cout << "#########################################################" << std::endl
            << "Processing frame : " << this->NbrFrameProcessed << std:: endl
            << "#########################################################" << std::endl
            << std::endl;

  // Reset the members variables used during the last
  // processed frame so that they can be used again
  PrepareDataForNextFrame();

  // Update the kalman filter time
  double time = newFrame->GetPointData()->GetArray("adjustedtime")->GetTuple1(0) * 1e-6;
  this->KalmanEstimator.SetCurrentTime(time);

  // If the new frame is the first one we just add the
  // extracted keypoints into the map without running
  // odometry and mapping steps
  if (this->NbrFrameProcessed == 0)
  {
    // print parameters to provide some information
    this->PrintParameters();

    // Convert the new frame into pcl format and sort
    // the laser scan-lines by vertical angle
    this->ConvertAndSortScanLines(newFrame);

    // Compute the edges and planars keypoints
    this->ComputeKeyPoints(newFrame);

    // Check if external measures have been
    // provided to the slam algorithm
    if (this->ExternalMeasures)
    {
      vtkGenericWarningMacro("External data provided to the SLAM");
      double adjuestedTime0 = newFrame->GetPointData()->GetArray("adjustedtime")->GetTuple1(0) * 1e-6;
      double rawTime0 = static_cast<double>(newFrame->GetPointData()->GetArray("timestamp")->GetTuple1(0)) * 1e-6;
      this->InitTworldUsingExternalData(adjuestedTime0, rawTime0);
    }

    // Populate keypoints maps
    // edges
    EdgesPointsLocalMap->Roll(this->Tworld);
    EdgesPointsLocalMap->Add(this->CurrentEdgesPoints);

    // planes
    PlanarPointsLocalMap->Roll(this->Tworld);
    PlanarPointsLocalMap->Add(this->MappingPlanarsPoints);

    // Blobs
    BlobsPointsLocalMap->Roll(this->Tworld);
    BlobsPointsLocalMap->Add(this->CurrentBlobsPoints);

    // Current keypoints become previous ones
    this->PreviousEdgesPoints = this->CurrentEdgesPoints;
    this->PreviousPlanarsPoints = this->CurrentPlanarsPoints;
    this->PreviousBlobsPoints = this->CurrentBlobsPoints;
    this->NbrFrameProcessed++;

    return;
  }

  // Convert the new frame into pcl format and sort
  // the laser scan-lines by vertical angle
  InitTime();
  this->ConvertAndSortScanLines(vtkCurrentFrame);
  StopTimeAndDisplay("Sorting lines");

  // Compute the edges and planars keypoints
  InitTime();
  this->ComputeKeyPoints(vtkCurrentFrame);
  StopTimeAndDisplay("Keypoints extraction");

  // Perfom EgoMotion
  InitTime();
  this->ComputeEgoMotion();
  StopTimeAndDisplay("Ego-Motion");

  // Transform the current keypoints to the
  // referential of the sensor at the end of
  // frame acquisition
  InitTime();
  //this->TransformCurrentKeypointsToEnd();
  StopTimeAndDisplay("Undistortion");

  // Perform Mapping
  InitTime();
  this->Mapping();
  StopTimeAndDisplay("Mapping");

  // Current keypoints become previous ones
  this->PreviousEdgesPoints = this->CurrentEdgesPoints;
  this->PreviousPlanarsPoints = this->CurrentPlanarsPoints;
  this->PreviousBlobsPoints = this->CurrentBlobsPoints;
  this->NbrFrameProcessed++;

  // Information
  Eigen::Matrix<double, 3, 1> angles, trans;

  angles << Rad2Deg(this->Trelative(0)), Rad2Deg(this->Trelative(1)), Rad2Deg(this->Trelative(2));
  trans << this->Trelative(3), this->Trelative(4), this->Trelative(5);
  std::cout << "Odometry : " << std::endl;
  std::cout << "angles : " << std::endl << angles << std::endl;
  std::cout << "trans : " << std::endl << trans << std::endl;

  angles << Rad2Deg(this->Tworld(0)), Rad2Deg(this->Tworld(1)), Rad2Deg(this->Tworld(2));
  trans << this->Tworld(3), this->Tworld(4), this->Tworld(5);
  std::cout << "World : " << std::endl;
  std::cout << "angles : " << std::endl << angles << std::endl;
  std::cout << "trans : " << std::endl << trans << std::endl;


  // Update Filter output

  // Update trajectory points, the cells are construct in the request Data
  this->Trajectory->GetPoints()->InsertNextPoint(this->Tworld[3], this->Tworld[4], this->Tworld[5]);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("time"))->InsertNextValue(newFrame->GetPointData()->GetArray("timestamp")->GetTuple1(0));
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("pitch"))->InsertNextValue(this->Tworld[0]);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("roll"))->InsertNextValue(this->Tworld[1]);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("yaw"))->InsertNextValue(this->Tworld[2]);

  // Update orientation points, the cell are construct in the request data
  this->Orientation->GetPoints()->InsertNextPoint(this->Tworld[0], this->Tworld[1], this->Tworld[2]);
  static_cast<vtkDoubleArray*>(this->Orientation->GetPointData()->GetArray("time"))->InsertNextValue(newFrame->GetPointData()->GetArray("timestamp")->GetTuple1(0));
  static_cast<vtkDoubleArray*>(this->Orientation->GetPointData()->GetArray("X"))->InsertNextValue(this->Tworld[3]);
  static_cast<vtkDoubleArray*>(this->Orientation->GetPointData()->GetArray("Y"))->InsertNextValue(this->Tworld[4]);
  static_cast<vtkDoubleArray*>(this->Orientation->GetPointData()->GetArray("Z"))->InsertNextValue(this->Tworld[5]);

  // Indicate the filter has been modify
  this->Modified();
  return;
}

//-----------------------------------------------------------------------------
void vtkSlam::ConvertAndSortScanLines(vtkSmartPointer<vtkPolyData> input)
{
  // temp var
  double xL[3]; // in {L}
  Point yL; // in {L}

  // Get informations about input pointcloud
  vtkDataArray* lasersId = input->GetPointData()->GetArray("laser_id");
  vtkDataArray* time = input->GetPointData()->GetArray("timestamp");
  vtkPoints* Points = input->GetPoints();
  unsigned int Npts = input->GetNumberOfPoints();
  double t0 = static_cast<double>(time->GetTuple1(0));
  double t1 = static_cast<double>(time->GetTuple1(Npts - 1));
  this->FromVTKtoPCLMapping.resize(Npts);


  for (unsigned int index = 0; index < Npts; ++index)
  {
    // Get information about current point
    Points->GetPoint(index, xL);
    yL.x = xL[0];
    yL.y = xL[1];
    yL.z = xL[2];

    double relAdv = (static_cast<double>(time->GetTuple1(index)) - t0) / (t1 - t0);
    unsigned int id = static_cast<int>(lasersId->GetTuple1(index));
    id = this->LaserIdMapping[id];
    yL.intensity = relAdv;
    yL.normal_y = id;

    // add the current point to its corresponding laser scan
    this->pclCurrentFrame->push_back(yL);
    this->pclCurrentFrameByScan[id]->push_back(yL);
    this->FromVTKtoPCLMapping[index] = std::pair<int, int>(id, this->pclCurrentFrameByScan[id]->size() - 1);
    this->FromPCLtoVTKMapping[id].push_back(index);
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeKeyPoints(vtkSmartPointer<vtkPolyData> input)
{
  // Initialize the vectors with the correct length
  for (unsigned int k = 0; k < this->NLasers; ++k)
  {
    this->IsPointValid[k].resize(this->pclCurrentFrameByScan[k]->size(), 1);
    this->Label[k].resize(this->pclCurrentFrameByScan[k]->size(), 0);
    this->Angles[k].resize(this->pclCurrentFrameByScan[k]->size(),0);
    this->DepthGap[k].resize(this->pclCurrentFrameByScan[k]->size(), 0);
    this->BlobScore[k].resize(this->pclCurrentFrameByScan[k]->size(), 0);
  }

  // compute keypoints scores
  this->ComputeCurvature(input);

  // Invalid points with bad criteria
  this->InvalidPointWithBadCriteria();

  // labelize keypoints
  this->SetKeyPointsLabels(input);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeCurvature(vtkSmartPointer<vtkPolyData> input)
{
  Point currentPoint;
  Eigen::Matrix<double, 3, 1> X, U, V, Pleft, Pright;
  Eigen::Matrix<double, 3, 1> Nleft, Nright, centralPoint;
  Eigen::Matrix<double, 3, 1> dirGapLeft, dirGapRight;
  Eigen::Matrix<double, 3, 3> Dleft, Dright;
  double distCandidate;
  LineFitting leftLine;
  LineFitting rightLine;

  // loop over scans lines
  for (unsigned int scanLine = 0; scanLine < this->NLasers; ++scanLine)
  {
    // loop over points in the current scan line
    int Npts = this->pclCurrentFrameByScan[scanLine]->size();

    // if the line is almost empty, skip it
    if (Npts < 3 * this->NeighborWidth)
    {
      continue;
    }

    for (int index = this->NeighborWidth; index < Npts - this->NeighborWidth - 1; ++index)
    {
      // central point
      currentPoint = this->pclCurrentFrameByScan[scanLine]->points[index];
      centralPoint << currentPoint.x, currentPoint.y, currentPoint.z;

      // We will compute the line that fit the neighbors located
      // previously the current. We will do the same for the
      // neighbors located after the current points. We will then
      // compute the angle between these two lines as an approximation
      // of the "sharpness" of the current point.
      std::vector<Eigen::Matrix<double, 3, 1> > leftNeighbor;
      std::vector<Eigen::Matrix<double, 3, 1> > rightNeighbor;

      // Fill right and left neighborhood
      for (int j = index - this->NeighborWidth; j <= index + this->NeighborWidth; ++j)
      {
        currentPoint = this->pclCurrentFrameByScan[scanLine]->points[j];
        X << currentPoint.x, currentPoint.y, currentPoint.z;
        if (j < index)
          leftNeighbor.push_back(X);
        if (j > index)
          rightNeighbor.push_back(X);
      }

      // Fit line on the neighborhood
      leftLine.FitFast(leftNeighbor);
      rightLine.FitFast(rightNeighbor);


      Pleft = leftLine.Position;
      Nleft = leftLine.Direction;
      Dleft = leftLine.SemiDist;

      Pright = rightLine.Position;
      Nright = rightLine.Direction;
      Dright = rightLine.SemiDist;

      // Indicate if the left and right side
      // neighborhood of the current point is flat or not
      bool leftFlat = true;
      bool rightFlat = true;

      // Measurement of the gap
      double minDistLeft = std::numeric_limits<double>::max();
      double minDistRight = std::numeric_limits<double>::max();

      // Compute the fitting line and estimate
      // if the neighborhood is flat
      for (int j = index - this->NeighborWidth; j <= index + this->NeighborWidth; ++j)
      {
        currentPoint = this->pclCurrentFrameByScan[scanLine]->points[j];
        X << currentPoint.x, currentPoint.y, currentPoint.z;

        if (j < index)
        {
          distCandidate = (X - centralPoint).norm() / centralPoint.norm();
          if (distCandidate < minDistLeft)
          {
            minDistLeft = distCandidate;
            dirGapLeft = (X - centralPoint).normalized();
          }

          // if a point of the neighborhood is too far from
          // the fitting line we considere the neighborhood as
          // non flat
          double d = std::sqrt((X - Pleft).transpose() * Dleft * (X - Pleft));
          if (d > 0.02)
          {
            leftFlat = false;
          }
        }
          
        if (j > index)
        {
          distCandidate = (X - centralPoint).norm() / centralPoint.norm();
          if (distCandidate < minDistRight)
          {
            minDistRight = distCandidate;
            dirGapRight = (X - centralPoint).normalized();
          }

          // if a point of the neighborhood is too far from
          // the fitting line we considere the neighborhood as
          // non flat
          double d = std::sqrt((X - Pright).transpose() * Dright * (X - Pright));
          if (d > 0.02)
          {
            rightFlat = false;
          }
        }
      }

      double dist1 = 0;
      double dist2 = 0;

      // if both neighborhood are flat we can compute
      // the angle between them as an approximation of the
      // sharpness of the current point
      if (rightFlat && leftFlat)
      {
        this->Angles[scanLine][index] = std::abs((Nleft.cross(Nright)).norm()); // sin of angle actually

        dist1 = std::abs(dirGapLeft.cross(Nleft).norm()) * minDistLeft;
        dist2 = std::abs(dirGapRight.cross(Nright).norm()) * minDistRight;
      }
      // Here one side of the neighborhood is non flat
      // Hence it is not worth to estimate the sharpness.
      // Only the gap will be considered here.
      else if (rightFlat && !leftFlat)
      {
        dist1 = minDistLeft;
        dist2 = std::abs(dirGapRight.cross(Nright).norm()) * minDistRight;
      }
      else if (!rightFlat && leftFlat)
      {
        dist1 = std::abs(dirGapLeft.cross(Nleft).norm()) * minDistLeft;
        dist2 = minDistRight;
      }
      else
      {
        dist1 = 0.5 * minDistLeft; // 0.5: minor trust
        dist2 = 0.5 * minDistRight;
        this->BlobScore[scanLine][index] = 1;
      }
      this->DepthGap[scanLine][index] = std::max(dist1, dist2);
    }
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::InvalidPointWithBadCriteria()
{
  // Temporary variables used in the next loop
  Eigen::Matrix<double, 3, 1> dX, X, Xn, Xp, Xproj, dXproj;
  Eigen::Matrix<double, 3, 1> Y, Yn, Yp, dY;
  double dL, L, Ln, expectedLength, dLn, dLp, expectedLengthNeighbor;
  Point currentPoint, nextPoint, previousPoint;
  Point temp;

  // loop over scan lines
  for (unsigned int scanLine = 0; scanLine < this->NLasers; ++scanLine)
  {
    int Npts = this->pclCurrentFrameByScan[scanLine]->size();

    // if the line is almost empty, skip it
    if (Npts < 3 * this->NeighborWidth)
    {
      continue;
    }
    // invalidate first and last points
    for (int index = 0; index <= this->NeighborWidth; ++index)
    {
      this->IsPointValid[scanLine][index] = 0;
    }
    for (int index = Npts - 1 - this->NeighborWidth - 1; index < Npts; ++index)
    {
      this->IsPointValid[scanLine][index] = 0;
    }

    // loop over points into the scan line
    for (int index = this->NeighborWidth; index <  Npts - this->NeighborWidth - 1; ++index)
    {
      currentPoint = this->pclCurrentFrameByScan[scanLine]->points[index];
      nextPoint = this->pclCurrentFrameByScan[scanLine]->points[index + 1];
      previousPoint = this->pclCurrentFrameByScan[scanLine]->points[index - 1];
      X << currentPoint.x, currentPoint.y, currentPoint.z;
      Xn << nextPoint.x, nextPoint.y, nextPoint.z;
      Xp << previousPoint.x, previousPoint.y, previousPoint.z;
      dX = Xn - X;
      L = X.norm();
      Ln = Xn.norm();
      dLn = dX.norm();

      // the expected length between two firing of the same laser
      // depend on the distance and the angular resolution of the
      // sensor.
      expectedLength = 2.0 *  std::tan(this->AngleResolution / 2.0) * L;
      double ratioExpectedLength = 10.0;

      // if the length between the two firing
      // if more than n-th the expected length
      // it means that there is a gap. We now must
      // determine if the gap is due to the geometry of
      // the scene or if the gap is due to an occluded area
      if (dLn > ratioExpectedLength * expectedLength)
      {
        // Project the next point onto the
        // sphere of center 0 and radius =
        // norm of the current point. If the
        // gap has disappeared it means that
        // the gap was due to an occlusion
        Xproj = L / Ln * Xn;
        dXproj = Xproj - X;
        // it is a depth gap, invalidate the part which belong
        // to the occluded area (farest)
        // invalid next part
        if (L < Ln)
        {
          for (unsigned int i = index + 1; i <= index + this->NeighborWidth; ++i)
          {
            if (i > index + 1)
            {
              temp = this->pclCurrentFrameByScan[scanLine]->points[i - 1];
              Yp << temp.x, temp.y, temp.z;
              temp = this->pclCurrentFrameByScan[scanLine]->points[i];
              Y << temp.x, temp.y, temp.z;
              dY = Y - Yp;
              expectedLengthNeighbor = 2.0 *  std::tan(this->AngleResolution / 2.0) * Y.norm();
              // if there is a gap in the neihborhood
              // we do not invalidate the rest of neihborhood
              if (dY.norm() > ratioExpectedLength * expectedLength)
              {
                break;
              }
            }
            this->IsPointValid[scanLine][i] = 0;
          }
        }
        // invalid previous part
        else
        {
          for (unsigned int i = index - this->NeighborWidth; i <= index; ++i)
          {
            if (i < index)
            {
              temp = this->pclCurrentFrameByScan[scanLine]->points[i + 1];
              Yn << temp.x, temp.y, temp.z;
              temp = this->pclCurrentFrameByScan[scanLine]->points[i];
              Y << temp.x, temp.y, temp.z;
              dY = Yn - Y;
              expectedLengthNeighbor = 2.0 *  std::tan(this->AngleResolution / 2.0) * Y.norm();
              // if there is a gap in the neihborhood
              // we do not invalidate the rest of neihborhood
              if (dY.norm() > ratioExpectedLength * expectedLength)
              {
                break;
              }
            }
            this->IsPointValid[scanLine][i] = 0;
          }
        }
      }
      // Invalid points which are too close from the sensor
      if (L < this->MinDistanceToSensor)
      {
        this->IsPointValid[scanLine][index] = 0;
      }

      // Invalid points which are on a planar
      // surface nearly parallel to the laser
      // beam direction
      dLp = (X - Xp).norm();
      if ((dLp > 1 / 4.0 * ratioExpectedLength * expectedLength) && (dLn > 1 / 4.0 * ratioExpectedLength * expectedLength))
      {
        this->IsPointValid[scanLine][index] = 0;
      }
    }
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::SetKeyPointsLabels(vtkSmartPointer<vtkPolyData> input)
{
  std::vector<std::pair<int, int> > edgesIndex;
  std::vector<std::pair<int, int> > planarIndex;
  std::vector<std::pair<int, int> > blobIndex;

  std::cout << "extracting with: " << this->MaxEdgePerScanLine << " MaxEdgePerScanLine" << std::endl;
  std::cout << "extracting with: " << this->MaxPlanarsPerScanLine << " MaxPlanarsPerScanLine" << std::endl;

  // loop over the scan lines
  for (unsigned int scanLine = 0; scanLine < this->NLasers; ++scanLine)
  {
    int Npts = this->pclCurrentFrameByScan[scanLine]->size();
    unsigned int nbrEdgePicked = 0;
    unsigned int nbrPlanarPicked = 0;

    // We split the validity of points between the edges
    // keypoints and planar keypoints. This allows to take
    // some points as planar keypoints even if they are close
    // to an edge keypoint. 
    std::vector<int> IsPointValidForPlanar = this->IsPointValid[scanLine];

    // if the line is almost empty, skip it
    if (Npts < 3 * this->NeighborWidth)
    {
      continue;
    }

    // Sort the curvature score in a decreasing order
    std::vector<size_t> sortedDepthGapIdx = sortIdx<double>(this->DepthGap[scanLine]);
    std::vector<size_t> sortedAnglesIdx = sortIdx<double>(this->Angles[scanLine]);
    std::vector<size_t> sortedBlobScoreIdx = sortIdx<double>(this->BlobScore[scanLine]);

    double depthGap = 0;
    double sinAngle = 0;
    double blobScore = 0;
    int index = 0;

    if (!this->FastSlam)
    {
      for (int k = 0; k < Npts; ++k)
      {
        // if the point is invalid continue
        if (this->IsPointValid[scanLine][k] == 0)
        {
          continue;
        }

        this->DensePlanarsPoints->push_back(this->pclCurrentFrameByScan[scanLine]->points[k]);
      }
    }

    // Edges using depth gap
    for (int k = 0; k < Npts; ++k)
    {
      index = sortedDepthGapIdx[k];
      depthGap = this->DepthGap[scanLine][index];

      // max keypoints reached
      if (nbrEdgePicked >= this->MaxEdgePerScanLine)
      {
        break;
      }

      // thresh
      if (depthGap < this->EdgeDepthGapThreshold)
      {
        break;
      }

      // if the point is invalid continue
      if (this->IsPointValid[scanLine][index] == 0)
      {
        continue;
      }

      // else indicate that the point is an edge
      this->Label[scanLine][index] = 4;
      edgesIndex.push_back(std::pair<int, int>(scanLine, index));
      nbrEdgePicked++;
      //IsPointValidForPlanar[index] = 0;

      // invalid its neighborhod
      int indexBegin = index - this->NeighborWidth + 1;
      int indexEnd = index + this->NeighborWidth - 1;
      indexBegin = std::max(0, indexBegin);
      indexEnd = std::min(Npts - 1, indexEnd);
      for (int j = indexBegin; j <= indexEnd; ++j)
      {
        this->IsPointValid[scanLine][j] = 0;
      }
    }

    // Edges using angles
    for (int k = 0; k < Npts; ++k)
    {
      index = sortedAnglesIdx[k];
      sinAngle = this->Angles[scanLine][index];

      // max keypoints reached
      if (nbrEdgePicked >= this->MaxEdgePerScanLine)
      {
        break;
      }

      // thresh
      if (sinAngle < this->EdgeSinAngleThreshold)
      {
        break;
      }

      // if the point is invalid continue
      if (this->IsPointValid[scanLine][index] == 0)
      {
        continue;
      }

      // else indicate that the point is an edge
      this->Label[scanLine][index] = 4;
      edgesIndex.push_back(std::pair<int, int>(scanLine, index));
      nbrEdgePicked++;
      //IsPointValidForPlanar[index] = 0;

      // invalid its neighborhod
      int indexBegin = index - this->NeighborWidth;
      int indexEnd = index + this->NeighborWidth;
      indexBegin = std::max(0, indexBegin);
      indexEnd = std::min(Npts - 1, indexEnd);
      for (int j = indexBegin; j <= indexEnd; ++j)
      {
        this->IsPointValid[scanLine][j] = 0;
      }
    }

    // Blobs Points
    for (int k = 0; k < Npts; k = k + 3)
    {
      // else indicate that the point is a blob
      if (this->Label[scanLine][index] == 0)
      {
        this->Label[scanLine][k] = 3;
      }
      blobIndex.push_back(std::pair<int, int>(scanLine, k));
    }

    // Planes
    for (int k = Npts - 1; k >= 0; --k)
    {
      index = sortedAnglesIdx[k];
      sinAngle = this->Angles[scanLine][index];

      // max keypoints reached
      if (nbrPlanarPicked >= this->MaxPlanarsPerScanLine)
      {
        //break;
      }

      // thresh
      if (sinAngle > this->PlaneSinAngleThreshold)
      {
        break;
      }

      // if the point is invalid continue
      if (IsPointValidForPlanar[index] == 0)
      {
        continue;
      }

      // else indicate that the point is a planar one
      if ((this->Label[scanLine][index] != 4) && (this->Label[scanLine][index] != 3))
        this->Label[scanLine][index] = 2;
      planarIndex.push_back(std::pair<int, int>(scanLine, index));
      IsPointValidForPlanar[index] = 0;
      this->IsPointValid[scanLine][index] = 0;

      // Invalid its neighbor so that we don't have too
      // many planar keypoints in the same region. This is
      // required because of the k-nearest search + plane
      // approximation realized in the odometry part. Indeed,
      // if tall the planar points are on the same scan line the
      //  problem is degenerated since all the points are distributed
      // on a line.
      int indexBegin = index - 4;
      int indexEnd = index + 4;
      indexBegin = std::max(0, indexBegin);
      indexEnd = std::min(Npts - 1, indexEnd);
      for (int j = indexBegin; j <= indexEnd; ++j)
      {
        IsPointValidForPlanar[j] = 0;
      }
      nbrPlanarPicked++;
    }
  }

  // add keypoints in increasing scan id order
  std::sort(edgesIndex.begin(), edgesIndex.end());
  std::sort(planarIndex.begin(), planarIndex.end());
  std::sort(blobIndex.begin(), blobIndex.end());

  for (unsigned int k = 0; k < edgesIndex.size(); ++k)
  {
    this->CurrentEdgesPoints->push_back(this->pclCurrentFrameByScan[edgesIndex[k].first]->points[edgesIndex[k].second]);
  }
  for (unsigned int k = 0; k < planarIndex.size(); ++k)
  {
    this->CurrentPlanarsPoints->push_back(this->pclCurrentFrameByScan[planarIndex[k].first]->points[planarIndex[k].second]);
  }
  for (unsigned int k = 0; k < blobIndex.size();  ++k)
  {
    this->CurrentBlobsPoints->push_back(this->pclCurrentFrameByScan[blobIndex[k].first]->points[blobIndex[k].second]);
  }

  if (this->FastSlam)
  {
    this->MappingPlanarsPoints = this->CurrentPlanarsPoints;
  }
  else
  {
    // Apply a voxel grid filter on the Dense planars points
    pcl::VoxelGrid<Point> downSizeFilter;
    pcl::PointCloud<Point> tempCloud;
    downSizeFilter.setInputCloud(this->DensePlanarsPoints);
    downSizeFilter.setLeafSize(0.1, 0.1, 0.1);
    downSizeFilter.filter(tempCloud);

    *this->MappingPlanarsPoints += tempCloud;
  }

  std::cout << "Extracted : " << this->CurrentEdgesPoints->size() << " : edges points" << std::endl;
  std::cout << "Extracted : " << this->CurrentPlanarsPoints->size() << " : planars points" << std::endl;
  std::cout << "Extracted : " << this->CurrentBlobsPoints->size() << " : Blobs points" << std::endl;
  std::cout << "Extracted : " << this->MappingPlanarsPoints->size() << " : mapping planars points" << std::endl;
}

//-----------------------------------------------------------------------------
void vtkSlam::TransformToStart(Point& pi, Point& pf, Eigen::Matrix<double, 6, 1>& T)
{
  // Remember, the intensity is the relative time
  // Hence s worth the relTime
  double s = pi.intensity;
  Eigen::Matrix<double, 3, 1> P0, P1;
  P0 << pi.x, pi.y, pi.z;
  this->TransformToStart(P0, P1, s, T);
  pf.x = P1(0);
  pf.y = P1(1);
  pf.z = P1(2);
}

//-----------------------------------------------------------------------------
void vtkSlam::TransformToStart(Eigen::Matrix<double, 3, 1>& Xi, Eigen::Matrix<double, 3, 1>& Xf, double s, Eigen::Matrix<double, 6, 1>& T)
{
  // Linearly interpolate the motion estimation depending
  // on the time at which the point has been acquired. This
  // interpolation assumes that during a sweep of the lidar the
  // angular velocity and the velocity are constant. This assumption
  // is pertinent as long as the sensor do not undergone strong
  // acceleration
  Eigen::Matrix<double, 6, 1> sT = s * T;

  Eigen::Matrix<double, 3, 3> R;
  Eigen::Matrix<double, 3, 1> dT;
  
  // full rotation
  R = GetRotationMatrix(sT);
  dT << sT(3), sT(4), sT(5);

  // Express the current point acquired at time t1
  // in the referential of the sensor at time t0.
  Xf = R * Xi + dT;
}

//-----------------------------------------------------------------------------
void vtkSlam::TransformToEnd(Point& pi, Point& pf, Eigen::Matrix<double, 6, 1>& T)
{
  // first transform to start
  Point ptemp;
  this->TransformToStart(pi, ptemp, T);

  // then transform to end using the estimated transformation
  // since the first transformation has distorted the point cloud
  // there is no need to interpolate again
  Eigen::Matrix<double, 3, 3> R;
  Eigen::Matrix<double, 3, 1> dT, P0, P1;
  P0 << ptemp.x, ptemp.y, ptemp.z;

  R = GetRotationMatrix(T);
  dT << T(3), T(4), T(5);
  P1 = R.transpose() * (P0 - dT);
  pf.x = P1(0);
  pf.y = P1(1);
  pf.z = P1(2);
}

//-----------------------------------------------------------------------------
void vtkSlam::TransformCurrentKeypointsToEnd()
{
  Point currentPoint, transformedPoint;
  // transform edges and planars keypoints
  for (unsigned int k = 0; k < this->CurrentEdgesPoints->size(); ++k)
  {
    currentPoint = this->CurrentEdgesPoints->points[k];
    this->TransformToEnd(currentPoint, transformedPoint, this->Trelative);
    this->CurrentEdgesPoints->points[k] = transformedPoint;
  }
  for (unsigned int k = 0; k < this->CurrentPlanarsPoints->size(); ++k)
  {
    currentPoint = this->CurrentPlanarsPoints->points[k];
    this->TransformToEnd(currentPoint, transformedPoint, this->Trelative);
    this->CurrentPlanarsPoints->points[k] = transformedPoint;
  }
  // if fast slam is set to true, the mapping planars keypoints
  // are the same than the ego motion one and have already been
  // transformed
  if (!this->FastSlam)
  {
    for (unsigned int k = 0; k < this->MappingPlanarsPoints->size(); ++k)
    {
      currentPoint = this->MappingPlanarsPoints->points[k];
      this->TransformToEnd(currentPoint, transformedPoint, this->Trelative);
      this->MappingPlanarsPoints->points[k] = transformedPoint;
    }
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::TransformToWorld(Point& p, Eigen::Matrix<double, 6, 1>& T)
{
  // Rotation and translation and points
  Eigen::Matrix<double, 3, 3> Rw;
  Eigen::Matrix<double, 3, 1> Tw;
  Eigen::Matrix<double, 3, 1> P;

  Rw = GetRotationMatrix(T);
  Tw << T(3), T(4), T(5);
  P << p.x, p.y, p.z;

  P = Rw * P + Tw;

  p.x = P(0);
  p.y = P(1);
  p.z = P(2);
}

//-----------------------------------------------------------------------------
void vtkSlam::FindEdgeLineMatch(Point p, pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousEdges,
                                std::vector<int>& matchEdgeIndex1, std::vector<int>& matchEdgeIndex2, int currentEdgeIndex,
                                Eigen::Matrix<double, 3, 3> R, Eigen::Matrix<double, 3, 1> dT)
{
  // transform point using current estimation
  Eigen::Matrix<double, 3, 1> P;
  P << p.x, p.y, p.z;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);

  Point p1, p2;
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;
  
  // Search the nearests points of the current point reprojected
  // nearestIndex is the index of the nearest pointsd found
  // nearestDist is their corresponding distances
  kdtreePreviousEdges->nearestKSearch(p, 1, nearestIndex, nearestDist);

  // closest point index
  int closestPointIndex = -1;
  int secondPointIndex = -1;
  matchEdgeIndex1[currentEdgeIndex] = -1;
  matchEdgeIndex2[currentEdgeIndex] = -1;

  // max distance allowed between two frames. It depends on the
  // sensor speed and the sensor RPM. It is not automatically computed
  // the value of MaxDistBetweenTwoFrames should be set. By default
  // it is set to 2.5 meters (90 km/h at 600 RPM)
  if (static_cast<double>(nearestDist[0]) < this->MaxDistBetweenTwoFrames)
  {
    // take the closest point
    closestPointIndex = nearestIndex[0];
    p1 = this->PreviousEdgesPoints->points[closestPointIndex];

    // Avoid SegFault when the kd-tree doesn't find the cloest point
    // it is due to a point p with -1.#IND values sometimes
    if(closestPointIndex > this->PreviousEdgesPoints->size()-1)
    {
      std::cout << "Edges correspondances error" << std::endl;
      std::cout << "closestPointInd : " << closestPointIndex << std::endl;
      std::cout << "point : [" << p.x << ";" << p.y << ";" << p.z << "]" << std::endl;
      return;
    }

    // get the ID of the closest scan line of the closest point
    int iD = p1.normal_y;

    // VLP-16: 2 scan line gap
    // VLP-32: 4 scan line gap
    // HDL-64: 8 scan line gap
    int maxScanIdStep = this->NLasers / 8;
    double minDist = 2.0 * this->MaxDistBetweenTwoFrames;

    // now find the second closest point that belong to an other
    // scan line. The keypoints are sorted using scan id.
    for (int pointIndex = closestPointIndex + 1; pointIndex < this->PreviousEdgesPoints->size(); ++pointIndex)
    {
      if (pointIndex > this->PreviousEdgesPoints->size() - 1)
      {
        break;
      }

      Point candidate = this->PreviousEdgesPoints->points[pointIndex];
      bool shouldSkip = (static_cast<int>(candidate.normal_y) == iD);
      bool shouldBreak = static_cast<int>(candidate.normal_y) > iD + maxScanIdStep;

      if (shouldBreak)
      {
        break;
      }
      if (!shouldSkip)
      {
        // compute the distance
        double dist = (p.x - candidate.x) * (p.x - candidate.x) + (p.y - candidate.y) * (p.y - candidate.y) + (p.z - candidate.z) * (p.z - candidate.z);
        if (dist < minDist)
        {
          minDist = dist;
          secondPointIndex = pointIndex;
        }
      }
    }
    for (int pointIndex = closestPointIndex - 1; pointIndex >= 0; --pointIndex)
    {
      if (pointIndex < 0)
      {
        break;
      }

      Point candidate = this->PreviousEdgesPoints->points[pointIndex];
      bool shouldSkip = (static_cast<int>(candidate.normal_y) == iD);
      bool shouldBreak = static_cast<int>(candidate.normal_y) < iD - maxScanIdStep;
      if (shouldBreak)
      {
        break;
      }
      if (!shouldSkip)
      {
        // compute the distance
        double dist = (p.x - candidate.x) * (p.x - candidate.x) + (p.y - candidate.y) * (p.y - candidate.y) + (p.z - candidate.z) * (p.z - candidate.z);

        if (dist < minDist)
        {
          minDist = dist;
          secondPointIndex = pointIndex;
        }
      }
    }
  }
  else
  {
    return;
  }

  if (secondPointIndex == -1)
  {
    return;
  }

  matchEdgeIndex1[currentEdgeIndex] = closestPointIndex;
  matchEdgeIndex2[currentEdgeIndex] = secondPointIndex;
  return;
}

//-----------------------------------------------------------------------------
void vtkSlam::FindPlaneMatch(Point p, pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousPlanes,
                      std::vector<int>& matchPlaneIndex1, std::vector<int>& matchPlaneIndex2,
                      std::vector<int>& matchPlaneIndex3, int currentPlaneIndex,
                      Eigen::Matrix<double, 3, 3> R, Eigen::Matrix<double, 3, 1> dT)
{
  // transform point using current estimation
  Eigen::Matrix<double, 3, 1> P;
  P << p.x, p.y, p.z;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);

  Point p1, p2, p3;
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;

  // Here we are looking for 3 points to define a plane. The first one is the closest point 
  // of the current planar point. The two others are the minPoint in the same scan and in another scan
  int closestPointIndex = -1;
  int secondPointIndex = -1;
  int thirdPointIndex = -1;

  // reset previous index
  matchPlaneIndex1[currentPlaneIndex] = -1;
  matchPlaneIndex2[currentPlaneIndex] = -1;
  matchPlaneIndex3[currentPlaneIndex] = -1;

  // Find the closest point
  kdtreePreviousPlanes->nearestKSearch(p, 1, nearestIndex, nearestDist);

  // max distance allowed between two frames. It depends on the
  // sensor speed and the sensor RPM. It is not automatically computed
  // the value of MaxDistBetweenTwoFrames should be set. By default
  // it is set to 2.5 meters (90 km/h at 600 RPM)
  if (static_cast<double>(nearestDist[0]) < 2.0 * this->MaxDistBetweenTwoFrames)
  {
    closestPointIndex = nearestIndex[0];
    if(closestPointIndex > this->PreviousPlanarsPoints->size() - 1 || closestPointIndex < 0)
    {
      std::cout << "Flat correspondances error" << std::endl;
      std::cout << "closestPointInd : " << closestPointIndex << std::endl;
      std::cout << "point : [" << p.x << ";" << p.y << ";" << p.z << "]" << std::endl;
      return;
    }

    p1 = this->PreviousPlanarsPoints->points[closestPointIndex];

    // We get the id of the closest scan laser line
    int iD = p1.normal_y; 

    // VLP-16: 2 scan line gap
    // VLP-32: 4 scan line gap
    // HDL-64: 8 scan line gap
    int maxScanIdStep = this->NLasers / 8;
    double minDist2 = 4.0 * this->MaxDistBetweenTwoFrames;
    double minDist3 = 4.0 * this->MaxDistBetweenTwoFrames;

    // now find the second closest point that belong to an other
    // scan line. The keypoints are sorted using scan id.
    for (int pointIndex = closestPointIndex + 1; pointIndex < this->PreviousPlanarsPoints->size(); ++pointIndex)
    {
      if (pointIndex > this->PreviousEdgesPoints->size() - 1)
      {
        break;
      }

      Point candidate = this->PreviousPlanarsPoints->points[pointIndex];
      bool isSameScan = (static_cast<int>(candidate.normal_y) == iD);
      bool shouldBreak = static_cast<int>(candidate.normal_y) > iD + maxScanIdStep;

      if (shouldBreak)
      {
        break;
      }

      // compute the distance
      double dist = (p.x - candidate.x) * (p.x - candidate.x) + (p.y - candidate.y) * (p.y - candidate.y) + (p.z - candidate.z) * (p.z - candidate.z);
      if (isSameScan)
      {
        if (dist < minDist2)
        {
          minDist2 = dist;
          secondPointIndex = pointIndex;
        }
      }
      else
      {
        if (dist < minDist3)
        {
          minDist3 = dist;
          thirdPointIndex = pointIndex;
        }
      }
    }
    // left side
    for (int pointIndex = closestPointIndex - 1; pointIndex >= 0; --pointIndex)
    {
      if (pointIndex < 0)
      {
        break;
      }

      Point candidate = this->PreviousPlanarsPoints->points[pointIndex];
      bool isSameScan = (static_cast<int>(candidate.normal_y) == iD);
      bool shouldBreak = static_cast<int>(candidate.normal_y) < iD - maxScanIdStep;

      if (shouldBreak)
      {
        break;
      }

      // compute the distance
      double dist = (p.x - candidate.x) * (p.x - candidate.x) + (p.y - candidate.y) * (p.y - candidate.y) + (p.z - candidate.z) * (p.z - candidate.z);
      if (isSameScan)
      {
        if (dist < minDist2)
        {
          minDist2 = dist;
          secondPointIndex = pointIndex;
        }
      }
      else
      {
        if (dist < minDist3)
        {
          minDist3 = dist;
          thirdPointIndex = pointIndex;
        }
      }
    }
  }

  matchPlaneIndex1[currentPlaneIndex] = closestPointIndex;
  matchPlaneIndex2[currentPlaneIndex] = secondPointIndex;
  matchPlaneIndex3[currentPlaneIndex] = thirdPointIndex;
  return;
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeLineDistanceParameters(std::vector<int>& matchEdgeIndex1, std::vector<int>& matchEdgeIndex2, unsigned int edgeIndex)
{
  Point p, p1, p2;
  Eigen::Matrix<double, 3, 1> P1, P2, n, X;
  Eigen::Matrix<double, 3, 3> A;
  
  // if the current keypoint has not corresponding line match
  if ((matchEdgeIndex1[edgeIndex] == -1) || (matchEdgeIndex2[edgeIndex] == -1))
  {
    return;
  }

  p = this->CurrentEdgesPoints->points[edgeIndex];
  p1 = this->PreviousEdgesPoints->points[matchEdgeIndex1[edgeIndex]];
  p2 = this->PreviousEdgesPoints->points[matchEdgeIndex2[edgeIndex]];
  X << p.x, p.y, p.z;
  P1 << p1.x, p1.y, p1.z;
  P2 << p2.x, p2.y, p2.z;

  // n is the director vector of the line
  n = (P2 - P1).normalized();

  // A = (I-n*n.t).t * (I-n*n.t) = (I - n*n.t)^2
  // since (I-n*n.t) is a symmetric matrix.
  A = (this->I3 - n * n.transpose());
  A = A.transpose() * A;

  // it would be the case if P1 = P2 For instance
  // if the sensor has some dual returns that hit the same point
  if (!vtkMath::IsFinite(A(0, 0)))
  {
    return;
  }

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(P1);
  this->Xvalues.push_back(X);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputePlaneDistanceParameters(std::vector<int>& matchPlaneIndex1, std::vector<int>& matchPlaneIndex2, std::vector<int>& matchPlaneIndex3, unsigned int planarIndex)
{
  Point p, p1, p2, p3;
  Eigen::Matrix<double, 3, 1> P1, P2, P3, n, X;
  Eigen::Matrix<double, 3, 3> A;
  
  // if the current keypoint has not corresponding
  // plane match
  if ((matchPlaneIndex1[planarIndex] == -1) || (matchPlaneIndex2[planarIndex] == -1) || (matchPlaneIndex3[planarIndex] == -1))
  {
    return;
  }

  if (matchPlaneIndex1[planarIndex] < 0 || matchPlaneIndex2[planarIndex] < 0 || matchPlaneIndex3[planarIndex] < 0)
  {
    return;
  }
  if (matchPlaneIndex1[planarIndex] >= this->PreviousPlanarsPoints->size() ||
      matchPlaneIndex2[planarIndex] >= this->PreviousPlanarsPoints->size() ||
      matchPlaneIndex3[planarIndex] >= this->PreviousPlanarsPoints->size())
  {
    return;
  }

  p = this->CurrentPlanarsPoints->points[planarIndex];
  p1 = this->PreviousPlanarsPoints->points[matchPlaneIndex1[planarIndex]];
  p2 = this->PreviousPlanarsPoints->points[matchPlaneIndex2[planarIndex]];
  p3 = this->PreviousPlanarsPoints->points[matchPlaneIndex3[planarIndex]];
  X << p.x, p.y, p.z;
  P1 << p1.x, p1.y, p1.z;
  P2 << p2.x, p2.y, p2.z;
  P3 << p3.x, p3.y, p3.z;

  // n is the director vector of the line
  n = ((P3 - P1).cross(P2 - P1)).normalized();

  // A = n*n.t
  A = n * n.transpose();

  // it would be the case if P1 = P2, P1 = P3
  // or P3 = P2. For instance if the sensor has
  // some dual returns that hit the same point
  if (!vtkMath::IsFinite(A(0, 0)))
  {
    return;
  }

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(P1);
  this->Xvalues.push_back(X);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeLineDistanceParametersAccurate(pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousEdges, Eigen::Matrix<double, 3, 3>& R,
                                                    Eigen::Matrix<double, 3, 1>& dT, Point p, std::string step)
{
  // number of neighbors edge points required to approximate
  // the corresponding egde line
  unsigned int requiredNearest;
  unsigned int eigenValuesRatio;

  // maximum distance between keypoints
  // and their computed line
  double maxDist;

  if (step == "egoMotion")
  {
    requiredNearest = this->EgoMotionLineDistanceNbrNeighbors;
    eigenValuesRatio = this->EgoMotionLineDistancefactor;
    maxDist = std::pow(this->EgoMotionMaxLineDistance, 2);
  }
  else if (step == "mapping")
  {
    requiredNearest = this->MappingLineDistanceNbrNeighbors;
    eigenValuesRatio = this->MappingLineDistancefactor;
    maxDist = std::pow(this->MappingMaxLineDistance, 2);
  }
  else
  {
    throw "ComputeLineDistanceParametersAccurate function got invalide step parameter";
  }

  Eigen::Matrix<double, 3, 1> P0, P, n;
  Eigen::Matrix<double, 3, 3> A;

  // Transform the point using the current pose estimation
  P << p.x, p.y, p.z;
  P0 = P;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);
  
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;

  if (step == "egoMotion")
  {
    GetEgoMotionLineSpecificNeighbor(nearestIndex, nearestDist, requiredNearest, kdtreePreviousEdges, p);
    if (nearestIndex.size() < this->EgoMotionMinimumLineNeighborRejection)
    {
      return;
    }
    requiredNearest = nearestIndex.size();
  }
  else if (step == "mapping")
  {
    GetMappingLineSpecificNeigbbor(nearestIndex, nearestDist, this->MappingLineMaxDistInlier, requiredNearest, kdtreePreviousEdges, p);
    if (nearestIndex.size() < this->MappingMinimumLineNeighborRejection)
    {
      return;
    }
    requiredNearest = nearestIndex.size();
    //kdtreePreviousEdges->nearestKSearch(p, requiredNearest, nearestIndex, nearestDist);
  }

  // if the nearest edges are too far from the
  // current edge keypoint we skip this point.
  if (nearestDist[requiredNearest - 1] > this->MaxDistanceForICPMatching)
  {
    return;
  }

  // Compute PCA to determine best line approximation
  // of the requiredNearest nearest edges points extracted
  // Thans to the PCA we will check the shape of the neighborhood
  // and keep it if it is distributed along a line
  Eigen::MatrixXd data(requiredNearest, 3);

  for (unsigned int k = 0; k < requiredNearest; k++)
  {
    Point pt = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[k]];
    data.row(k) << pt.x, pt.y, pt.z;
  }

  Eigen::Matrix<double, 3, 1> mean = data.colwise().mean();
  Eigen::MatrixXd centered = data.rowwise() - mean.transpose();
  Eigen::MatrixXd cov = centered.transpose() * centered;
  Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> eig(cov);

  // Eigen values
  Eigen::MatrixXd D(1,3);
  // Eigen vectors
  Eigen::MatrixXd V(3,3);

  D = eig.eigenvalues();
  V = eig.eigenvectors();

  // if the first eigen value is significantly higher than
  // the second one, it means the sourrounding points are 
  // distributed on a edge line
  if (D(2) > eigenValuesRatio * D(1))
  {
    // n is the director vector of the line
    n = V.col(2);
    n.normalized();
  }
  else
  {
    return;
  }

  // A = (I-n*n.t).t * (I-n*n.t) = (I - n*n.t)^2
  // since (I-n*n.t) is a symmetric matrix.
  A = (this->I3 - n * n.transpose());
  A = A.transpose() * A;

  // it would be the case if P1 = P2 For instance
  // if the sensor has some dual returns that hit the same point
  if (!vtkMath::IsFinite(A(0, 0)))
  {
    return;
  }

  Eigen::Matrix<double, 3, 1> Xtemp;
  Point pt;
  for (unsigned int k = 0; k < requiredNearest; ++k)
  {
    pt = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[k]];
    Xtemp(0) = pt.x;
    Xtemp(1) = pt.y;
    Xtemp(2) = pt.z;
    if ( ((Xtemp - mean).transpose() * A * (Xtemp - mean)) > maxDist )
    {
      return;
    }
  }

  // distance between current point and the corresponding matching line
  double s = 1.0;
  if (step == "mapping")
  {
    s = 1 - 0.9 * std::sqrt((P - mean).transpose() * A * (P - mean));
    if (s < 0.1)
    {
      return;
    }
  }

  else if (step == "egoMotion")
  {
    // Score the point - line matching by the angle of the
    // line with ez. The idea is that the lidar is more accurate
    // in line detection when those lines are colinear with the
    // azimutal rotation axis.
    s = 0.5 + 0.5 * n(2) * n(2); // score the match by its angle with ez
  }

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(mean);
  this->Xvalues.push_back(P0);
  this->OutlierDistScale.push_back(s);
  this->RadiusIncertitude.push_back(0.0);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputePlaneDistanceParametersAccurate(pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousPlanes, Eigen::Matrix<double, 3, 3>& R,
                                                     Eigen::Matrix<double, 3, 1>& dT, Point p, std::string step)
{
  // number of neighbors edge points required to approximate
  // the corresponding egde line
  unsigned int requiredNearest;
  unsigned int significantlyFactor1, significantlyFactor2;

  // maximum distance between keypoints
  // and their computed plane
  double maxDist;

  if (step == "egoMotion")
  {
    significantlyFactor1 = this->EgoMotionPlaneDistancefactor1;
    significantlyFactor2 = this->EgoMotionPlaneDistancefactor2;
    requiredNearest = this->EgoMotionPlaneDistanceNbrNeighbors;
    maxDist = std::pow(this->EgoMotionMaxPlaneDistance, 2);
  }
  else if (step == "mapping")
  {
    significantlyFactor1 = this->MappingPlaneDistancefactor1;
    significantlyFactor2 = this->MappingPlaneDistancefactor2;
    requiredNearest = this->MappingPlaneDistanceNbrNeighbors;
    maxDist = std::pow(this->MappingMaxPlaneDistance, 2);
  }
  else
  {
    throw "ComputeLineDistanceParametersAccurate function got invalide step parameter";
  }

  Eigen::Matrix<double, 3, 1> P0, P, n;
  Eigen::Matrix<double, 3, 3> A;

  // Transform the point using the current pose estimation
  P << p.x, p.y, p.z;
  P0 = P;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);
  
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;
  kdtreePreviousPlanes->nearestKSearch(p, requiredNearest, nearestIndex, nearestDist);

  // It means that there is not enought keypoints in the neighbohood
  if (nearestIndex.size() < requiredNearest)
  {
    return;
  }

  // if the nearest planars are too far from the
  // current planar keypoint we skip this point.
  if (nearestDist[requiredNearest - 1] > this->MaxDistanceForICPMatching)
  {
    return;
  }

  // Compute PCA to determine best line approximation
  // of the requiredNearest nearest edges points extracted
  // Thanks to the PCA we will check the shape of the neighborhood
  // and keep it if it is distributed along a line
  Eigen::MatrixXd data(requiredNearest,3);

  for (unsigned int k = 0; k < requiredNearest; k++)
  {
    Point pt = kdtreePreviousPlanes->getInputCloud()->points[nearestIndex[k]];
    data.row(k) << pt.x, pt.y, pt.z;
  }

  Eigen::Matrix<double, 3, 1> mean = data.colwise().mean();
  Eigen::MatrixXd centered = data.rowwise() - mean.transpose();
  Eigen::MatrixXd cov = centered.transpose() * centered;
  Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> eig(cov);

  // Eigen values
  Eigen::MatrixXd D(1,3);
  // Eigen vectors
  Eigen::MatrixXd V(3,3);

  D = eig.eigenvalues();
  V = eig.eigenvectors();

  // if the second eigen value is close to the highest one
  // and bigger than the smallest one it means that the points
  // are distributed among a plane
  Eigen::Matrix<double, 3, 1> u, v;
  if ( (significantlyFactor2 * D(1) > D(2)) && (D(1) > significantlyFactor1 * D(0)) )
  {
    u = V.col(2);
    v = V.col(1);
  }
  else
  {
    return;
  }

  n = u.cross(v);
  n.normalized();

  // A = n*n.t
  A = n * n.transpose();

  // it would be the case if P1 = P2, P1 = P3
  // or P3 = P2. For instance if the sensor has
  // some dual returns that hit the same point
  if (!vtkMath::IsFinite(A(0, 0)))
  {
    return;
  }

  Eigen::Matrix<double, 3, 1> Xtemp;
  Point pt;
  for (unsigned int k = 0; k < requiredNearest; ++k)
  {
    pt = kdtreePreviousPlanes->getInputCloud()->points[nearestIndex[k]];
    Xtemp(0) = pt.x;
    Xtemp(1) = pt.y;
    Xtemp(2) = pt.z;
    if ( ((Xtemp - mean).transpose() * A * (Xtemp - mean)) > maxDist )
    {
      return;
    }
  }

  // distance between current point and the corresponding matching plane
  double s = 1.0;
  if (step == "mapping")
  {
    s = 1 - 0.9 * std::sqrt((P - mean).transpose() * A * (P - mean)) / std::sqrt(P.norm());
    if (s < 0.1)
    {
      return;
    }
  }

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(mean);
  this->Xvalues.push_back(P0);
  this->OutlierDistScale.push_back(s);
  this->RadiusIncertitude.push_back(0.0);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeBlobsDistanceParametersAccurate(pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousBlobs, Eigen::Matrix<double, 3, 3>& R,
                                            Eigen::Matrix<double, 3, 1>& dT, Point p, std::string step)
{
  // number of neighbors blobs points required to approximate
  // the corresponding ellipsoide
  unsigned int requiredNearest;

  // maximum distance between keypoints
  // and its neighbor
  double maxDist;

  if (step == "egoMotion")
  {
    requiredNearest = 5;
    maxDist = 4.5;
  }
  else if (step == "mapping")
  {
    requiredNearest = 7;
    maxDist = 2.0;
  }
  else
  {
    throw "ComputeLineDistanceParametersAccurate function got invalide step parameter";
  }

  // Usefull variables
  Eigen::Matrix<double, 3, 1> P0, P, n;
  Eigen::Matrix<double, 3, 3> A;

  // Transform the point using the current pose estimation
  P << p.x, p.y, p.z;
  P0 = P;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);

  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;
  kdtreePreviousBlobs->nearestKSearch(p, requiredNearest, nearestIndex, nearestDist);

  // It means that there is not enought keypoints in the neighbohood
  if (nearestIndex.size() < requiredNearest)
  {
    return;
  }

  // if the nearest blobs is too far from the
  // current blob keypoint we skip this point.
  if (nearestDist[requiredNearest - 1] > maxDist)
  {
    return;
  }

  // Compute PCA to determine best ellipsoide approximation
  // of the requiredNearest nearest blobs points extracted
  // Thanks to the PCA we will check the shape of the neighborhood
  // tune a distance function adapter to the distribution
  // (Mahalanobis distance)
  Eigen::MatrixXd data(requiredNearest, 3);

  for (unsigned int k = 0; k < requiredNearest; k++)
  {
    Point pt = kdtreePreviousBlobs->getInputCloud()->points[nearestIndex[k]];
    data.row(k) << pt.x, pt.y, pt.z;
  }

  Eigen::Matrix<double, 3, 1> mean = data.colwise().mean();
  Eigen::MatrixXd centered = data.rowwise() - mean.transpose();
  Eigen::MatrixXd cov = centered.transpose() * centered;
  Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> eig(cov);

  // Eigen values
  Eigen::MatrixXd D(1,3);
  D = eig.eigenvalues();

  // A is the inverse of the covariance
  // Matrix, encode the mahalanobis distance
  A = this->I3;

  // Coefficient the distance
  // using the distance between the point
  // and its matching blob; The aim is to prevent
  // wrong matching to pull the point cloud in the
  // bad direction
  double s = 1.0 - nearestDist[requiredNearest - 1] / maxDist;

  if (step == "egoMotion")
  {
    double r = std::tan(2.0 / 180.0 * vtkMath::Pi()) * (P0.norm() + mean.norm()) / 2.0;
    // store the distance parameters values
    this->Avalues.push_back(A);
    this->Pvalues.push_back(mean);
    this->Xvalues.push_back(P0);
    this->OutlierDistScale.push_back(s);
    this->RadiusIncertitude.push_back(r);
  }

  // Check that the region is a blob
  // i.e check the sphericity by computing
  // the ratio between the smallest and biggest
  // eigen value
  double sphericity = D(0) / D(2);
  if (sphericity < this->SphericityThreshold)
  {
    return;
  }

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(mean);
  this->Xvalues.push_back(P0);
  this->OutlierDistScale.push_back(s);
  this->RadiusIncertitude.push_back(1.0 / 10.0 * this->IncertitudeCoef * std::sqrt(D(2)));
}

//-----------------------------------------------------------------------------
void vtkSlam::GetEgoMotionLineSpecificNeighbor(std::vector<int>& nearestValid, std::vector<float>& nearestValidDist,
                                               unsigned int nearestSearch, pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousEdges, Point p)
{
  // clear vector
  nearestValid.clear();
  nearestValid.resize(0);
  nearestValidDist.clear();
  nearestValidDist.resize(0);

  // get nearest neighbor of the query point
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;
  kdtreePreviousEdges->nearestKSearch(p, nearestSearch, nearestIndex, nearestDist);

  // take the closest point
  std::vector<int> idAlreadyTook(this->NLasers, 0);
  Point closest = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[0]];
  nearestValid.push_back(nearestIndex[0]);
  nearestValidDist.push_back(nearestDist[0]);

  // invalid all possible points that
  // are on the same scan line than the
  // closest one
  idAlreadyTook[(int)closest.normal_y] = 1;

  // invalid all possible points from scan
  // lines that are too far from the closest one
  for (int k = 0; k < this->NLasers; ++k)
  {
    if (std::abs(closest.normal_y - k) > 3)
    {
      idAlreadyTook[k] = 1;
    }
  }

  // Make a selection among the neighborhood
  // of the query point. We can only take one edge
  // per scan line
  int id;
  for (unsigned int k = 1; k < nearestIndex.size(); ++k)
  {
    id = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[k]].normal_y;
    if (idAlreadyTook[id] < 1)
    {
      idAlreadyTook[id] = 1;
      nearestValid.push_back(nearestIndex[k]);
      nearestValidDist.push_back(nearestDist[k]);
    }
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::GetEgoMotionPlaneSpecificNeighbor()
{

}

//-----------------------------------------------------------------------------
void vtkSlam::GetMappingLineSpecificNeigbbor(std::vector<int>& nearestValid, std::vector<float>& nearestValidDist, double maxDistInlier,
                                             unsigned int nearestSearch, pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousEdges, Point p)
{
  // reset vectors
  nearestValid.clear();
  nearestValid.resize(0);
  nearestValidDist.clear();
  nearestValidDist.resize(0);

  // to prevent square root when making camparisons
  maxDistInlier = std::pow(maxDistInlier, 2);

  // Take the neighborhood of the query point
  // get nearest neighbor of the query point
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;
  kdtreePreviousEdges->nearestKSearch(p, nearestSearch, nearestIndex, nearestDist);

  // take the closest point
  std::vector<std::vector<int> > inliersList;
  Point closest = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[0]];
  nearestValid.push_back(nearestIndex[0]);
  nearestValidDist.push_back(nearestDist[0]);

  Eigen::Matrix<double, 3, 1> P1, P2, dir, Pcdt;
  Eigen::Matrix<double, 3, 3> D;
  P1 << closest.x, closest.y, closest.z;
  Point pclP2;
  Point inlierCandidate;

  // Loop over other neighbors of the neighborhood. For each of them
  // compute the line between closest point and current point and
  // compute the number of inlier that fit this line. Keep the line and its
  // inmliers with the most inliers
  for (unsigned int ptIndex = 1; ptIndex < nearestIndex.size(); ++ptIndex)
  {
    std::vector<int> inlierIndex;
    pclP2 = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[ptIndex]];
    P2 << pclP2.x, pclP2.y, pclP2.z;
    dir = (P2 - P1).normalized();
    D = this->I3 - dir * dir.transpose();
    D = D.transpose() * D;

    for (unsigned int candidateIndex = 1; candidateIndex < nearestIndex.size(); ++candidateIndex)
    {
      inlierCandidate = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[candidateIndex]];
      Pcdt << inlierCandidate.x, inlierCandidate.y, inlierCandidate.z;
      if ( (Pcdt - P1).transpose() * D * (Pcdt - P1) < maxDistInlier)
      {
        inlierIndex.push_back(candidateIndex);
      }
    }
    inliersList.push_back(inlierIndex);
  }

  int maxInliers = 0;
  int indexMaxInliers = -1;
  for (unsigned int k = 0; k < inliersList.size(); ++k)
  {
    if (inliersList[k].size() > maxInliers)
    {
      maxInliers = inliersList[k].size();
      indexMaxInliers = k;
    }
  }

  // fill
  for (unsigned int k = 0; k < inliersList[indexMaxInliers].size(); ++k)
  {
    nearestValid.push_back(nearestIndex[inliersList[indexMaxInliers][k]]);
    nearestValidDist.push_back(nearestDist[inliersList[indexMaxInliers][k]]);
  }

  return;
}

//-----------------------------------------------------------------------------
void vtkSlam::GetMappingPlaneSpecificNeigbbor()
{

}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeResidualValues(std::vector<Eigen::Matrix<double, 3, 3> >& vA, std::vector<Eigen::Matrix<double, 3, 1> >& vX,
                                    std::vector<Eigen::Matrix<double, 3, 1> >& vP, std::vector<double>& vS,
                                    Eigen::Matrix<double, 3, 3>& R, Eigen::Matrix<double, 3, 1>& dT, Eigen::MatrixXd& residuals)
{
  residuals = Eigen::MatrixXd(vX.size(), 1);
  Eigen::Matrix<double, 3, 1> Xp;
  double s;
  for (unsigned int k = 0; k < vX.size(); ++k)
  {
    s = vS[k];
    Xp = R * vX[k] + dT;
    residuals(k) = std::max(std::sqrt(std::abs((Xp - vP[k]).transpose() * vA[k] * (Xp - vP[k]))) - this->RadiusIncertitude[k], 0.0);
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeResidualJacobians(std::vector<Eigen::Matrix<double, 3, 3> >& vA, std::vector<Eigen::Matrix<double, 3, 1> >& vX,
                                       std::vector<Eigen::Matrix<double, 3, 1> >& vP, std::vector<double> vS,
                                       Eigen::Matrix<double, 6, 1>& T, Eigen::MatrixXd& residualsJacobians)
{
  residualsJacobians = Eigen::MatrixXd(vX.size(), 6);

  bool warned = false;
  double epsilon = 1e-5;
  double rx, ry, rz;
  rx = T(0); ry = T(1); rz = T(2);
  double X1, X2, X3;
  double C1, C2, C3;
  Eigen::Matrix<double, 3, 3> A;
  Eigen::Matrix<double, 3, 3> R = GetRotationMatrix(T);
  Eigen::Matrix<double, 3, 1> dT;
  dT << T(3), T(4), T(5);

  // cosinus and sinus of the current
  // estimated angles for the ego-motion
  // This is done in order to speed the algortihm
  // full rotation
  double crx, srx;
  double cry, sry;
  double crz, srz;
  crx = std::cos(rx); srx = std::sin(rx);
  cry = std::cos(ry); sry = std::sin(ry);
  crz = std::cos(rz); srz = std::sin(rz);

  // scale factor for outliers points
  // so that they do not have big influence
  // on the final result (whereas pure square
  // distance would give outlier points a too big
  // influence on the final result)
  double s;

  for (unsigned int k = 0; k < vX.size(); ++k)
  {
    // here the cost funtion is the distance between
    // the current plane/ edge point and its corresponding line / plane.
    // The distance is f(R,T)=sqrt((R*X+T - P).t * A * (R*X+T - P))
    // To compute the jacobian we will use the chain-rule
    // we define g(X) = sqrt(X.t * A * X) and h(R,T)=R*X+T-P1
    // Hence, f(R,T) = g(h(R, T)) and the jacobian
    // Jf(R,T) = Jg(h(R,T))*Jh(R,T)
    s = vS[k];
    X1 = vX[k](0); X2 = vX[k](1); X3 = vX[k](2);
    C1 = vP[k](0); C2 = vP[k](1); C3 = vP[k](2);
    A = vA[k];

    // represents h(R,T)
    Eigen::Matrix<double, 3, 1> h_R_t = R * vX[k] + dT - vP[k];

    // represent the jacobian of the G function
    // evaluated at the point h(R,T). Note that G is
    // the composition of the functions sqrt and X' * A * X
    // and is not differentiable when X'*A*X = 0
    Eigen::Matrix<double, 1, 3> JacobianG;
    double dist = std::sqrt(h_R_t.transpose() * A * h_R_t);

    if (dist - this->RadiusIncertitude[k] < 0)
    {
      for (unsigned int i = 0; i < 6; ++i)
      {
        residualsJacobians(k, i) = 0.0;
      }
      continue;
    }

    if (dist > 1e-12)
    {
      JacobianG = 1.0 / (2.0 * dist) * s * s * h_R_t.transpose() * (A + A.transpose());
    }

    // represent the jacobian of the H function
    // evaluated at the point R, T
    Eigen::Matrix<double, 3, 6> JacobianH;
    // dx / drx
    JacobianH(0, 0) = (srz * srx + crz * sry * crx) * X2 + (srz * crx - crz * sry * srx) * X3;
    // dx / dry
    JacobianH(0, 1) = -crz * sry * X1 + crz * cry * srx * X2 + crz * cry * crx * X3;
    // dx / drz
    JacobianH(0, 2) = -srz * cry * X1 + (-crz * crx - srz * sry * srx) * X2+ (crz * srx - srz * sry * crx) * X3;
    // dx / dtx
    JacobianH(0, 3) = 1;
    // dx / dty
    JacobianH(0, 4) = 0;
    // dx / dtz
    JacobianH(0, 5) = 0;
    // dy / drx
    JacobianH(1, 0) = (-crz * srx + srz * sry * crx) * X2 + (-crz * crx - srz * sry * srx) * X3;
    // dy / dry
    JacobianH(1, 1) = -srz * sry * X1 + srz * cry * srx * X2 + srz * cry * crx * X3;
    // dy / drz
    JacobianH(1, 2) = crz * cry * X1 + (-srz * crx + crz * sry * srx) * X2 + (srz * srx + crz * sry * crx) * X3;
    // dy / dtx
    JacobianH(1, 3) = 0;
    // dy / dty
    JacobianH(1, 4) = 1;
    // dy / dtz
    JacobianH(1, 5) = 0;
    // dz / drx
    JacobianH(2, 0) = cry * crx * X2 - cry * srx * X3;
    // dz / dry
    JacobianH(2, 1) = -cry * X1 - sry * srx * X2 - sry * crx * X3;
    // dz / drz
    JacobianH(2, 2) = 0;
    // dz / dtx
    JacobianH(2, 3) = 0;
    // dz / dty
    JacobianH(2, 4) = 0;
    // dr / dtz
    JacobianH(2, 5) = 1;

    Eigen::Matrix<double, 1, 6> currentJacobian = JacobianG * JacobianH;

    for (unsigned int i = 0; i < 6; ++i)
    {
      residualsJacobians(k, i) = currentJacobian(0, i);
    }
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeEgoMotion()
{
  // reset the relative transform
  this->Trelative << 0, 0, 0, 0, 0, 0;

  // kd-tree to process fast nearest neighbor
  // among the keypoints of the previous pointcloud
  pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousEdges(new pcl::KdTreeFLANN<Point>());
  pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousPlanes(new pcl::KdTreeFLANN<Point>());
  pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousBlobs(new pcl::KdTreeFLANN<Point>());
  kdtreePreviousEdges->setInputCloud(this->PreviousEdgesPoints);
  kdtreePreviousPlanes->setInputCloud(this->PreviousPlanarsPoints);
  kdtreePreviousBlobs->setInputCloud(this->PreviousBlobsPoints);

  std::cout << "Performing ego-motion using : " << std::endl;
  std::cout << "previous edges : " << this->PreviousEdgesPoints->size() << " current edges : " << this->CurrentEdgesPoints->size() << std::endl;
  std::cout << "previous planes : " << this->PreviousPlanarsPoints->size() << " current planes : " << this->CurrentPlanarsPoints->size() << std::endl;

  std::vector<double> costFunction(0, 0);

  // let's note f(R, T) = sum(d(point, line)^2) + sum(d(point, plane)^2)
  // f(R, T) = sum(fi(R, T)) = sum(sqrt((R*X+T-P).t*A*(R*X+T-P))). We also note
  // the new step toward the solution is
  // (H + lambda * I)^(-1)*d. Whith H the hessian
  // of the cost function and d = fi(R, T) * gradFi(R, T).
  // Here we approximate the hessian using its jacobian H = JtJ.
  // The lambda parameter is a trade off between X = H^(-1) * d
  // = H^(-1) * (fi(R, T) * gradfi(R, T)) which is tge Gauss-Newton
  // algorithm and
  // X = 1 / lambda * d = 1 / lambda * fi(R, T) * gradfi(R, T)
  // = 1 / (2.0 * lambda) * gradf which is the gradient descent algorithm.
  // The Gauss-Newton algorithm makes the assumption that the point (R, T)
  // is close enought to the solution so that f can be approximated by its
  // quadratic part involving its hessian. The idea of the Levenberg-Marquardt
  // algorithm is to start with a gradient descent value and to slowly drift toward
  // a Gauss-Newton algortihm as we converge toward the minimum of the function
  double lambda = this->Lambda0;

  unsigned int usedEdges = 0;
  unsigned int usedPlanes = 0;
  unsigned int usedBlobs = 0;
  unsigned int nbrRejection = 0;
  // ICP - Levenberg-Marquardt loop
  for (unsigned int iterCount = 0; iterCount < this->EgoMotionMaxIter; ++iterCount)
  {
    // Rotation and translation at this step
    Eigen::Matrix<double, 3, 3> R;
    Eigen::Matrix<double, 3, 1> dT;
    R = GetRotationMatrix(this->Trelative);
    dT << this->Trelative(3), this->Trelative(4), this->Trelative(5);

    Point currentPoint, transformedPoint;

    if (iterCount % this->EgoMotionIcpFrequence == 0)
    {
      this->ResetDistanceParameters();

      // loop over edges
      for (unsigned int edgeIndex = 0; edgeIndex < this->CurrentEdgesPoints->size(); ++edgeIndex)
      {
        currentPoint = this->CurrentEdgesPoints->points[edgeIndex];

        // Find the closest correspondence edge line of the current edge point
        if (this->PreviousEdgesPoints->size() > 1)
        {
          // Compute the parameters of the point - line distance
          // i.e A = (I - n*n.t)^2 with n being the director vector
          // and P a point of the line
          this->ComputeLineDistanceParametersAccurate(kdtreePreviousEdges, R, dT, currentPoint, "egoMotion");
          usedEdges = this->Xvalues.size();
        }
      }

      // loop over surfaces
      for (unsigned int planarIndex = 0; planarIndex < this->CurrentPlanarsPoints->size(); ++planarIndex)
      {
        currentPoint = this->CurrentPlanarsPoints->points[planarIndex];

        // Find the closest correspondence plane of the current planar point
        if (this->PreviousPlanarsPoints->size() > 2)
        {
          // Compute the parameters of the point - plane distance
          // i.e A = n * n.t with n being a normal of the plane
          // and is a point of the plane
          this->ComputePlaneDistanceParametersAccurate(kdtreePreviousPlanes, R, dT, currentPoint, "egoMotion");
          usedPlanes = this->Xvalues.size() - usedEdges;
        }
      }

      // loop over blobs
      if (this->UseBlob)
      {
        for (unsigned int blobIndex = 0; blobIndex < this->CurrentBlobsPoints->size(); ++blobIndex)
        {
          currentPoint = this->CurrentBlobsPoints->points[blobIndex];

          // Find the closest correspondence blob of the current blob point
          if (this->CurrentBlobsPoints->size() > 2)
          {
            this->ComputeBlobsDistanceParametersAccurate(kdtreePreviousBlobs, R, dT, currentPoint, "egoMotion");
            usedBlobs = this->Xvalues.size() - usedPlanes - usedEdges;
          }
        }
      }
    }

    // f(R, T) = sum(fi(R, T))
    // fi(R, T) = sqrt((R*X+T-P).t * A * (R*X+T-P)
    // J: residual jacobians, [dfi(R, T)/dR, dfi(R, T)/dT]
    // Y: residual values, fi(R, T)
    Eigen::MatrixXd J, Y;
    this->ComputeResidualValues(this->Avalues, this->Xvalues, this->Pvalues, this->OutlierDistScale, R, dT, Y);
    this->ComputeResidualJacobians(this->Avalues, this->Xvalues, this->Pvalues, this->OutlierDistScale, this->Trelative, J);

    // RMSE
    costFunction.push_back(std::sqrt(0.5 / static_cast<double>(Y.rows()) * (Y.transpose() * Y)(0)));

    Eigen::MatrixXd Jt = J.transpose();
    Eigen::MatrixXd JtJ = Jt * J;
    Eigen::MatrixXd JtY = Jt * Y;
    Eigen::Matrix<double, 6, 6> diagJtJ;
    diagJtJ << JtJ(0, 0), 0, 0, 0, 0, 0,
               0, JtJ(1, 1), 0, 0, 0, 0,
               0, 0, JtJ(2, 2), 0, 0, 0,
               0, 0, 0, JtJ(3, 3), 0, 0,
               0, 0, 0, 0, JtJ(4, 4), 0,
               0, 0, 0, 0, 0, JtJ(5, 5);

    // The next step of the L-M algorithm is computed by solving
    // (JtJ + lambda * diagJtJ) = Jt * Y. To avoid the computation
    // of the inverse of (JtJ + lambda * diagJtJ) we use a gauss-pivot
    // algorithm to solve the linear equation for this particular point
    Eigen::ColPivHouseholderQR<Eigen::MatrixXd> dec(JtJ + lambda * diagJtJ);
    Eigen::Matrix<double, 6, 1> X = dec.solve(JtY);
    if (!vtkMath::IsFinite(X(0)) || !vtkMath::IsFinite(X(3)))
    {
      vtkGenericWarningMacro("Estimated transform not finite, skip this frame");
      break;
    }

    // Check if the cost function has not increase
    // in the last iteration. If it does, we are too
    // away from the solution to use the Gauss-Newton
    // algorithm. Increase lambda to drift toward gradient descent
    Eigen::Matrix<double, 6, 1> Tcandidate;
    Tcandidate = this->Trelative - X;
    Eigen::Matrix<double, 3, 3> Rcandidate = GetRotationMatrix(Tcandidate);
    Eigen::Matrix<double, 3, 1> dTcandidate;
    dTcandidate << Tcandidate(3), Tcandidate(4), Tcandidate(5);
    Eigen::MatrixXd Ycandidate;
    this->ComputeResidualValues(this->Avalues, this->Xvalues, this->Pvalues, this->OutlierDistScale, Rcandidate, dTcandidate, Ycandidate);
    double newCost = std::sqrt(0.5 / static_cast<double>(Ycandidate.rows()) * (Ycandidate.transpose() * Ycandidate)(0));

    if (newCost > costFunction[costFunction.size() - 1])
    {
      lambda = this->LambdaRatio * lambda;
      nbrRejection++;
    }
    else
    {
      this->Trelative = Tcandidate;
      lambda = 1.0 / this->LambdaRatio * lambda;
    }
    
    this->EgoMotionIterMade = iterCount + 1;
  }
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: intiale cost function"))->InsertNextValue(costFunction[0]);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: final cost function"))->InsertNextValue(costFunction[costFunction.size() - 1]);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: edges used"))->InsertNextValue(usedEdges);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: planes used"))->InsertNextValue(usedPlanes);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: blobs used"))->InsertNextValue(usedBlobs);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: total keypoints used"))->InsertNextValue(this->Xvalues.size());
  std::cout << "cost goes from : " << costFunction[0] << " to : " << costFunction[costFunction.size() - 1] << std::endl;
  std::cout << "used keypoints : " << this->Xvalues.size() << std::endl;
  std::cout << "edges : " << usedEdges << " planes : " << usedPlanes << " blobs : " << usedBlobs << std::endl;
  std::cout << "nbr rejection : " << nbrRejection << std::endl;
  std::cout << "final lambda value : " << lambda << std::endl;

  // Integrate the relative motion
  // to the world transformation
  this->UpdateTworldUsingTrelative();
}

//-----------------------------------------------------------------------------
void vtkSlam::Mapping()
{
  // let's note f(R, T) = sum(d(point, line)^2) + sum(d(point, plane)^2)
  // f(R, T) = sum(fi(R, T)) = sum(sqrt((R*X+T-P).t*A*(R*X+T-P))). We also note
  // the new step toward the solution is
  // (H + lambda * I)^(-1)*d. Whith H the hessian
  // of the cost function and d = fi(R, T) * gradFi(R, T).
  // Here we approximate the hessian using its jacobian H = JtJ.
  // The lambda parameter is a trade off between X = H^(-1) * d
  // = H^(-1) * (fi(R, T) * gradfi(R, T)) which is tge Gauss-Newton
  // algorithm and
  // X = 1 / lambda * d = 1 / lambda * fi(R, T) * gradfi(R, T)
  // = 1 / (2.0 * lambda) * gradf which is the gradient descent algorithm.
  // The Gauss-Newton algorithm makes the assumption that the point (R, T)
  // is close enought to the solution so that f can be approximated by its
  // quadratic part involving its hessian. The idea of the Levenberg-Marquardt
  // algorithm is to start with a gradient descent value and to slowly drift toward
  // a Gauss-Newton algortihm as we converge toward the minimum of the function
  double lambda = this->Lambda0;

  // Get a prediction of Tworld using motion
  // model of a constant acceleration
  Eigen::Matrix<double, 6, 1> Tpredicted = this->PredictTWorld();

  std::vector<double> costFunction(0, 0);
  std::vector<double> normJacobian(0, 0);

  // contruct kd-tree for fast search
  pcl::KdTreeFLANN<Point>::Ptr kdtreeEdges(new pcl::KdTreeFLANN<Point>());
  pcl::KdTreeFLANN<Point>::Ptr kdtreePlanes(new pcl::KdTreeFLANN<Point>());
  pcl::KdTreeFLANN<Point>::Ptr kdtreeBlobs(new pcl::KdTreeFLANN<Point>());

  pcl::PointCloud<Point>::Ptr subEdgesPointsLocalMap = this->EdgesPointsLocalMap->Get(this->Tworld);
  pcl::PointCloud<Point>::Ptr subPlanarPointsLocalMap = this->PlanarPointsLocalMap->Get(this->Tworld);
  pcl::PointCloud<Point>::Ptr subBlobPointsLocalMap = this->BlobsPointsLocalMap->Get(this->Tworld);

  std::cout << "edges map : " << subEdgesPointsLocalMap->points.size() << std::endl;
  std::cout << "flat map : " << subPlanarPointsLocalMap->points.size() << std::endl;
  std::cout << "blobs map : " << subBlobPointsLocalMap->points.size() << std::endl;

  kdtreeEdges->setInputCloud(subEdgesPointsLocalMap);
  kdtreePlanes->setInputCloud(subPlanarPointsLocalMap);
  kdtreeBlobs->setInputCloud(subBlobPointsLocalMap);

  unsigned int usedEdges = 0;
  unsigned int usedPlanes = 0;
  unsigned int usedBlobs = 0;

  // ICP - Levenberg-Marquardt loop
  for (int iterCount = 0; iterCount < this->MappingMaxIter; ++iterCount)
  {
    // Rotation and translation at this step      
    Eigen::Matrix<double, 3, 3> R;
    Eigen::Matrix<double, 3, 1> dT;

    R = GetRotationMatrix(this->Tworld);
    dT << this->Tworld(3), this->Tworld(4), this->Tworld(5);

    Point currentPoint;

    // ICP matching
    if (iterCount % this->MappingIcpFrequence == 0)
    {
      // clear all data
      this->ResetDistanceParameters();

      // loop over edges
      for (unsigned int edgeIndex = 0; edgeIndex < this->CurrentEdgesPoints->size(); ++edgeIndex)
      {
        currentPoint = this->CurrentEdgesPoints->points[edgeIndex];

        // Find the closest correspondence edge line of the current edge point
        this->ComputeLineDistanceParametersAccurate(kdtreeEdges, R, dT, currentPoint, "mapping");
        usedEdges = this->Xvalues.size();
      }

      // loop over surfaces
      for (unsigned int planarIndex = 0; planarIndex < this->MappingPlanarsPoints->size(); ++planarIndex)
      {
        currentPoint = this->MappingPlanarsPoints->points[planarIndex];

        // Find the closest correspondence plane of the current planar point
        this->ComputePlaneDistanceParametersAccurate(kdtreePlanes, R, dT, currentPoint, "mapping");
        usedPlanes = this->Xvalues.size() - usedEdges;
      }

      if (this->UseBlob)
      {
        // loop over blobs
        for (unsigned int blobIndex = 0; blobIndex < this->CurrentBlobsPoints->size(); ++blobIndex)
        {
          currentPoint = this->CurrentBlobsPoints->points[blobIndex];

          // Find the closest correspondence plane of the current planar point
          this->ComputeBlobsDistanceParametersAccurate(kdtreeBlobs, R, dT, currentPoint, "mapping");
          usedBlobs = this->Xvalues.size() - usedPlanes - usedEdges;
        }
      }
    }

    // f(R, T) = sum(fi(R, T))
    // fi(R, T) = sqrt((R*X+T-P).t * A * (R*X+T-P)
    // J: residual jacobians, [dfi(R, T)/dR, dfi(R, T)/dT]
    // Y: residual values, fi(R, T)
    Eigen::MatrixXd J, Y, Jsum;
    this->ComputeResidualValues(this->Avalues, this->Xvalues, this->Pvalues, this->OutlierDistScale, R, dT, Y);
    this->ComputeResidualJacobians(this->Avalues, this->Xvalues, this->Pvalues, this->OutlierDistScale, this->Tworld, J);

    // RMSE
    costFunction.push_back(std::sqrt(0.5 / static_cast<double>(Y.rows()) * (Y.transpose() * Y)(0)));

    Eigen::MatrixXd Jt = J.transpose();
    Eigen::MatrixXd JtJ = Jt * J;
    Eigen::MatrixXd JtY = Jt * Y;
    Eigen::Matrix<double, 6, 6> diagJtJ;
    diagJtJ << JtJ(0, 0), 0, 0, 0, 0, 0,
               0, JtJ(1, 1), 0, 0, 0, 0,
               0, 0, JtJ(2, 2), 0, 0, 0,
               0, 0, 0, JtJ(3, 3), 0, 0,
               0, 0, 0, 0, JtJ(4, 4), 0,
               0, 0, 0, 0, 0, JtJ(5, 5);

    // The next step of the L-M algorithm is computed by solving
    // (JtJ + lambda * diagJtJ) = Jt * Y. To avoid the computation
    // of the inverse of (JtJ + lambda * diagJtJ) we use a gauss-pivot
    // algorithm to solve the linear equation for this particular point
    Eigen::ColPivHouseholderQR<Eigen::MatrixXd> dec(JtJ + lambda * diagJtJ);
    Eigen::Matrix<double, 6, 1> X = dec.solve(JtY);

    if (!vtkMath::IsFinite(X(0)) || !vtkMath::IsFinite(X(3)))
    {
      vtkGenericWarningMacro("Estimated transform not finite, skip this frame");
      break;
    }

    // Jacobian of the full sum function
    // F(R, T) = sum fi(R, T)^2. Derivate
    // upon R and T (=P) we found:
    // dF / dP = 2 * sum(fi(P) * dfi(P) / dP)
    Jsum = 2 * Y.transpose() * J;
    normJacobian.push_back(Jsum.norm());

    // Check if the cost function has not increase
    // in the last iteration. If it does, we are too
    // away from the solution to use the Gauss-Newton
    // algorithm. Increase lambda to drift toward gradient descent
    Eigen::Matrix<double, 6, 1> Tcandidate;
    Tcandidate = this->Tworld - X;
    Eigen::Matrix<double, 3, 3> Rcandidate = GetRotationMatrix(Tcandidate);
    Eigen::Matrix<double, 3, 1> dTcandidate;
    dTcandidate << Tcandidate(3), Tcandidate(4), Tcandidate(5);
    Eigen::MatrixXd Ycandidate;
    this->ComputeResidualValues(this->Avalues, this->Xvalues, this->Pvalues, this->OutlierDistScale, Rcandidate, dTcandidate, Ycandidate);
    double newCost = std::sqrt(0.5 / static_cast<double>(Ycandidate.rows()) * (Ycandidate.transpose() * Ycandidate)(0));

    if (newCost > costFunction[costFunction.size() - 1])
    {
      lambda = this->LambdaRatio * lambda;
    }
    else
    {
      this->Tworld = Tcandidate;
      lambda = 1.0 / this->LambdaRatio * lambda;
    }

    this->MappingIterMade = iterCount + 1;
  }

  // Now evaluate the quality of the parameters
  // prediction using an approxiamte computation
  // of the variance covariance matrix
  // Rotation and translation at the end of the mapping
  Eigen::Matrix<double, 3, 3> R;
  Eigen::Matrix<double, 3, 1> dT;
  R = GetRotationMatrix(this->Tworld);
  dT << this->Tworld(3), this->Tworld(4), this->Tworld(5);

  // Compute residuals values mean and variance
  Eigen::MatrixXd Y;
  this->ComputeResidualValues(this->Avalues, this->Xvalues, this->Pvalues, this->OutlierDistScale, R, dT, Y);
  double residualSum = std::sqrt(0.5 / static_cast<double>(Y.rows()) * (Y.transpose() * Y)(0));
  double meanResidual = Y.sum();
  double varResidual = 0;
  for (unsigned int k = 0; k < Y.rows(); ++k)
  {
    varResidual = std::pow(Y(k) - meanResidual, 2);
  }
  varResidual /= static_cast<double>(Y.rows());

  Eigen::MatrixXd J;
  this->ComputeResidualJacobians(this->Avalues, this->Xvalues, this->Pvalues, this->OutlierDistScale, this->Tworld, J);

  Eigen::MatrixXd JtJ = J.transpose() * J;
  Eigen::MatrixXd Sigma = varResidual * JtJ.inverse();
  Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> eig(Sigma);
  Eigen::MatrixXd D = eig.eigenvalues();

  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: intiale cost function"))->InsertNextValue(costFunction[0]);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: final cost function"))->InsertNextValue(costFunction[costFunction.size() - 1]);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("Variance Error"))->InsertNextValue(costFunction[D(5)]);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: edges used"))->InsertNextValue(usedEdges);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: planes used"))->InsertNextValue(usedPlanes);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: blobs used"))->InsertNextValue(usedBlobs);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: total keypoints used"))->InsertNextValue(this->Xvalues.size());

  std::cout << "cost goes from : " << costFunction[0] << " to : " << costFunction[costFunction.size() - 1] << " is equal ? : " << residualSum << std::endl;
  std::cout << "used keypoints : " << this->Xvalues.size() << std::endl;
  std::cout << "edges : " << usedEdges << " planes : " << usedPlanes << " blobs : " << usedBlobs << std::endl;
  std::cout << "final lambda value : " << lambda << std::endl;
  std::cout << "Jacobian norm goes from: " << normJacobian[0] << " to : " << normJacobian[normJacobian.size() - 1] << std::endl;
  std::cout << "Covariance matrix: " << Sigma << std::endl;
  std::cout << "Covariance Eigen values: " << D << std::endl;
  std::cout << "Maximum variance: " << D(5) << std::endl;

  if (this->MotionModel)
  {
    this->KalmanEstimator.Prediction();
    this->KalmanEstimator.SetMeasureCovariance(Sigma);
    this->KalmanEstimator.Correction(this->Tworld);
    Eigen::Matrix<double, 12, 1> stateVector = this->KalmanEstimator.GetStateVector();

    std::cout << "State vector: " << std::endl << stateVector << std::endl;

    for (unsigned int i = 0; i < 6; ++i)
    {
      this->Tworld(i) = stateVector(i);
    }
  }

  // Add the current computed transform to the list
  this->TworldList.push_back(this->Tworld);

  // Update EdgeMap
  pcl::PointCloud<Point>::Ptr MapEdgesPoints(new pcl::PointCloud<Point>());
  for (unsigned int i = 0; i < this->CurrentEdgesPoints->size(); ++i)
  {
    MapEdgesPoints->push_back(this->CurrentEdgesPoints->at(i));
    this->TransformToWorld(MapEdgesPoints->at(i), this->Tworld);
  }
  EdgesPointsLocalMap->Roll(this->Tworld);
  EdgesPointsLocalMap->Add(MapEdgesPoints);

  // Update PlanarMap
  pcl::PointCloud<Point>::Ptr MapPlanarsPoints(new pcl::PointCloud<Point>());
  for (unsigned int i = 0; i < this->MappingPlanarsPoints->size(); ++i)
  {
    MapPlanarsPoints->push_back(this->MappingPlanarsPoints->at(i));
    this->TransformToWorld(MapPlanarsPoints->at(i), this->Tworld);
  }
  PlanarPointsLocalMap->Roll(this->Tworld);
  PlanarPointsLocalMap->Add(MapPlanarsPoints);

  // Update BlobsMap
  pcl::PointCloud<Point>::Ptr MapBlobsPoints(new pcl::PointCloud<Point>());
  for (unsigned int i = 0; i < this->CurrentBlobsPoints->size(); ++i)
  {
    MapBlobsPoints->push_back(this->CurrentBlobsPoints->at(i));
    this->TransformToWorld(MapBlobsPoints->at(i), this->Tworld);
  }
  BlobsPointsLocalMap->Roll(this->Tworld);
  BlobsPointsLocalMap->Add(MapBlobsPoints);
}

//-----------------------------------------------------------------------------
void vtkSlam::ResetDistanceParameters()
{
  this->Xvalues.clear();
  this->Xvalues.resize(0);
  this->Avalues.clear();
  this->Avalues.resize(0);
  this->Pvalues.clear();
  this->Pvalues.resize(0);
  this->TimeValues.clear();
  this->TimeValues.resize(0);
  this->OutlierDistScale.clear();
  this->OutlierDistScale.resize(0);
  this->RadiusIncertitude.clear();
  this->RadiusIncertitude.resize(0);
}

//-----------------------------------------------------------------------------
void vtkSlam::UpdateTworldUsingTrelative()
{
  // Rotation and translation relative
  Eigen::Matrix<double, 3, 3> Rr, Rw;
  Eigen::Matrix<double, 3, 1> Tr, Tw;
  Rr = GetRotationMatrix(this->Trelative);
  Tr << this->Trelative(3), this->Trelative(4), this->Trelative(5);

  // full rotation
  Rw = GetRotationMatrix(this->Tworld);
  Tw << this->Tworld(3), this->Tworld(4), this->Tworld(5);

  Eigen::Matrix<double, 3, 1> newTw;
  Eigen::Matrix<double, 3, 3> newRw;

  // The new pos of the sensor in the world
  // referential is the previous one composed
  // with the relative motion estimated at the
  // odometry step
  newRw = Rw * Rr;
  newTw = Rw * Tr + Tw;

  double rx = std::atan2(newRw(2, 1), newRw(2, 2));
  double ry = -std::asin(newRw(2, 0));
  double rz = std::atan2(newRw(1, 0), newRw(0, 0));

  this->Tworld(0) = rx;
  this->Tworld(1) = ry;
  this->Tworld(2) = rz;
  this->Tworld(3) = newTw(0);
  this->Tworld(4) = newTw(1);
  this->Tworld(5) = newTw(2);
}

//-----------------------------------------------------------------------------
/*const*/ unsigned int vtkSlam::Get_RollingGrid_VoxelSize() const
{
  return this->EdgesPointsLocalMap->Get_VoxelSize();
}

//-----------------------------------------------------------------------------
void vtkSlam::Set_RollingGrid_VoxelSize(const unsigned int size)
{
  this->EdgesPointsLocalMap->Set_VoxelSize(size);
  this->PlanarPointsLocalMap->Set_VoxelSize(size);
}

//-----------------------------------------------------------------------------
void vtkSlam::Get_RollingGrid_Grid_NbVoxel(double nbVoxel[3]) const
{
  this->EdgesPointsLocalMap->Get_Grid_NbVoxel(nbVoxel);
}

//-----------------------------------------------------------------------------
void vtkSlam::Set_RollingGrid_Grid_NbVoxel(const double nbVoxel[3])
{
  this->EdgesPointsLocalMap->Set_Grid_NbVoxel(nbVoxel);
  this->PlanarPointsLocalMap->Set_Grid_NbVoxel(nbVoxel);
}

//-----------------------------------------------------------------------------
void vtkSlam::Get_RollingGrid_PointCloud_NbVoxel(double nbVoxel[3]) const
{
  this->EdgesPointsLocalMap->Get_PointCloud_NbVoxel(nbVoxel);
}

//-----------------------------------------------------------------------------
void vtkSlam::Set_RollingGrid_PointCloud_NbVoxel(const double nbVoxel[3])
{
  this->EdgesPointsLocalMap->Set_PointCloud_NbVoxel(nbVoxel);
  this->PlanarPointsLocalMap->Set_PointCloud_NbVoxel(nbVoxel);
}

//-----------------------------------------------------------------------------
/*const*/ double vtkSlam::Get_RollingGrid_LeafVoxelFilterSize() const
{
  return this->EdgesPointsLocalMap->Get_LeafVoxelFilterSize();
}

//-----------------------------------------------------------------------------
void vtkSlam::Set_RollingGrid_LeafVoxelFilterSize(const double size)
{
  this->EdgesPointsLocalMap->Set_LeafVoxelFilterSize(0.75 * size);
  this->PlanarPointsLocalMap->Set_LeafVoxelFilterSize(size);
  this->BlobsPointsLocalMap->Set_LeafVoxelFilterSize(size);
}

//-----------------------------------------------------------------------------
Eigen::Matrix<double, 6, 1> vtkSlam::PredictTWorld()
{
  return Eigen::Matrix<double, 6, 1>();
}

//-----------------------------------------------------------------------------
void vtkSlam::SetMaxVelocityAcceleration(double acc)
{
  this->KalmanEstimator.SetMaxVelocityAcceleration(acc);
}

//-----------------------------------------------------------------------------
void vtkSlam::SetMaxAngleAcceleration(double acc)
{
  this->KalmanEstimator.SetMaxAngleAcceleration(acc);
}

//-----------------------------------------------------------------------------
void vtkSlam::SetExternalSensorMeasures(vtkVelodyneTransformInterpolator* interpolator)
{
  if (this->NbrFrameProcessed > 0)
  {
    vtkGenericWarningMacro("The external sensor measures should be provided"
                           << "Before launching any odometry operation");
  }
  this->ExternalMeasures = interpolator;
}

//-----------------------------------------------------------------------------
KalmanFilter::KalmanFilter()
{
  this->ResetKalmanFilter();
}

//-----------------------------------------------------------------------------
void KalmanFilter::ResetKalmanFilter()
{
  // Fill motion Model diagonal
  for (unsigned int i = 0; i < 12; ++i)
  {
    for (unsigned int j = 0; j < 12; ++j)
    {
      this->MotionModel(i, j) = 0;
      if (i == j)
        this->MotionModel(i, j) = 1.0;
    }
  }

  // Fill Estimator covariance
  // Set to zero because we know for
  // sure that we are at position (0, 0, 0)
  // and velocity (0, 0, 0)
  for (unsigned int i = 0; i < 12; ++i)
  {
    for (unsigned int j = 0; j < 12; ++j)
    {
      this->EstimatorCovariance(i, j) = 0.0;
    }
  }

  // Fill measure model
  for (unsigned int i = 0; i < 12; ++i)
  {
    for (unsigned int j = 0; j < 12; ++j)
    {
      this->MeasureModel(i, j) = 0;
    }
  }
  for (unsigned int i = 0; i < 6; ++i)
  {
    this->MeasureModel(i, i) = 1.0;
  }

  // Fill Motion model covariance
  for (unsigned int i = 0; i < 12; ++i)
  {
    for (unsigned int j = 0; j < 12; ++j)
    {
      this->ModelCovariance(i, j) = 0;
    }
  }

  // Fill vector state
  this->VectorState << 0,0,0,0,0,0,0,0,0,0,0,0;

  // Set the maximale acceleration
  // Settle to 10 m.s-2 (= 1g). it is
  // the maximal acceleration that a "normal"
  // car can endorsed. Moreover, it the acceleration
  // of a falling drone. Seems a good limit
  // Reducing the maximal acceleration will
  // reduce the motion model covariance matrix
  this->MaxAcceleration = 10.0;

  // Maximal acceleration settled to
  // 540 degrees / s-2
  this->MaxAngleAcceleration = 540.0 / 180.0 * vtkMath::Pi();
}

//-----------------------------------------------------------------------------
void KalmanFilter::SetCurrentTime(double time)
{
  // Update time
  this->PreviousTime = this->CurrentTime;
  this->CurrentTime = time;
  this->DeltaTime = this->CurrentTime - this->PreviousTime;

  // Update motion model matrix
  for (unsigned int i = 0; i <= 5; ++i)
  {
    this->MotionModel(i, i + 6) = this->DeltaTime;
  }

  // Update Motion model covariance matrix
  // angle
  for (unsigned int i = 0; i < 3; ++i)
  {
    this->ModelCovariance(i, i) = std::pow(0.5 * this->MaxAngleAcceleration * std::pow(this->DeltaTime, 2), 2);
  }
  // Position
  for (unsigned int i = 3; i < 6; ++i)
  {
    this->ModelCovariance(i, i) = std::pow(0.5 * this->MaxAcceleration * std::pow(this->DeltaTime, 2), 2);
  }
  // Angle speed
  for (unsigned int i = 6; i < 9; ++i)
  {
    this->ModelCovariance(i, i) = std::pow(this->MaxAngleAcceleration * this->DeltaTime, 2);
  }
  // Velocity
  for (unsigned int i = 9; i < 12; ++i)
  {
    this->ModelCovariance(i, i) = std::pow(this->MaxAcceleration * this->DeltaTime, 2);
  }

  /*std::cout << "Motion Model: " << std::endl << this->MotionModel << std::endl;
  std::cout << "Measure Model: " << std::endl << this->MeasureModel << std::endl;
  std::cout << "Model Covariance: " << std::endl << this->ModelCovariance << std::endl;*/
}

//-----------------------------------------------------------------------------
void KalmanFilter::SetMeasureCovariance(Eigen::Matrix<double, 6, 6> argCov)
{
  this->MeasureCovariance = argCov;
}

//-----------------------------------------------------------------------------
void KalmanFilter::Prediction()
{
  // Prediction using motion model and motion covariance
  // Vector state prediction
  this->VectorStatePredicted = this->MotionModel * this->VectorState;
  // Estimator covariance update
  this->EstimatorCovariance = this->MotionModel * this->EstimatorCovariance * this->MotionModel.transpose() + this->ModelCovariance;
}

//-----------------------------------------------------------------------------
void KalmanFilter::Correction(Eigen::Matrix<double, 6, 1> Measure)
{
  // Update using the measure and its covariance
  Eigen::MatrixXd novelty = (this->MeasureModel * this->EstimatorCovariance * this->MeasureModel.transpose() + this->MeasureCovariance);
  Eigen::MatrixXd gain = this->EstimatorCovariance * this->MeasureModel.transpose() * novelty.inverse();

  // Update the vector state estimation
  this->VectorState = this->VectorStatePredicted + gain * (Measure - this->MeasureModel * this->VectorStatePredicted);

  // Update Estimator covariance
  this->EstimatorCovariance = this->EstimatorCovariance - gain * this->MeasureModel * this->EstimatorCovariance;
}

//-----------------------------------------------------------------------------
Eigen::Matrix<double, 12, 1> KalmanFilter::GetStateVector()
{
  return this->VectorState;
}

//-----------------------------------------------------------------------------
void KalmanFilter::SetMaxAngleAcceleration(double acc)
{
  this->MaxAngleAcceleration = acc / 180.0 * vtkMath::Pi();
}

//-----------------------------------------------------------------------------
void KalmanFilter::SetMaxVelocityAcceleration(double acc)
{
  this->MaxAcceleration = acc;
}