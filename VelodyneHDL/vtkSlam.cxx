//=========================================================================
//
// Copyright 2018 Kitware, Inc.
// Author: Guilbert Pierre (spguilbert@gmail.com)
// Data: 03-27-2018
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//=========================================================================

// This slam algorithm is largely inspired by the LOAM algorithm:
// J. Zhang and S. Singh. LOAM: Lidar Odometry and Mapping in Real-time.
// Robotics: Science and Systems Conference (RSS). Berkeley, CA, July 2014.

// The algorithm is composed of three sequential steps:
//
// - Keypoints extraction: this step consist of extracting keypoints over
// the point clouds. To do that, the laser lines / scans are trated indepently.
// The laser lines are projected onto the XY plane and are rescale depending on
// their vertical angle. Then we compute their curvature and create two class of
// keypoints. The edges keypoints which correspond to points with a hight curvature
// and planar points which correspond to points with a low curvature.
//
// - Ego-Motion: this step consist of recovering the motion of the lidar
// sensor between two frames (two sweeps). The motion is modelized by a constant
// velocity and angular velocity between two frames. Hence, we can parameterize
// the motion by a rotation and translation per sweep / frame and interpolate
// the transformation inside a frame using the timestamp of the points.
// Since the point clouds generated by a lidar are sparse we decided to use
// a closest-point matching between the keypoints of the current frame
// and the ones of the previous frame. Once the matching is done, a keypoint
// of the current frame is matched with a plane / line (depending of the
// nature of the keypoint) from the previous frame. Then, we recover R and T by
// minimizing the function f(R, T) = sum(d(point, line)^2) + sum(d(point, plane)^2).
// Which can be writen f(R, T) = sum((R*X+T-P).t*A*(R*X+T-P)) where:
// - X is a keypoint of the current frame
// - P is a point of the corresponding line / plane
// - A = (n*n.t) with n being the normal of the plane
// - A = (I - n*n.t).t * (I - n*n.t) with n being a director vector of the line
// Since the function f(R, T) is a non-linear mean square error function
// we decided to use the Levenberg-Marquardt algorithm to recover its argmin.

// In the following programs : "vtkSlam.h" and "vtkSlam.cxx" the lidar
// coordinate system {L} is a 3D coordinate system with its origin at the
// geometric center of the lidar. The world coordinate system {W} is a 3D
// coordinate system which coinciding with {L] at the initial position. The
// points will be denoted by the ending letter L or W if they belong to
// the corresponding coordinate system

// LOCAL
#include "vtkSlam.h"
#include "vtkVelodyneHDLReader.h"
#include "vtkVelodyneTransformInterpolator.h"
// STD
#include <sstream>
#include <algorithm>
#include <cmath>
#include <cfloat>
#include <ctime>
// VTK
#include <vtkCellArray.h>
#include <vtkCellData.h>
#include <vtkDataArray.h>
#include <vtkDoubleArray.h>
#include <vtkFloatArray.h>
#include <vtkInformation.h>
#include <vtkInformationVector.h>
#include <vtkMath.h>
#include <vtkNew.h>
#include <vtkObjectFactory.h>
#include <vtkPointData.h>
#include <vtkPoints.h>
#include <vtkPolyData.h>
#include <vtkPolyLine.h>
#include <vtkSmartPointer.h>
#include <vtkStreamingDemandDrivenPipeline.h>
#include <vtkQuaternion.h>
#include <vtkUnsignedCharArray.h>
#include <vtkUnsignedShortArray.h>
#include <vtkTransform.h>
// EIGEN
#include <Eigen/Dense>
// PCL
#include <pcl/point_types.h>
#include <pcl/filters/voxel_grid.h>
// CERES
//#include <ceres/include/ceres/ceres.h>

vtkStandardNewMacro(vtkSlam);

//-----------------------------------------------------------------------------
Eigen::Matrix<double, 3, 3> GetRotationMatrix(Eigen::Matrix<double, 6, 1> T)
{
  // Rotation and translation relative
  Eigen::Matrix<double, 3, 3> Rx, Ry, Rz, R;
  // rotation around X-axis
  Rx << 1,         0,          0,
        0, cos(T(0)), -sin(T(0)),
        0, sin(T(0)),  cos(T(0));
  // rotation around Y-axis
  Ry <<  cos(T(1)), 0, sin(T(1)),
        0,          1,         0,
        -sin(T(1)), 0, cos(T(1));
  // rotation around Z-axis
  Rz << cos(T(2)), -sin(T(2)), 0,
        sin(T(2)),  cos(T(2)), 0,
                0,          0, 1;

  // full rotation
  R = Rz * Ry * Rx;
  return R;
}

//-----------------------------------------------------------------------------
template <typename T>
vtkSmartPointer<T> CreateDataArray(const char* name, vtkIdType np, vtkPolyData* pd)
{
  vtkSmartPointer<T> array = vtkSmartPointer<T>::New();
  array->Allocate(np);
  array->SetName(name);

  if (pd)
    {
    pd->GetPointData()->AddArray(array);
    }

  return array;
}

//-----------------------------------------------------------------------------
vtkSmartPointer<vtkCellArray> NewVertexCells(vtkIdType numberOfVerts)
{
  vtkNew<vtkIdTypeArray> cells;
  cells->SetNumberOfValues(numberOfVerts*2);
  vtkIdType* ids = cells->GetPointer(0);
  for (vtkIdType i = 0; i < numberOfVerts; ++i)
    {
    ids[i*2] = 1;
    ids[i*2+1] = i;
    }

  vtkSmartPointer<vtkCellArray> cellArray = vtkSmartPointer<vtkCellArray>::New();
  cellArray->SetCells(numberOfVerts, cells.GetPointer());
  return cellArray;
}

//-----------------------------------------------------------------------------
int vtkSlam::RequestData(vtkInformation *vtkNotUsed(request),
vtkInformationVector **inputVector, vtkInformationVector *outputVector)
{
  // Get the output
  vtkPolyData *output = vtkPolyData::GetData(outputVector);
  vtkInformation *info = outputVector->GetInformationObject(0);

  // Fill output port
  //output->ShallowCopy(this->Trajectory);

  return 1;
}

//-----------------------------------------------------------------------------
int vtkSlam::RequestInformation(vtkInformation *request,
                                     vtkInformationVector **inputVector,
                                     vtkInformationVector *outputVector)
{
  return this->Superclass::RequestInformation(request, inputVector, outputVector);
}

//-----------------------------------------------------------------------------
int vtkSlam::CanReadFile(const char* fname)
{
  return 1;
}

//-----------------------------------------------------------------------------
void vtkSlam::PrintSelf(ostream& os, vtkIndent indent)
{
  this->Superclass::PrintSelf(os, indent);
}


//-----------------------------------------------------------------------------
vtkSlam::vtkSlam()
{
  this->SetNumberOfInputPorts(0);
  this->ResetAlgorithm();
}

//-----------------------------------------------------------------------------
vtkSlam::~vtkSlam()
{
}

//-----------------------------------------------------------------------------
void vtkSlam::InitTime()
{
  this->Timer1 = std::clock();
}

//-----------------------------------------------------------------------------
void vtkSlam::StopTimeAndDisplay(std::string functionName)
{
  this->Timer2 = std::clock();
  double dt = static_cast<double>(this->Timer2 - this->Timer1) / CLOCKS_PER_SEC;
  std::cout << "  -time elapsed in function <" << functionName << "> : " << dt << " sec" << std::endl;
}

//-----------------------------------------------------------------------------
std::vector<double> vtkSlam::GetWorldTransform()
{
  // Rotation and translation relative
  Eigen::Matrix<double, 3, 3> Rw;

  // full rotation
  Rw = GetRotationMatrix(this->Tworld);

  double rx = std::atan2(Rw(2, 1), Rw(2, 2));
  double ry = -std::asin(Rw(2, 0));
  double rz = std::atan2(Rw(1, 0), Rw(0, 0));
  std::vector<double> res(6, 0);
  
  res[0] = rx;
  res[1] = ry;
  res[2] = rz;
  res[3] = this->Tworld(3);
  res[4] = this->Tworld(4);
  res[5] = this->Tworld(5);

  return res;
}

//-----------------------------------------------------------------------------
void vtkSlam::ResetAlgorithm()
{
  this->DisplayMode = true; // switch to false to improve speed
  this->NeighborWidth = 5; // size indicated in Zhang paper
  this->EgoMotionMaxIter = 25; // So that 4 icp will be made
  this->MaxEdgePerScanLine = 40;
  this->MaxPlanarsPerScanLine = 60;
  this->NbrFrameProcessed = 0;
  this->EgoMotionIterMade = 0;
  this->NLasers = 0;
  this->LaserIdMapping.clear();
  this->LaserIdMapping.resize(0);
  this->FromVTKtoPCLMapping.clear();
  this->FromVTKtoPCLMapping.resize(0);
  this->FromPCLtoVTKMapping.clear();
  this->FromPCLtoVTKMapping.resize(this->NLasers);
  this->Curvature.clear();
  this->Curvature.resize(this->NLasers);
  this->Gradient.clear();
  this->Gradient.resize(this->NLasers);
  this->SecondDiff.clear();
  this->SecondDiff.resize(this->NLasers);
  this->Angles.clear();
  this->Angles.resize(this->NLasers);
  this->DepthGap.clear();
  this->DepthGap.resize(this->NLasers);
  this->IsPointValid.clear();
  this->IsPointValid.resize(this->NLasers);
  this->Label.clear();
  this->Label.resize(this->NLasers);
  this->Tworld << 0, 0, 0, 0, 0, 0;

  this->I3 << 1, 0, 0,
              0, 1, 0,
              0, 0, 1;

  this->I6 << 1, 0, 0, 0, 0, 0,
              0, 1, 0, 0, 0, 0,
              0, 0, 1, 0, 0, 0,
              0, 0, 0, 1, 0, 0,
              0, 0, 0, 0, 1, 0,
              0, 0, 0, 0, 0, 1;

  // Represent the distance that the lidar has made during one sweep
  // if it is moving at a speed of 90 km/h and spinning at a rpm
  // of 600 rotation per minute
  this->MaxDistBetweenTwoFrames = (90.0 / 3.6) * (60.0 / 600.0);
}

//-----------------------------------------------------------------------------
void vtkSlam::PrepareDataForNextFrame()
{
  // Reset the pcl format pointcloud to store the new frame
  this->pclCurrentFrame.reset(new pcl::PointCloud<Point>());
  for (unsigned int k = 0; k < this->NLasers; ++k)
  {
    this->pclCurrentFrameByScan[k].reset(new pcl::PointCloud<Point>());
  }
  this->CurrentEdgesPoints.reset(new pcl::PointCloud<Point>());
  this->CurrentPlanarsPoints.reset(new pcl::PointCloud<Point>());

  // reset vtk <-> pcl id mapping
  this->FromVTKtoPCLMapping.clear();
  this->FromVTKtoPCLMapping.resize(0);
  this->FromPCLtoVTKMapping.clear();
  this->FromPCLtoVTKMapping.resize(this->NLasers);
  this->Curvature.clear();
  this->Curvature.resize(this->NLasers);
  this->Gradient.clear();
  this->Gradient.resize(this->NLasers);
  this->SecondDiff.clear();
  this->SecondDiff.resize(this->NLasers);
  this->Angles.clear();
  this->Angles.resize(this->NLasers);
  this->DepthGap.clear();
  this->DepthGap.resize(this->NLasers);
  this->IsPointValid.clear();
  this->IsPointValid.resize(this->NLasers);
  this->Label.clear();
  this->Label.resize(this->NLasers);

  this->EgoMotionIterMade = 0;
}

//-----------------------------------------------------------------------------
void vtkSlam::SetSensorCalibration(std::vector<int> mapping)
{
  this->NLasers = mapping.size();
  this->LaserIdMapping = mapping;
  this->pclCurrentFrameByScan.resize(this->NLasers);

  std::cout << "mapping is : " << std::endl;
  for (unsigned int k = 0; k < this->NLasers; ++k)
  {
    std::cout << k << " <--> " << this->LaserIdMapping[k] << std::endl;
  }
}

//-----------------------------------------------------------------------------
bool vtkSlam::GetIsSensorCalibrationProvided()
{
  return (this->NLasers > 0) && (this->LaserIdMapping.size() == this->NLasers);
}

//-----------------------------------------------------------------------------
void vtkSlam::DisplayLaserIdMapping(vtkSmartPointer<vtkPolyData> input)
{
  vtkDataArray* idsArray = input->GetPointData()->GetArray("laser_id");
  vtkSmartPointer<vtkIntArray> laserMappingArray = vtkSmartPointer<vtkIntArray>::New();
  laserMappingArray->Allocate(input->GetNumberOfPoints());
  laserMappingArray->SetName("laser_mapping");
  for (unsigned int k = 0; k < input->GetNumberOfPoints(); ++k)
  {
    int id = static_cast<int>(idsArray->GetTuple1(k));
    id = this->LaserIdMapping[id];
    laserMappingArray->InsertNextTuple1(id);
  }
  input->GetPointData()->AddArray(laserMappingArray);
}

//-----------------------------------------------------------------------------
void vtkSlam::DisplayRelAdv(vtkSmartPointer<vtkPolyData> input)
{
  vtkDataArray* idsArray = input->GetPointData()->GetArray("laser_id");
  vtkSmartPointer<vtkDoubleArray> relAdvArray = vtkSmartPointer<vtkDoubleArray>::New();
  relAdvArray->Allocate(input->GetNumberOfPoints());
  relAdvArray->SetName("relative_adv");
  for (unsigned int k = 0; k < input->GetNumberOfPoints(); ++k)
  {
    unsigned int scan = this->FromVTKtoPCLMapping[k].first;
    unsigned int index = this->FromVTKtoPCLMapping[k].second;
    relAdvArray->InsertNextTuple1(this->pclCurrentFrameByScan[scan]->points[index].intensity);
  }
  input->GetPointData()->AddArray(relAdvArray);
}

//-----------------------------------------------------------------------------
void vtkSlam::DisplayCurvatureScores(vtkSmartPointer<vtkPolyData> input)
{
  vtkSmartPointer<vtkDoubleArray> curvArray = vtkSmartPointer<vtkDoubleArray>::New();
  vtkSmartPointer<vtkDoubleArray> gradArray = vtkSmartPointer<vtkDoubleArray>::New();
  vtkSmartPointer<vtkDoubleArray> diffArray = vtkSmartPointer<vtkDoubleArray>::New();
  vtkSmartPointer<vtkDoubleArray> anglesArray = vtkSmartPointer<vtkDoubleArray>::New();
  vtkSmartPointer<vtkDoubleArray> depthArray = vtkSmartPointer<vtkDoubleArray>::New();
  vtkSmartPointer<vtkIntArray> indexArray = vtkSmartPointer<vtkIntArray>::New();
  vtkSmartPointer<vtkIntArray> indexArray2 = vtkSmartPointer<vtkIntArray>::New();
  vtkSmartPointer<vtkIntArray> idArray = vtkSmartPointer<vtkIntArray>::New();
  curvArray->Allocate(input->GetNumberOfPoints());
  curvArray->SetName("curvature");
  gradArray->Allocate(input->GetNumberOfPoints());
  gradArray->SetName("gradient_norm");
  diffArray->Allocate(input->GetNumberOfPoints());
  diffArray->SetName("second_derivation");
  anglesArray->Allocate(input->GetNumberOfPoints());
  anglesArray->SetName("angle_line");
  depthArray->Allocate(input->GetNumberOfPoints());
  depthArray->SetName("depth_gap");
  indexArray->Allocate(input->GetNumberOfPoints());
  indexArray->SetName("index_in_scanLine");
  indexArray2->Allocate(input->GetNumberOfPoints());
  indexArray2->SetName("index_in_scanLine2");
  idArray->Allocate(input->GetNumberOfPoints());
  idArray->SetName("iDLaser_of_points");
  for (unsigned int k = 0; k < input->GetNumberOfPoints(); ++k)
  {
    unsigned int scan = this->FromVTKtoPCLMapping[k].first;
    unsigned int index = this->FromVTKtoPCLMapping[k].second;
    curvArray->InsertNextTuple1(this->Curvature[scan][index].first);
    gradArray->InsertNextTuple1(this->Gradient[scan][index]);
    diffArray->InsertNextTuple1(this->SecondDiff[scan][index].first);
    anglesArray->InsertNextTuple1(this->Angles[scan][index].first);
    depthArray->InsertNextTuple1(this->DepthGap[scan][index].first);
    indexArray->InsertNextTuple1(index);
    indexArray2->InsertNextTuple1(0);
    idArray->InsertNextTuple1(this->pclCurrentFrameByScan[scan]->points[index].normal_y);
  }

  for (int scanLine = 0; scanLine < this->NLasers; ++scanLine)
  {
    for (int index = 0; index < this->pclCurrentFrameByScan[scanLine]->size(); ++index)
    {
      if (scanLine >= this->FromPCLtoVTKMapping.size())
      {
        std::cout << "Error in mapping nlaser" << std::endl;
        continue;
      }
      if (index >= this->FromPCLtoVTKMapping[scanLine].size())
      {
        std::cout << "Error in mapping number of points in line : " << scanLine << std::endl;
        continue;
      }

      int k = this->FromPCLtoVTKMapping[scanLine][index];

      if (k >= input->GetNumberOfPoints())
      {
        std::cout << "Error in mapping, k : " << k << " is over : " << input->GetNumberOfPoints() << " for scan : " << scanLine << " point : " << index << std::endl;
        continue;
      }
      
      indexArray2->SetValue(k, index);
    }
  }

  input->GetPointData()->AddArray(curvArray);
  input->GetPointData()->AddArray(gradArray);
  input->GetPointData()->AddArray(diffArray);
  input->GetPointData()->AddArray(anglesArray);
  input->GetPointData()->AddArray(depthArray);
  input->GetPointData()->AddArray(indexArray);
  input->GetPointData()->AddArray(indexArray2);
  input->GetPointData()->AddArray(idArray);
}

//-----------------------------------------------------------------------------
void vtkSlam::DisplayKeypointsResults(vtkSmartPointer<vtkPolyData> input)
{
  vtkSmartPointer<vtkIntArray> isValidArray = vtkSmartPointer<vtkIntArray>::New();
  vtkSmartPointer<vtkIntArray> labelArray = vtkSmartPointer<vtkIntArray>::New();
  isValidArray->Allocate(input->GetNumberOfPoints());
  isValidArray->SetName("is_point_valid");
  labelArray->Allocate(input->GetNumberOfPoints());
  labelArray->SetName("keypoint_label");
  for (unsigned int k = 0; k < input->GetNumberOfPoints(); ++k)
  {
    unsigned int scan = this->FromVTKtoPCLMapping[k].first;
    unsigned int index = this->FromVTKtoPCLMapping[k].second;
    isValidArray->InsertNextTuple1(this->IsPointValid[scan][index]);
    labelArray->InsertNextTuple1(this->Label[scan][index]);
  }
  input->GetPointData()->AddArray(isValidArray);
  input->GetPointData()->AddArray(labelArray);
}

//-----------------------------------------------------------------------------
void vtkSlam::OnlyComputeKeypoints(vtkSmartPointer<vtkPolyData> newFrame)
{
  this->PrepareDataForNextFrame();
  this->ConvertAndSortScanLines(newFrame);
  this->ComputeKeyPoints(newFrame);
}

//-----------------------------------------------------------------------------
void vtkSlam::AddFrame(vtkSmartPointer<vtkPolyData> newFrame)
{
  // Check if the number of lasers has been set
  if (this->NLasers == 0)
  {
    vtkGenericWarningMacro("Frame added without specifying the number of lasers");
  }
  std::cout << "Processing frame : " << this->NbrFrameProcessed << std:: endl;

  // Reset the members variables used during the last
  // processed frame so that they can be used again
  PrepareDataForNextFrame();

  // If the new frame is the first one we just add the
  // extracted keypoints into the map without running
  // odometry and mapping steps
  if (this->NbrFrameProcessed == 0)
  {
    std::cout << "Slam initialization" << std::endl;
    // Convert the new frame into pcl format and sort
    // the laser scan-lines by vertical angle
    this->ConvertAndSortScanLines(newFrame);

    // Compute the edges and planars keypoints
    this->ComputeKeyPoints(newFrame);

    // Current keypoints become previous ones
    this->PreviousEdgesPoints = this->CurrentEdgesPoints;
    this->PreviousPlanarsPoints = this->CurrentPlanarsPoints;
    this->NbrFrameProcessed++;
    return;
  }

  // Convert the new frame into pcl format and sort
  // the laser scan-lines by vertical angle
  this->InitTime();
  this->ConvertAndSortScanLines(newFrame);
  this->StopTimeAndDisplay("Sorting lines");

  // Compute the edges and planars keypoints
  this->InitTime();
  this->ComputeKeyPoints(newFrame);
  this->StopTimeAndDisplay("Keypoints extraction");

  // Perfom EgoMotion
  this->InitTime();
  this->ComputeEgoMotion();
  this->StopTimeAndDisplay("Ego-Motion");

  // Transform the current keypoints to the
  // referential of the sensor at the end of
  // frame acquisition
  this->InitTime();
  //this->TransformCurrentKeypointsToEnd();
  this->StopTimeAndDisplay("Undistortion");

  // Current keypoints become previous ones
  this->PreviousEdgesPoints = this->CurrentEdgesPoints;
  this->PreviousPlanarsPoints = this->CurrentPlanarsPoints;
  this->NbrFrameProcessed++;

  // Information
  Eigen::Matrix<double, 3, 1> angles, trans;
  angles << this->Trelative(0), this->Trelative(1), this->Trelative(2);
  trans << this->Trelative(3), this->Trelative(4), this->Trelative(5);

  angles = angles * 1.0 / vtkMath::Pi() * 180.0;
  std::cout << "Odometry : " << std::endl;
  std::cout << "angles : " << std::endl << angles << std::endl;
  std::cout << "trans : " << std::endl << trans << std::endl;

  angles << this->Tworld(0), this->Tworld(1), this->Tworld(2);
  trans << this->Tworld(3), this->Tworld(4), this->Tworld(5);
  angles = angles * 1.0 / vtkMath::Pi() * 180.0;
  std::cout << "World : " << std::endl;
  std::cout << "angles : " << std::endl << angles << std::endl;
  std::cout << "trans : " << std::endl << trans << std::endl;

  return;
}

//-----------------------------------------------------------------------------
void vtkSlam::ConvertAndSortScanLines(vtkSmartPointer<vtkPolyData> input)
{
  if (this->DisplayMode)
  {
    this->DisplayLaserIdMapping(input);
  }
  // temp var
  double xL[3]; // in {L}
  Point yL; // in {L}

  // Get informations about input pointcloud
  vtkDataArray* lasersId = input->GetPointData()->GetArray("laser_id");
  vtkDataArray* time = input->GetPointData()->GetArray("timestamp");
  vtkPoints* Points = input->GetPoints();
  unsigned int Npts = input->GetNumberOfPoints();
  double t0 = static_cast<double>(time->GetTuple1(0));
  double t1 = static_cast<double>(time->GetTuple1(Npts - 1));
  this->FromVTKtoPCLMapping.resize(Npts);


  for (unsigned int index = 0; index < Npts; ++index)
  {
    // Get information about current point
    Points->GetPoint(index, xL);
    yL.x = xL[0];
    yL.y = xL[1];
    yL.z = xL[2];

    double relAdv = (static_cast<double>(time->GetTuple1(index)) - t0) / (t1 - t0);
    unsigned int id = static_cast<int>(lasersId->GetTuple1(index));
    id = this->LaserIdMapping[id];
    yL.intensity = relAdv;
    yL.normal_y = id;

    // add the current point to its corresponding laser scan
    this->pclCurrentFrameByScan[id]->push_back(yL);
    this->FromVTKtoPCLMapping[index] = std::pair<int, int>(id, this->pclCurrentFrameByScan[id]->size() - 1);
    this->FromPCLtoVTKMapping[id].push_back(index);
  }

  if (DisplayMode)
  {
    this->DisplayRelAdv(input);
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeKeyPoints(vtkSmartPointer<vtkPolyData> input)
{
  // Initialize the vectors with the correct length
  for (unsigned int k = 0; k < this->NLasers; ++k)
  {
    this->Curvature[k].resize(this->pclCurrentFrameByScan[k]->size(), std::pair<double, int>(0, 0));
    this->Gradient[k].resize(this->pclCurrentFrameByScan[k]->size(), 0);
    this->SecondDiff[k].resize(this->pclCurrentFrameByScan[k]->size(), std::pair<double, int>(0, 0));
    this->IsPointValid[k].resize(this->pclCurrentFrameByScan[k]->size(), 1);
    this->Label[k].resize(this->pclCurrentFrameByScan[k]->size(), 0);
    this->Angles[k].resize(this->pclCurrentFrameByScan[k]->size(), std::pair<double, int>(0, 0));
    this->DepthGap[k].resize(this->pclCurrentFrameByScan[k]->size(), std::pair<double, int>(0, 0));
  }

  // compute keypoints scores
  this->ComputeCurvature(input);

  // Invalid points with bad criteria
  this->InvalidPointWithBadCriteria();

  // labelize keypoints
  this->SetKeyPointsLabels(input);

  // Display keypoints results
  if (this->DisplayMode)
  {
    this->DisplayKeypointsResults(input);
  }

}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeCurvature(vtkSmartPointer<vtkPolyData> input)
{
  // loop over scans lines
  for (unsigned int scanLine = 0; scanLine < this->NLasers; ++scanLine)
  {
    // loop over points in the current scan line
    int Npts = this->pclCurrentFrameByScan[scanLine]->size();

    // if the line is almost empty, skip it
    if (Npts < 3 * this->NeighborWidth)
    {
      continue;
    }

    for (int index = this->NeighborWidth; index < Npts - this->NeighborWidth - 1; ++index)
    {
      Eigen::Matrix<double, 3, 1> projdX; // first derivation of scan line
      Eigen::Matrix<double, 3, 1> projd2X; // second derivation of scan line
      Eigen::Matrix<double, 3, 1> d2X; // second derivation of scan line
      projdX << 0, 0, 0;
      projd2X << 0, 0, 0;
      d2X << 0, 0, 0;

      Point currentPoint = this->pclCurrentFrameByScan[scanLine]->points[index];
      Eigen::Matrix<double, 3, 1> X; // Point in {L}
      Eigen::Matrix<double, 3, 1> projX; // Projection onto (X, Y) plane

      // 
      X << currentPoint.x, currentPoint.y, currentPoint.z;
      projX << X(0), X(1), 0;
      projX = X.norm() / projX.norm() * projX;
      projd2X -= (2.0 * this->NeighborWidth + 1) * projX; // +1 to handle when j = index
      d2X -= (2.0 * this->NeighborWidth + 1) * X; // +1 to handle when j = index

      // Compute derivative
      for (int j = index - this->NeighborWidth; j <= index + this->NeighborWidth; ++j)
      {
        currentPoint = this->pclCurrentFrameByScan[scanLine]->points[j];
        X << currentPoint.x, currentPoint.y, currentPoint.z;
        projX << X(0), X(1), 0;
        projX = X.norm() / projX.norm() * projX; // rescaling to take into account vertical angle

        d2X += X;
        projd2X += projX;

        if (j < index)
        {
          projdX -= projX;
        }
          
        if (j > index)
        {
          projdX += projX;
        }
      }

      this->Curvature[scanLine][index].first = std::abs((projdX(0) * d2X(1) - projdX(1) * d2X(0)) / (std::sqrt(std::pow(projdX.norm(), 3))));
      this->Curvature[scanLine][index].second = index;
      this->SecondDiff[scanLine][index].first = std::pow(d2X.norm(), 2);
      this->SecondDiff[scanLine][index].second = index;
      this->Gradient[scanLine][index] = projdX.norm();

      /*int width = this->NeighborWidth - 1;
      // line fitting left and right
      Eigen::MatrixXd M1(width, 2);
      Eigen::MatrixXd M2(width, 2);
      Eigen::Matrix<double, 3, 1> mean1, mean2;
      mean1 << 0, 0, 0; mean2 << 0, 0, 0;
      for (int j = 0; j < width; ++j)
      {
        int J1 = index + j + 1;
        int J2 = index - j - 1;
        Eigen::Matrix<double, 3, 1> X, projX;

        // Right side
        Point currentPoint = this->pclCurrentFrameByScan[scanLine]->points[J1];
        X << currentPoint.x, currentPoint.y, currentPoint.z;
        projX << X(0), X(1), 0;
        projX = X.norm() / projX.norm() * projX;
        mean1 += projX;
        M1(j, 0) = projX(0);
        M1(j, 1) = projX(1);

        // Left side
        currentPoint = this->pclCurrentFrameByScan[scanLine]->points[J2];
        X << currentPoint.x, currentPoint.y, currentPoint.z;
        projX << X(0), X(1), 0;
        projX = X.norm() / projX.norm() * projX;
        mean2 += projX;
        M2(j, 0) = projX(0);
        M2(j, 1) = projX(1);
      }

      mean1 = mean1 / static_cast<double>(width);
      mean2 = mean2 / static_cast<double>(width);
      // mean-shifting
      for(int i = 0; i < width; ++i)
      {
        M1(i, 0) -= mean1(0);
        M1(i, 1) -= mean1(1);
        M2(i, 0) -= mean2(0);
        M2(i, 1) -= mean2(1);
      }

      Eigen::Matrix<double, 2, 2> G1 = M1.transpose() * M1;
      Eigen::Matrix<double, 2, 2> G2 = M2.transpose() * M2;

      // Eigen values
      Eigen::MatrixXd D1(1,2), D2(1, 2);
      // Eigen vectors
      Eigen::MatrixXd V1(2,2), V2(2, 2);

      Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> es1(G1);
      Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> es2(G2);
      D1 = es1.eigenvalues();
      V1 = es1.eigenvectors();
      D2 = es2.eigenvalues();
      V2 = es2.eigenvectors();

      Eigen::Matrix<double, 3, 1> u1, u2;
      u1 << V1(0, 1), V1(1, 1), 0;
      u2 << V2(0, 1), V2(1, 1), 0;
      u1.normalized();
      u2.normalized();*/

      //this->Angles[scanLine][index].first = std::abs((u1.cross(u2)).norm());
      //this->DepthGap[scanLine][index].first = std::abs(mean1.norm() - mean2.norm());
      //this->Angles[scanLine][index].second = index;
      //this->DepthGap[scanLine][index].second = index;
    }
  }

  if (this->DisplayMode)
  {
    this->DisplayCurvatureScores(input);
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::InvalidPointWithBadCriteria()
{
  // Temporary variables used in the next loop
  Eigen::Matrix<double, 3, 1> dX, X, Xn, Xp;
  double dL, L, Ln, expectedLength, dLn, dLp;
  Point currentPoint, nextPoint, previousPoint;
  // azimutal resolution of the VLP-16. We add an extra 20 %
  double const angleResolution = 1.2 * (0.4 / 180.0 * vtkMath::Pi());

  // loop over scan lines
  for (unsigned int scanLine = 0; scanLine < this->NLasers; ++scanLine)
  {
    int Npts = this->pclCurrentFrameByScan[scanLine]->size();

    // if the line is almost empty, skip it
    if (Npts < 3 * this->NeighborWidth)
    {
      continue;
    }
    // invalidate first and last points
    for (int index = 0; index <= this->NeighborWidth; ++index)
    {
      this->IsPointValid[scanLine][index] = 0;
    }
    for (int index = Npts - 1 - this->NeighborWidth - 1; index < Npts; ++index)
    {
      this->IsPointValid[scanLine][index] = 0;
    }

    // loop over points into the scan line
    for (int index = this->NeighborWidth; index <  Npts - this->NeighborWidth - 1; ++index)
    {
      currentPoint = this->pclCurrentFrameByScan[scanLine]->points[index];
      nextPoint = this->pclCurrentFrameByScan[scanLine]->points[index + 1];
      previousPoint = this->pclCurrentFrameByScan[scanLine]->points[index - 1];
      X << currentPoint.x, currentPoint.y, currentPoint.z;
      Xn << nextPoint.x, nextPoint.y, nextPoint.z;
      Xp << previousPoint.x, previousPoint.y, previousPoint.z;
      dX = Xn - X;
      L = X.norm();
      Ln = Xn.norm();
      dLn = dX.norm();

      // the expected length between two firing of the same laser
      // depend on the distance and the angular resolution of the
      // sensor.
      expectedLength = 2.0 *  std::tan(angleResolution / 2.0) * L;

      // if the length between the two firing
      // if more than n-th the expected length
      // it means that there is a gap. We now must
      // determine if the gap is due to the geometry of
      // the scene or if the gap is due to an occluded area
      if (dLn > 5 * expectedLength)
      {
        // keep the left side since the right
        // side is occluded
        if (Ln > L)
        {
          // Project the next point onto the
          // sphere of center 0 and radius =
          // norm of the current point. If the
          // gap has disappeared it means that
          // the gap was due to an occlusion
          dX = L / Ln * Xn - X;
          dL = dX.norm();
          if (dL < 5 * expectedLength)
          {
            for (unsigned int j = index + 1; j < index + 1 + this->NeighborWidth; ++j)
            {
              this->IsPointValid[scanLine][j] = 0;
            }
          }
        }
        // keep the right side since the
        // left side is occluded
        else
        {
          // Project the current point onto the
          // sphere of center 0 and radius =
          // norm of the next point. If the
          // gap has disappeared it means that
          // the gap was due to an occlusion
          dX = Xn - Ln / L * X;
          dL = dX.norm();
          if (dL < 5 * expectedLength)
          {
            for (unsigned int j = index - this->NeighborWidth; j <= index; ++j)
            {
              this->IsPointValid[scanLine][j] = 0;
            }
          }
        }
      }
      // Invalid points which are too close from the sensor
      if (L < 3.0)
      {
        this->IsPointValid[scanLine][index] = 0;
      }

      // Invalid points which are on a planar
      // surface nearly parallel to the laser
      // beam direction
      dLp = (X - Xp).norm();
      if ((dLp > 1.0 * expectedLength) && (dLn > 1.0 * expectedLength))
      {
        this->IsPointValid[scanLine][index] = 0;
      }
    }
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::SetKeyPointsLabels(vtkSmartPointer<vtkPolyData> input)
{
  std::vector<std::pair<int, int> > edgesIndex;
  std::vector<std::pair<int, int> > planarIndex;

  // loop over the scan lines
  for (unsigned int scanLine = 0; scanLine < this->NLasers; ++scanLine)
  {
    int Npts = this->pclCurrentFrameByScan[scanLine]->size();
    unsigned int nbrEdgePicked = 0;
    unsigned int nbrPlanarPicked = 0;

    // if the line is almost empty, skip it
    if (Npts < 3 * this->NeighborWidth)
    {
      continue;
    }

    // Sort the curvature score in a decreasing order
    std::sort(this->Curvature[scanLine].begin(), this->Curvature[scanLine].end(), std::greater<std::pair<double, int> >());
    std::sort(this->DepthGap[scanLine].begin(), this->DepthGap[scanLine].end(), std::greater<std::pair<double, int> >());
    std::sort(this->Angles[scanLine].begin(), this->Angles[scanLine].end(), std::greater<std::pair<double, int> >());
    std::sort(this->SecondDiff[scanLine].begin(), this->SecondDiff[scanLine].end(), std::greater<std::pair<double, int> >());

    double depthGap = 0;
    double sinAngle = 0;
    double curvature = 0;
    int index = 0;

    // Edges
    for (int k = 0; k < Npts; ++k)
    {
      curvature = this->SecondDiff[scanLine][k].first;
      index = this->SecondDiff[scanLine][k].second;

      // max keypoints reached
      if (nbrEdgePicked >= this->MaxEdgePerScanLine)
      {
        break;
      }

      // thresh
      double curvThresh = 1.0 / 4.0; // 4 meters radius
      if (curvature < 0.1)
      {
        break;
      }

      // if the point is invalid continue
      if (this->IsPointValid[scanLine][index] == 0)
      {
        continue;
      }

      // else indicate that the point is an edge
      this->Label[scanLine][index] = 4;
      edgesIndex.push_back(std::pair<int, int>(scanLine, index));
      nbrEdgePicked++;

      // invalid its neighborhod
      int indexBegin = index - this->NeighborWidth;
      int indexEnd = index + this->NeighborWidth;
      indexBegin = std::max(0, indexBegin);
      indexEnd = std::min(Npts - 1, indexEnd);
      for (int j = indexBegin; j <= indexEnd; ++j)
      {
        this->IsPointValid[scanLine][j] = 0;
      }
    }

    // Planes
    for (int k = Npts - 1; k >= 0; --k)
    {
      curvature = this->SecondDiff[scanLine][k].first;
      index = this->SecondDiff[scanLine][k].second;

      // max keypoints reached
      if (nbrPlanarPicked >= this->MaxPlanarsPerScanLine)
      {
        //break;
      }

      // thresh
      double curvThresh = 1.0 / 15.0; // 15 meters radius
      if (curvature > 0.1)
      {
        break;
      }

      // if the point is invalid continue
      if (this->IsPointValid[scanLine][index] == 0)
      {
        continue;
      }

      // else indicate that the point is a planar one
      this->Label[scanLine][index] = 2;
      planarIndex.push_back(std::pair<int, int>(scanLine, index));
      this->IsPointValid[scanLine][index] = 0;

      // Invalid its neighbor so that we don't have too
      // many palanr keypoints in the same region. This is
      // required because of the k-nearest search + plane
      // approximation realized in the odometry part. Indeed,
      // if tall the planar points are on the same scan line the
      //  problem is degenerated since all the points are distributed
      // on a line.
      for (int j = index - 4; j <= index + 4; ++j)
      {
        this->IsPointValid[scanLine][j] = 0;
      }
      nbrPlanarPicked++;
    }
  }

  // add keypoints in increasing scan id order
  std::sort(edgesIndex.begin(), edgesIndex.end());
  std::sort(planarIndex.begin(), planarIndex.end());
  for (unsigned int k = 0; k < edgesIndex.size(); ++k)
  {
    this->CurrentEdgesPoints->push_back(this->pclCurrentFrameByScan[edgesIndex[k].first]->points[edgesIndex[k].second]);
  }
  for (unsigned int k = 0; k < planarIndex.size(); ++k)
  {
    this->CurrentPlanarsPoints->push_back(this->pclCurrentFrameByScan[planarIndex[k].first]->points[planarIndex[k].second]);
  }

  std::cout << "Extracted : " << this->CurrentEdgesPoints->size() << " : edges points" << std::endl;
  std::cout << "Extracted : " << this->CurrentPlanarsPoints->size() << " : planars points" << std::endl;
}

//-----------------------------------------------------------------------------
void vtkSlam::TransformToStart(Point& pi, Point& pf, Eigen::Matrix<double, 6, 1>& T)
{
  // Remember, the intensity is the relative time
  // Hence s worth the relTime
  double s = pi.intensity;
  Eigen::Matrix<double, 3, 1> P0, P1;
  P0 << pi.x, pi.y, pi.z;
  this->TransformToStart(P0, P1, s, T);
  pf.x = P1(0);
  pf.y = P1(1);
  pf.z = P1(2);
}

//-----------------------------------------------------------------------------
void vtkSlam::TransformToStart(Eigen::Matrix<double, 3, 1>& Xi, Eigen::Matrix<double, 3, 1>& Xf, double s, Eigen::Matrix<double, 6, 1>& T)
{
  // Linearly interpolate the motion estimation depending
  // on the time at which the point has been acquired. This
  // interpolation assumes that during a sweep of the lidar the
  // angular velocity and the velocity are constant. This assumption
  // is pertinent as long as the sensor do not undergone strong
  // acceleration
  Eigen::Matrix<double, 6, 1> sT = s * T;

  Eigen::Matrix<double, 3, 3> R;
  Eigen::Matrix<double, 3, 1> dT;
  
  // full rotation
  R = GetRotationMatrix(sT);
  dT << sT(3), sT(4), sT(5);

  // Express the current point acquired at time t1
  // in the referential of the sensor at time t0.
  Xf = R * Xi + dT;
}

//-----------------------------------------------------------------------------
void vtkSlam::TransformToEnd(Point& pi, Point& pf, Eigen::Matrix<double, 6, 1>& T)
{
  // first transform to start
  Point ptemp;
  this->TransformToStart(pi, ptemp, T);

  // then transform to end using the estimated transformation
  // since the first transformation has distorted the point cloud
  // there is no need to interpolate again
  Eigen::Matrix<double, 3, 3> R;
  Eigen::Matrix<double, 3, 1> dT, P0, P1;
  P0 << ptemp.x, ptemp.y, ptemp.z;

  R = GetRotationMatrix(T);
  dT << T(3), T(4), T(5);
  P1 = R.transpose() * (P0 - dT);
  pf.x = P1(0);
  pf.y = P1(1);
  pf.z = P1(2);
}

//-----------------------------------------------------------------------------
void vtkSlam::TransformCurrentKeypointsToEnd()
{
  Point currentPoint, transformedPoint;
  // transform edges and planars keypoints
  for (unsigned int k = 0; k < this->CurrentEdgesPoints->size(); ++k)
  {
    currentPoint = this->CurrentEdgesPoints->points[k];
    this->TransformToEnd(currentPoint, transformedPoint, this->Trelative);
    this->CurrentEdgesPoints->points[k] = transformedPoint;
  }
  for (unsigned int k = 0; k < this->CurrentPlanarsPoints->size(); ++k)
  {
    currentPoint = this->CurrentPlanarsPoints->points[k];
    this->TransformToEnd(currentPoint, transformedPoint, this->Trelative);
    this->CurrentPlanarsPoints->points[k] = transformedPoint;
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::FindEdgeLineMatch(Point p, pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousEdges,
                                std::vector<int>& matchEdgeIndex1, std::vector<int>& matchEdgeIndex2, int currentEdgeIndex,
                                Eigen::Matrix<double, 3, 3> R, Eigen::Matrix<double, 3, 1> dT)
{
  // transform point using current estimation
  Eigen::Matrix<double, 3, 1> P;
  P << p.x, p.y, p.z;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);

  Point p1, p2;
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;
  
  // Search the nearests points of the current point reprojected
  // nearestIndex is the index of the nearest pointsd found
  // nearestDist is their corresponding distances
  kdtreePreviousEdges->nearestKSearch(p, 1, nearestIndex, nearestDist);

  // closest point index
  int closestPointIndex = -1;
  int secondPointIndex = -1;
  matchEdgeIndex1[currentEdgeIndex] = -1;
  matchEdgeIndex2[currentEdgeIndex] = -1;

  // max distance allowed between two frames. It depends on the
  // sensor speed and the sensor RPM. It is not automatically computed
  // the value of MaxDistBetweenTwoFrames should be set. By default
  // it is set to 2.5 meters (90 km/h at 600 RPM)
  if (static_cast<double>(nearestDist[0]) < this->MaxDistBetweenTwoFrames)
  {
    // take the closest point
    closestPointIndex = nearestIndex[0];
    p1 = this->PreviousEdgesPoints->points[closestPointIndex];

    // Avoid SegFault when the kd-tree doesn't find the cloest point
    // it is due to a point p with -1.#IND values sometimes
    if(closestPointIndex > this->PreviousEdgesPoints->size()-1)
    {
      std::cout << "Edges correspondances error" << std::endl;
      std::cout << "closestPointInd : " << closestPointIndex << std::endl;
      std::cout << "point : [" << p.x << ";" << p.y << ";" << p.z << "]" << std::endl;
      return;
    }

    // get the ID of the closest scan line of the closest point
    int iD = p1.normal_y;

    // VLP-16: 2 scan line gap
    // VLP-32: 4 scan line gap
    // HDL-64: 8 scan line gap
    int maxScanIdStep = this->NLasers / 8;
    double minDist = 2.0 * this->MaxDistBetweenTwoFrames;

    // now find the second closest point that belong to an other
    // scan line. The keypoints are sorted using scan id.
    for (int pointIndex = closestPointIndex + 1; pointIndex < this->PreviousEdgesPoints->size(); ++pointIndex)
    {
      if (pointIndex > this->PreviousEdgesPoints->size() - 1)
      {
        break;
      }

      Point candidate = this->PreviousEdgesPoints->points[pointIndex];
      bool shouldSkip = (static_cast<int>(candidate.normal_y) == iD);
      bool shouldBreak = static_cast<int>(candidate.normal_y) > iD + maxScanIdStep;

      if (shouldBreak)
      {
        break;
      }
      if (!shouldSkip)
      {
        // compute the distance
        double dist = (p.x - candidate.x) * (p.x - candidate.x) + (p.y - candidate.y) * (p.y - candidate.y) + (p.z - candidate.z) * (p.z - candidate.z);
        if (dist < minDist)
        {
          minDist = dist;
          secondPointIndex = pointIndex;
        }
      }
    }
    for (int pointIndex = closestPointIndex - 1; pointIndex >= 0; --pointIndex)
    {
      if (pointIndex < 0)
      {
        break;
      }

      Point candidate = this->PreviousEdgesPoints->points[pointIndex];
      bool shouldSkip = (static_cast<int>(candidate.normal_y) == iD);
      bool shouldBreak = static_cast<int>(candidate.normal_y) < iD - maxScanIdStep;
      if (shouldBreak)
      {
        break;
      }
      if (!shouldSkip)
      {
        // compute the distance
        double dist = (p.x - candidate.x) * (p.x - candidate.x) + (p.y - candidate.y) * (p.y - candidate.y) + (p.z - candidate.z) * (p.z - candidate.z);

        if (dist < minDist)
        {
          minDist = dist;
          secondPointIndex = pointIndex;
        }
      }
    }
  }
  else
  {
    return;
  }

  if (secondPointIndex == -1)
  {
    return;
  }

  matchEdgeIndex1[currentEdgeIndex] = closestPointIndex;
  matchEdgeIndex2[currentEdgeIndex] = secondPointIndex;
  return;
}

//-----------------------------------------------------------------------------
void vtkSlam::FindPlaneMatch(Point p, pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousPlanes,
                      std::vector<int>& matchPlaneIndex1, std::vector<int>& matchPlaneIndex2,
                      std::vector<int>& matchPlaneIndex3, int currentPlaneIndex,
                      Eigen::Matrix<double, 3, 3> R, Eigen::Matrix<double, 3, 1> dT)
{
  // transform point using current estimation
  Eigen::Matrix<double, 3, 1> P;
  P << p.x, p.y, p.z;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);

  Point p1, p2, p3;
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;

  // Here we are looking for 3 points to define a plane. The first one is the closest point 
  // of the current planar point. The two others are the minPoint in the same scan and in another scan
  int closestPointIndex = -1;
  int secondPointIndex = -1;
  int thirdPointIndex = -1;

  // reset previous index
  matchPlaneIndex1[currentPlaneIndex] = -1;
  matchPlaneIndex2[currentPlaneIndex] = -1;
  matchPlaneIndex3[currentPlaneIndex] = -1;

  // Find the closest point
  kdtreePreviousPlanes->nearestKSearch(p, 1, nearestIndex, nearestDist);

  // max distance allowed between two frames. It depends on the
  // sensor speed and the sensor RPM. It is not automatically computed
  // the value of MaxDistBetweenTwoFrames should be set. By default
  // it is set to 2.5 meters (90 km/h at 600 RPM)
  if (static_cast<double>(nearestDist[0]) < 2.0 * this->MaxDistBetweenTwoFrames)
  {
    closestPointIndex = nearestIndex[0];
    if(closestPointIndex > this->PreviousPlanarsPoints->size() - 1 || closestPointIndex < 0)
    {
      std::cout << "Flat correspondances error" << std::endl;
      std::cout << "closestPointInd : " << closestPointIndex << std::endl;
      std::cout << "point : [" << p.x << ";" << p.y << ";" << p.z << "]" << std::endl;
      return;
    }

    p1 = this->PreviousPlanarsPoints->points[closestPointIndex];

    // We get the id of the closest scan laser line
    int iD = p1.normal_y; 

    // VLP-16: 2 scan line gap
    // VLP-32: 4 scan line gap
    // HDL-64: 8 scan line gap
    int maxScanIdStep = this->NLasers / 8;
    double minDist2 = 4.0 * this->MaxDistBetweenTwoFrames;
    double minDist3 = 4.0 * this->MaxDistBetweenTwoFrames;

    // now find the second closest point that belong to an other
    // scan line. The keypoints are sorted using scan id.
    for (int pointIndex = closestPointIndex + 1; pointIndex < this->PreviousPlanarsPoints->size(); ++pointIndex)
    {
      if (pointIndex > this->PreviousEdgesPoints->size() - 1)
      {
        break;
      }

      Point candidate = this->PreviousPlanarsPoints->points[pointIndex];
      bool isSameScan = (static_cast<int>(candidate.normal_y) == iD);
      bool shouldBreak = static_cast<int>(candidate.normal_y) > iD + maxScanIdStep;

      if (shouldBreak)
      {
        break;
      }

      // compute the distance
      double dist = (p.x - candidate.x) * (p.x - candidate.x) + (p.y - candidate.y) * (p.y - candidate.y) + (p.z - candidate.z) * (p.z - candidate.z);
      if (isSameScan)
      {
        if (dist < minDist2)
        {
          minDist2 = dist;
          secondPointIndex = pointIndex;
        }
      }
      else
      {
        if (dist < minDist3)
        {
          minDist3 = dist;
          thirdPointIndex = pointIndex;
        }
      }
    }
    // left side
    for (int pointIndex = closestPointIndex - 1; pointIndex >= 0; --pointIndex)
    {
      if (pointIndex < 0)
      {
        break;
      }

      Point candidate = this->PreviousPlanarsPoints->points[pointIndex];
      bool isSameScan = (static_cast<int>(candidate.normal_y) == iD);
      bool shouldBreak = static_cast<int>(candidate.normal_y) < iD - maxScanIdStep;

      if (shouldBreak)
      {
        break;
      }

      // compute the distance
      double dist = (p.x - candidate.x) * (p.x - candidate.x) + (p.y - candidate.y) * (p.y - candidate.y) + (p.z - candidate.z) * (p.z - candidate.z);
      if (isSameScan)
      {
        if (dist < minDist2)
        {
          minDist2 = dist;
          secondPointIndex = pointIndex;
        }
      }
      else
      {
        if (dist < minDist3)
        {
          minDist3 = dist;
          thirdPointIndex = pointIndex;
        }
      }
    }
  }

  matchPlaneIndex1[currentPlaneIndex] = closestPointIndex;
  matchPlaneIndex2[currentPlaneIndex] = secondPointIndex;
  matchPlaneIndex3[currentPlaneIndex] = thirdPointIndex;
  return;
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeLineDistanceParameters(std::vector<int>& matchEdgeIndex1, std::vector<int>& matchEdgeIndex2, unsigned int edgeIndex)
{
  Point p, p1, p2;
  Eigen::Matrix<double, 3, 1> P1, P2, n, X;
  Eigen::Matrix<double, 3, 3> A;
  
  // if the current keypoint has not corresponding line match
  if ((matchEdgeIndex1[edgeIndex] == -1) || (matchEdgeIndex2[edgeIndex] == -1))
  {
    return;
  }

  p = this->CurrentEdgesPoints->points[edgeIndex];
  p1 = this->PreviousEdgesPoints->points[matchEdgeIndex1[edgeIndex]];
  p2 = this->PreviousEdgesPoints->points[matchEdgeIndex2[edgeIndex]];
  X << p.x, p.y, p.z;
  P1 << p1.x, p1.y, p1.z;
  P2 << p2.x, p2.y, p2.z;

  // n is the director vector of the line
  n = (P2 - P1).normalized();

  // A = (I-n*n.t).t * (I-n*n.t) = (I - n*n.t)^2
  // since (I-n*n.t) is a symmetric matrix.
  A = (this->I3 - n * n.transpose());
  A = A.transpose() * A;

  // it would be the case if P1 = P2 For instance
  // if the sensor has some dual returns that hit the same point
  if (!vtkMath::IsFinite(A(0, 0)))
  {
    return;
  }

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(P1);
  this->Xvalues.push_back(X);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputePlaneDistanceParameters(std::vector<int>& matchPlaneIndex1, std::vector<int>& matchPlaneIndex2, std::vector<int>& matchPlaneIndex3, unsigned int planarIndex)
{
  Point p, p1, p2, p3;
  Eigen::Matrix<double, 3, 1> P1, P2, P3, n, X;
  Eigen::Matrix<double, 3, 3> A;
  
  // if the current keypoint has not corresponding
  // plane match
  if ((matchPlaneIndex1[planarIndex] == -1) || (matchPlaneIndex2[planarIndex] == -1) || (matchPlaneIndex3[planarIndex] == -1))
  {
    return;
  }

  if (matchPlaneIndex1[planarIndex] < 0 || matchPlaneIndex2[planarIndex] < 0 || matchPlaneIndex3[planarIndex] < 0)
  {
    return;
  }
  if (matchPlaneIndex1[planarIndex] >= this->PreviousPlanarsPoints->size() ||
      matchPlaneIndex2[planarIndex] >= this->PreviousPlanarsPoints->size() ||
      matchPlaneIndex3[planarIndex] >= this->PreviousPlanarsPoints->size())
  {
    return;
  }

  p = this->CurrentPlanarsPoints->points[planarIndex];
  p1 = this->PreviousPlanarsPoints->points[matchPlaneIndex1[planarIndex]];
  p2 = this->PreviousPlanarsPoints->points[matchPlaneIndex2[planarIndex]];
  p3 = this->PreviousPlanarsPoints->points[matchPlaneIndex3[planarIndex]];
  X << p.x, p.y, p.z;
  P1 << p1.x, p1.y, p1.z;
  P2 << p2.x, p2.y, p2.z;
  P3 << p3.x, p3.y, p3.z;

  // n is the director vector of the line
  n = ((P3 - P1).cross(P2 - P1)).normalized();

  // A = n*n.t
  A = n * n.transpose();

  // it would be the case if P1 = P2, P1 = P3
  // or P3 = P2. For instance if the sensor has
  // some dual returns that hit the same point
  if (!vtkMath::IsFinite(A(0, 0)))
  {
    return;
  }

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(P1);
  this->Xvalues.push_back(X);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeLineDistanceParametersAccurate(pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousEdges, Eigen::Matrix<double, 3, 3>& R,
                                                    Eigen::Matrix<double, 3, 1>& dT, Point p)
{
  // number of neighbors edge points required to approximate
  // the corresponding egde line
  unsigned int requiredNearest = 4;
  if (this->NLasers > 16)
    requiredNearest = 5;

  Eigen::Matrix<double, 3, 1> P0, P, P1, n, X;
  Eigen::Matrix<double, 3, 3> A;

  // Transform the point using the current pose estimation
  P << p.x, p.y, p.z;
  P0 = P;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);
  
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;
  kdtreePreviousEdges->nearestKSearch(p, requiredNearest, nearestIndex, nearestDist);

  // if the nearest edges are too far from the
  // current edge keypoint we skip this point.
  if (nearestDist[requiredNearest - 1] > 2.0)
  {
    return;
  }

  // Compute PCA to determine best line approximation
  // of the requiredNearest nearest edges points extracted
  // Thans to the PCA we will check the shape of the neighborhood
  // and keep it if it is distributed along a line
  Eigen::MatrixXd M(requiredNearest, 3);
  Eigen::Matrix<double, 3, 1> mean;
  mean << 0, 0, 0;
  for (unsigned int k = 0; k < requiredNearest; ++k)
  {
    p = this->PreviousEdgesPoints->points[nearestIndex[k]];
    X << p.x, p.y, p.z;
    mean += X;
    M(k, 0) = X(0);
    M(k, 1) = X(1);
    M(k, 2) = X(2);
  }

  mean /= static_cast<double>(requiredNearest);
  for (unsigned int k = 0; k < requiredNearest; ++k)
  {
    M(k, 0) -= mean(0);
    M(k, 1) -= mean(1);
    M(k, 2) -= mean(2);
  }
  Eigen::Matrix<double, 3, 3> G = M.transpose() * M;

  // Eigen values
  Eigen::MatrixXd D(1,3);
  // Eigen vectors
  Eigen::MatrixXd V(3,3);

  Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> es(G);
  D = es.eigenvalues();
  V = es.eigenvectors();

  // if the first eigen value is significantly higher than
  // the second one, it means the sourrounding points are 
  // distributed on a edge line
  if (D(2, 0) > 30 * D(1, 0))
  {
    // n is the director vector of the line
    n(0) = V(0, 2);
    n(1) = V(1, 2);
    n(2) = V(2, 2);
    n.normalized();
  }
  else
  {
    return;
  }

  // A = (I-n*n.t).t * (I-n*n.t) = (I - n*n.t)^2
  // since (I-n*n.t) is a symmetric matrix.
  A = (this->I3 - n * n.transpose());
  A = A.transpose() * A;

  // it would be the case if P1 = P2 For instance
  // if the sensor has some dual returns that hit the same point
  if (!vtkMath::IsFinite(A(0, 0)))
  {
    return;
  }

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(mean);
  this->Xvalues.push_back(P0);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputePlaneDistanceParametersAccurate(pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousPlanes, Eigen::Matrix<double, 3, 3>& R,
                                                     Eigen::Matrix<double, 3, 1>& dT, Point p)
{
  // number of neighbors edge points required to approximate
  // the corresponding egde line
  unsigned int requiredNearest = 8;
  if (this->NLasers > 16)
    requiredNearest = 7;

  Eigen::Matrix<double, 3, 1> P0, P, P1, P2, n, X;
  Eigen::Matrix<double, 3, 3> A;

  // Transform the point using the current pose estimation
  P << p.x, p.y, p.z;
  P0 = P;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);
  
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;
  kdtreePreviousPlanes->nearestKSearch(p, requiredNearest, nearestIndex, nearestDist);

  // if the nearest planars are too far from the
  // current planar keypoint we skip this point.
  if (nearestDist[requiredNearest - 1] > 2.0)
  {
    return;
  }

  // Compute PCA to determine best line approximation
  // of the requiredNearest nearest edges points extracted
  // Thanks to the PCA we will check the shape of the neighborhood
  // and keep it if it is distributed along a line
  Eigen::MatrixXd M(requiredNearest, 3);
  Eigen::Matrix<double, 3, 1> mean;
  mean << 0, 0, 0;
  for (unsigned int k = 0; k < requiredNearest; ++k)
  {
    p = this->PreviousPlanarsPoints->points[nearestIndex[k]];
    X << p.x, p.y, p.z;
    mean += X;
    M(k, 0) = X(0);
    M(k, 1) = X(1);
    M(k, 2) = X(2);
  }
  mean /= static_cast<double>(requiredNearest);

  for (unsigned int k = 0; k < requiredNearest; ++k)
  {
    M(k, 0) -= mean(0);
    M(k, 1) -= mean(1);
    M(k, 2) -= mean(2);
  }
  Eigen::Matrix<double, 3, 3> G = M.transpose() * M;

  // Eigen values
  Eigen::MatrixXd D(1,3);
  // Eigen vectors
  Eigen::MatrixXd V(3,3);

  Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> es(G);
  D = es.eigenvalues();
  V = es.eigenvectors();

  // if the second eigen value is close to the highest one
  // and bigger than the smallest one it means that the points
  // are distributed among a plane
  Eigen::Matrix<double, 3, 1> u, v;
  if ( (3 * D(1, 0) > D(2, 0)) && (D(1, 0) > 30 * D(0, 0)) )
  {
    u << V(0, 2), V(1, 2), V(2, 2);
    v << V(0, 1), V(1, 1), V(2, 1);
  }
  else
  {
    return;
  }

  n = u.cross(v);
  n.normalized();

  // A = n*n.t
  A = n * n.transpose();

  // it would be the case if P1 = P2, P1 = P3
  // or P3 = P2. For instance if the sensor has
  // some dual returns that hit the same point
  if (!vtkMath::IsFinite(A(0, 0)))
  {
    return;
  }

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(mean);
  this->Xvalues.push_back(P0);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeResidualValues(std::vector<Eigen::Matrix<double, 3, 3> >& vA, std::vector<Eigen::Matrix<double, 3, 1> >& vX,
                                    std::vector<Eigen::Matrix<double, 3, 1> >& vP, Eigen::Matrix<double, 3, 3>& R,
                                    Eigen::Matrix<double, 3, 1>& dT, Eigen::MatrixXd& residuals)
{
  residuals = Eigen::MatrixXd(vX.size(), 1);
  Eigen::Matrix<double, 3, 1> Xp;
  for (unsigned int k = 0; k < vX.size(); ++k)
  {
    Xp = R * vX[k] + dT;
    residuals(k) = std::sqrt(std::abs((Xp - vP[k]).transpose() * vA[k] * (Xp - vP[k])));
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeResidualJacobians(std::vector<Eigen::Matrix<double, 3, 3> >& vA, std::vector<Eigen::Matrix<double, 3, 1> >& vX,
                                       std::vector<Eigen::Matrix<double, 3, 1> >& vP, Eigen::Matrix<double, 6, 1>& T,
                                       Eigen::MatrixXd& residualsJacobians)
{
  residualsJacobians = Eigen::MatrixXd(vX.size(), 6);

  double rx, ry, rz;
  rx = T(0); ry = T(1); rz = T(2);
  double X1, X2, X3;
  double C1, C2, C3;
  Eigen::Matrix<double, 3, 3> A;
  Eigen::Matrix<double, 3, 3> R = GetRotationMatrix(T);
  Eigen::Matrix<double, 3, 1> dT;
  dT << T(3), T(4), T(5);

  // cosinus and sinus of the current
  // estimated angles for the ego-motion
  // This is done in order to speed the algortihm
  // full rotation
  double crx, srx;
  double cry, sry;
  double crz, srz;
  crx = std::cos(rx); srx = std::sin(rx);
  cry = std::cos(ry); sry = std::sin(ry);
  crz = std::cos(rz); srz = std::sin(rz);

  for (unsigned int k = 0; k < vX.size(); ++k)
  {
    X1 = vX[k](0); X2 = vX[k](1); X3 = vX[k](2);
    C1 = vP[k](0); C2 = vP[k](1); C3 = vP[k](2);
    A = vA[k];

    // here the cost funtion is the distance between
    // the current plane/ edge point and its corresponding line / plane.
    // The distance is f(R,T)=sqrt((R*X+T - P).t * A * (R*X+T - P))
    // To compute the jacobian we will use the chain-rule
    // we define g(X) = sqrt(X.t * A * X) and h(R,T)=R*X+T-P1
    // Hence, f(R,T) = g(h(R, T)) and the jacobian
    // Jf(R,T) = Jg(h(R,T))*Jh(R,T)

    // represents h(R,T)
    Eigen::Matrix<double, 3, 1> h_R_t = R * vX[k] + dT - vP[k];

    // represent the jacobian of the G function
    // evaluated at the point h(R,T). Note that G is
    // the composition of the functions sqrt and X' * A * X
    // and is not differentiable when X'*A*X = 0
    Eigen::Matrix<double, 1, 3> JacobianG;
    JacobianG << 0, 0, 0;
    double dist = std::sqrt(h_R_t.transpose() * A * h_R_t);
    if (dist > 1e-12)
    {
      JacobianG = h_R_t.transpose() * (A + A.transpose()) * 1.0 / (2.0 * dist);
    }

    // represent the jacobian of the H function
    // evaluated at the point R, T
    Eigen::Matrix<double, 3, 6> JacobianH;
    // dx / drx
    JacobianH(0, 0) = (srz * srx + crz * sry * crx) * X2 + (srz * crx - crz * sry * srx) * X3;
    // dx / dry
    JacobianH(0, 1) = -crz * sry * X1 + crz * cry * srx * X2 + crz * cry * crx * X3;
    // dx / drz
    JacobianH(0, 2) = -srz * cry * X1 + (-crz * crx - srz * sry * srx) * X2+ (crz * srx - srz * sry * crx) * X3;
    // dx / dtx
    JacobianH(0, 3) = 1;
    // dx / dty
    JacobianH(0, 4) = 0;
    // dx / dtz
    JacobianH(0, 5) = 0;
    // dy / drx
    JacobianH(1, 0) = (-crz * srx + srz * sry * crx) * X2 + (-crz * crx - srz * sry * srx) * X3;
    // dy / dry
    JacobianH(1, 1) = -srz * sry * X1 + srz * cry * srx * X2 + srz * cry * crx * X3;
    // dy / drz
    JacobianH(1, 2) = crz * cry * X1 + (-srz * crx + crz * sry * srx) * X2 + (srz * srx + crz * sry * crx) * X3;
    // dy / dtx
    JacobianH(1, 3) = 0;
    // dy / dty
    JacobianH(1, 4) = 1;
    // dy / dtz
    JacobianH(1, 5) = 0;
    // dz / drx
    JacobianH(2, 0) = cry * crx * X2 - cry * srx * X3;
    // dz / dry
    JacobianH(2, 1) = -cry * X1 - sry * srx * X2 - sry * crx * X3;
    // dz / drz
    JacobianH(2, 2) = 0;
    // dz / dtx
    JacobianH(2, 3) = 0;
    // dz / dty
    JacobianH(2, 4) = 0;
    // dr / dtz
    JacobianH(2, 5) = 1;

    Eigen::Matrix<double, 1, 6> jacobian = JacobianG * JacobianH;
    for (unsigned int i = 0; i < 6; ++i)
    {
      residualsJacobians(k, i) = jacobian(0, i);
    }
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeEgoMotion()
{
  // reset the relative transform
  //this->Trelative << 1.8, -0.45, 1.31, 10.0, -10.0, 100.0;
  //this->Trelative << 0.45, -0.12, 0.18, 0.45, -0.62, 0.03;
  //this->Trelative << 0.5, 0.5, 0.5, 0.5, 0.5, 0.5;
  if (this->Trelative.norm() > 15)
  {
    this->Trelative << 0, 0, 0, 0, 0, 0;
  }
  this->Trelative << 0, 0, 0, 0, 0, 0;

  // kd-tree to process fast nearest neighbor
  // among the keypoints of the previous pointcloud
  pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousEdges(new pcl::KdTreeFLANN<Point>());
  pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousPlanes(new pcl::KdTreeFLANN<Point>());
  kdtreePreviousEdges->setInputCloud(this->PreviousEdgesPoints);
  kdtreePreviousPlanes->setInputCloud(this->PreviousPlanarsPoints);

  // corresponding edge line to the edge keypoint
  std::vector<int> matchEdgeIndex1(this->CurrentEdgesPoints->size());
  std::vector<int> matchEdgeIndex2(this->CurrentEdgesPoints->size());

  // corresponding plane line to the planar keypoint
  std::vector<int> matchPlaneIndex1(this->CurrentPlanarsPoints->size());
  std::vector<int> matchPlaneIndex2(this->CurrentPlanarsPoints->size());
  std::vector<int> matchPlaneIndex3(this->CurrentPlanarsPoints->size());

  std::cout << "Performing ego-motion using : " << std::endl;
  std::cout << "previous edges : " << this->PreviousEdgesPoints->size() << " current edges : " << this->CurrentEdgesPoints->size() << std::endl;
  std::cout << "previous edges : " << this->PreviousPlanarsPoints->size() << " current planars : " << this->CurrentPlanarsPoints->size() << std::endl;

  std::vector<double> costFunction(0, 0);

  // let's note f(R, T) = sum(d(point, line)^2) + sum(d(point, plane)^2)
  // f(R, T) = sum(fi(R, T)) = sum(sqrt((R*X+T-P).t*A*(R*X+T-P))). We also note
  // the new step toward the solution is
  // (H + lambda * I)^(-1)*d. Whith H the hessian
  // of the cost function and d = fi(R, T) * gradFi(R, T).
  // Here we approximate the hessian using its jacobian H = JtJ.
  // The lambda parameter is a trade off between X = H^(-1) * d
  // = H^(-1) * (fi(R, T) * gradfi(R, T)) which is tge Gauss-Newton
  // algorithm and
  // X = 1 / lambda * d = 1 / lambda * fi(R, T) * gradfi(R, T)
  // = 1 / (2.0 * lambda) * gradf which is the gradient descent algorithm.
  // The Gauss-Newton algorithm makes the assumption that the point (R, T)
  // is close enought to the solution so that f can be approximated by its
  // quadratic part involving its hessian. The idea of the Levenberg-Marquardt
  // algorithm is to start with a gradient descent value and to slowly drift toward
  // a Gauss-Newton algortihm as we converge toward the minimum of the function
  double lambda = 0.1;

  unsigned int nbrEdgesUsed = 0;
  unsigned int nbrPlanesUsed = 0;
  unsigned int nbrRejection = 0;
  // ICP - Levenberg-Marquardt loop
  for (unsigned int iterCount = 0; iterCount < this->EgoMotionMaxIter; ++iterCount)
  {
    // Rotation and translation at this step
    Eigen::Matrix<double, 3, 3> R;
    Eigen::Matrix<double, 3, 1> dT;
    R = GetRotationMatrix(this->Trelative);
    dT << this->Trelative(3), this->Trelative(4), this->Trelative(5);

    if (iterCount % iterFindMatches == 0)
    {
      this->ResetDistanceParameters();
    }

    //this->ResetDistanceParameters();

    Point currentPoint, transformedPoint;

    // loop over edges
    for (unsigned int edgeIndex = 0; edgeIndex < this->CurrentEdgesPoints->size(); ++edgeIndex)
    {
      currentPoint = this->CurrentEdgesPoints->points[edgeIndex];

      // Transform the current point in the frame L(t_start)
      //this->TransformToStart(currentPoint, transformedPoint, this->Trelative);
      //currentPoint = transformedPoint;

      // Find the closest correspondence edge line of the current edge point
      if (iterCount % iterFindMatches == 0)
      {
        //this->FindEdgeLineMatch(currentPoint, kdtreePreviousEdges, matchEdgeIndex1, matchEdgeIndex2, edgeIndex, R, dT);
        this->ComputeLineDistanceParametersAccurate(kdtreePreviousEdges, R, dT, currentPoint);
        nbrEdgesUsed = this->Xvalues.size();
      }

      // Compute the parameters of the point - line distance
      // i.e A = (I - n*n.t)^2 with n being the director vector
      // and P a point of the line
      //this->ComputeLineDistanceParameters(matchEdgeIndex1, matchEdgeIndex2, edgeIndex);
    }

    // loop over surfaces
    for (unsigned int planarIndex = 0; planarIndex < this->CurrentPlanarsPoints->size(); ++planarIndex)
    {
      currentPoint = this->CurrentPlanarsPoints->points[planarIndex];

      // Transform the current point in the frame L(t_start)
      //this->TransformToStart(currentPoint, transformedPoint, this->Trelative);
      //currentPoint = transformedPoint;

      // Find the closest correspondence edge line of the current edge point
      if (iterCount % iterFindMatches == 0)
      {
        //this->FindPlaneMatch(currentPoint, kdtreePreviousPlanes, matchPlaneIndex1, matchPlaneIndex2, matchPlaneIndex3, planarIndex, R, dT);
        this->ComputePlaneDistanceParametersAccurate(kdtreePreviousPlanes, R, dT, currentPoint);
        nbrPlanesUsed = this->Xvalues.size() - nbrEdgesUsed;
      }

      // Compute the parameters of the point - plane distance
      // i.e A = n * n.t with n being a normal of the plane
      // and is a point of the plane
      //this->ComputePlaneDistanceParameters(matchPlaneIndex1, matchPlaneIndex2, matchPlaneIndex3, planarIndex);
    }

    // f(R, T) = sum(fi(R, T))
    // fi(R, T) = sqrt((R*X+T-P).t * A * (R*X+T-P)
    // J: residual jacobians, [dfi(R, T)/dR, dfi(R, T)/dT]
    // Y: residual values, fi(R, T)
    Eigen::MatrixXd J, Y;
    this->ComputeResidualValues(this->Avalues, this->Xvalues, this->Pvalues, R, dT, Y);
    this->ComputeResidualJacobians(this->Avalues, this->Xvalues, this->Pvalues, this->Trelative, J);

    // RMSE
    costFunction.push_back(0);
    for (unsigned int kk = 0; kk < Y.rows(); ++kk)
    {
      costFunction[costFunction.size() - 1] += Y(kk);
    }
    costFunction[costFunction.size() - 1] /= static_cast<double>(this->Xvalues.size());

    Eigen::MatrixXd Jt = J.transpose();
    Eigen::MatrixXd JtJ = Jt * J;
    Eigen::MatrixXd JtY = Jt * Y;
    Eigen::Matrix<double, 6, 6> diagJtJ;
    diagJtJ << JtJ(0, 0), 0, 0, 0, 0, 0,
               0, JtJ(1, 1), 0, 0, 0, 0,
               0, 0, JtJ(2, 2), 0, 0, 0,
               0, 0, 0, JtJ(3, 3), 0, 0,
               0, 0, 0, 0, JtJ(4, 4), 0,
               0, 0, 0, 0, 0, JtJ(5, 5);

    // The next step of the L-M algorithm is computed by solving
    // (JtJ + lambda * diagJtJ) = Jt * Y. To avoid the computation
    // of the inverse of (JtJ + lambda * diagJtJ) we use a gauss-pivot
    // algorithm to solve the linear equation for this particular point
    Eigen::ColPivHouseholderQR<Eigen::MatrixXd> dec(JtJ + lambda * this->I6);
    Eigen::Matrix<double, 6, 1> X = dec.solve(JtY);

    // Check if the cost function has not increase
    // in the last iteration. If it does, we are too
    // away from the solution to use the Gauss-Newton
    // algorithm. Increase lambda to drift toward gradient descent
    Eigen::Matrix<double, 6, 1> Tcandidate;
    Tcandidate = this->Trelative - X;
    Eigen::Matrix<double, 3, 3> Rcandidate = GetRotationMatrix(Tcandidate);
    Eigen::Matrix<double, 3, 1> dTcandidate;
    dTcandidate << Tcandidate(3), Tcandidate(4), Tcandidate(5);
    Eigen::MatrixXd Ycandidate;
    this->ComputeResidualValues(this->Avalues, this->Xvalues, this->Pvalues, Rcandidate, dTcandidate, Ycandidate);
    double newCost = 0;
    for (unsigned int kk = 0; kk < Ycandidate.rows(); ++kk)
    {
      newCost += Ycandidate(kk);
    }
    newCost /= static_cast<double>(this->Xvalues.size());

    if (newCost > costFunction[costFunction.size() - 1])
    {
      lambda = 3.0 * lambda;
      nbrRejection++;
    }
    else
    {
      this->Trelative = Tcandidate;
      lambda = 1.0 / 3.0 * lambda;
    }
    
    this->EgoMotionIterMade = iterCount + 1;
  }

  for (unsigned int k = 0; k < costFunction.size(); ++k)
  {
    std::cout << "cost : " << costFunction[k] << std::endl;
  }
  std::cout << "cost goes from : " << costFunction[0] << " to : " << costFunction[costFunction.size() - 1] << std::endl;
  std::cout << "used keypoints : " << this->Xvalues.size() << std::endl;
  std::cout << "edges : " << nbrEdgesUsed << " planes : " << nbrPlanesUsed << std::endl;
  std::cout << "nbr rejection : " << nbrRejection << std::endl;
  std::cout << "final lambda value : " << lambda << std::endl;

  // Integrate the relative motion
  // to the world transformation
  this->UpdateTworldUsingTrelative();
}

//-----------------------------------------------------------------------------
void vtkSlam::ResetDistanceParameters()
{
  this->Xvalues.clear();
  this->Xvalues.resize(0);
  this->Avalues.clear();
  this->Avalues.resize(0);
  this->Pvalues.clear();
  this->Pvalues.resize(0);
  this->TimeValues.clear();
  this->TimeValues.resize(0);
}

//-----------------------------------------------------------------------------
void vtkSlam::UpdateTworldUsingTrelative()
{
  // Rotation and translation relative
  Eigen::Matrix<double, 3, 3> Rr, Rw;
  Eigen::Matrix<double, 3, 1> Tr, Tw;
  Rr = GetRotationMatrix(this->Trelative);
  Tr << this->Trelative(3), this->Trelative(4), this->Trelative(5);

  // full rotation
  Rw = GetRotationMatrix(this->Tworld);
  Tw << this->Tworld(3), this->Tworld(4), this->Tworld(5);

  Eigen::Matrix<double, 3, 1> newTw;
  Eigen::Matrix<double, 3, 3> newRw;

  // The new pos of the sensor in the world
  // referential is the previous one composed
  // with the relative motion estimated at the
  // odometry step
  newRw = Rw * Rr;
  newTw = Rw * Tr + Tw;

  double rx = std::atan2(newRw(2, 1), newRw(2, 2));
  double ry = -std::asin(newRw(2, 0));
  double rz = std::atan2(newRw(1, 0), newRw(0, 0));

  this->Tworld(0) = rx;
  this->Tworld(1) = ry;
  this->Tworld(2) = rz;
  this->Tworld(3) = newTw(0);
  this->Tworld(4) = newTw(1);
  this->Tworld(5) = newTw(2);
}