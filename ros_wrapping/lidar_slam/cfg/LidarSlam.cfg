#!/usr/bin/env python

from enum import Enum

PACKAGE='lidar_slam'

from dynamic_reconfigure.parameter_generator_catkin import *

gen = ParameterGenerator()

#########################################################
#        Real-time LiDAR SLAM default parameters        #
#             (see Slam.h for description)              #
#########################################################

# Level of parameters
class Levels(Enum):
    GLOBAL = 0,
    LOGGING = 1,

# Structure parameters
#       Name                    Type  0
#       Description
#       Default                 Min       Max

# -------------------------------------------------------------------------------------------------
# General parameters
gen.add("n_threads", int_t, 0,
        "Max number of threads to use for parallel processing",
        4, 1, 32)
gen.add("TwoD_mode", bool_t, 0,
        "Optimize only 2D pose (X, Y, rZ) of tracking_frame relatively to odometry_frame.",
        False)

# How to estimate Ego-Motion (approximate relative motion since last frame).
# The ego-motion step aims to give a fast and approximate initialization of new
# frame world pose to ensure faster and more precise convergence in Localization step.
#  0) No ego-motion step is performed : relative motion is Identity, new estimated
#     Tworld is equal to previous Tworld. Fast, but may lead to unstable and imprecise
#     Localization step if motion is important.
#  1) Previous motion is linearly extrapolated to estimate new Tworld pose from the
#     2 previous poses. Fast and precise if motion is roughly constant and continuous
#  2) Estimate Trelative (and therefore Tworld) by globally registering new frame
#     on previous frame. Slower and need textured enough environment, but do not
#     rely on constant motion hypothesis.
#  3) Previous motion is linearly extrapolated to estimate new Tworld pose from
#     the 2 previous poses. Then this estimation is refined by globally registering
#     new frame on previous frame. Slower and need textured enough environment,
#     but should be more precise and rely less on constant motion hypothesis.
gen.add("ego_motion", int_t, 0,
        "Ego-Motion estimation mode (see cfg for details)",
        1, 0, 3)

  # Undistortion mode, to correct rolling shutter distortion during frame acquisition.
  # The undistortion should greatly improve the accuracy for smooth motions,
  # but might be unstable for high-frequency motions.
  #  0) NONE: no undistortion is performed :
  #     - End scan pose is optimized using rigid registration of raw scan and map.
  #     - Raw input scan is added to map.
  #  1) ONCE: undistortion is performed only one using estimated ego-motion:
  #     - Begin and end scan poses are linearly interpolated using estimated ego-motion.
  #     - Scan is linearly undistorted between begin and end scan poses.
  #     - Scan pose is iteratively optimized using rigid registration of undistorted scan and map.
  #     - Undistorted scan is added to map.
  #  2) REFINED: undistortion is iteratively refined using optimized ego-motion:
  #     - Begin and end scan poses are linearly interpolated using ego-motion.
  #     - Scan is linearly undistorted between begin and end scan poses.
  #     - Scan pose is optimized using rigid registration of undistorted scan and map.
  #     - Iterate the three previous steps with updated ego-motion and poses.
  #     - Undistorted scan is added to map.
gen.add("undistortion", int_t, 0,
        "Undistortion mode, to correct rolling shutter distortion during frame acquisition",
        2, 0, 2)

gen.add("verbosity", int_t, 0,
        "Verbosity level",
        3, 0, 5)

# -------------------------------------------------------------------------------------------------
logging_group = gen.add_group("Logging")
# Optional logging of computed pose, localization covariance and keypoints of each processed frame.
#  - A value of 0. will disable logging.
#  - A negative value will log all incoming data, without any timeout.
#  - A positive value will keep only most recent data, forgetting all previous data older than timeout seconds.
# Logged data will be used for pose graph optimization, GPS antenna/LiDAR sensor calibration using GPS data
# and velocity/acceleration estimations.
# WARNING : the time window duration must be set lower than this value.
logging_group.add("timeout", double_t, 1,
                  "Logging timeout",
                  0, 0, 10000) #? Max

# How to store pointclouds data during keypoints logging (if logging_timeout != 0):
#  0) PCL pointcloud                    (in RAM,     no compression,      no overhead)
#  1) Octree compressed binary data     (in RAM,    ~5x compression,   ~3 ms overhead)
#  2) Ascii format PCD file             (on disk, ~0.6x compression,   ~5 ms overhead)
#  3) Binary format PCD file            (on disk, ~1.3x compression, ~0.3 ms overhead)
#  4) Binary compressed format PCD file (on disk, ~1.5x compression, ~0.8 ms overhead)
logging_group.add("storage_type", int_t, 1,
                  "Storage mode for pointclouds data",
                  0, 0, 4)



exit(gen.generate(PACKAGE, "lidar_slam", "LidarSlam"))